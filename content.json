{"meta":{"title":"Jason","subtitle":"","description":"","author":"Jason Yu","url":"https://junfish.github.io","root":"/"},"pages":[{"title":"分类","date":"2023-08-31T02:01:44.815Z","updated":"2021-07-05T18:02:59.000Z","comments":false,"path":"categories/index.html","permalink":"https://junfish.github.io/categories/index.html","excerpt":"","text":""},{"title":"About","date":"2023-09-12T21:14:18.933Z","updated":"2023-08-31T17:55:54.793Z","comments":false,"path":"about/index.html","permalink":"https://junfish.github.io/about/index.html","excerpt":"","text":"Academic Activities Aug. 2023: Oral speaker (in-person) on Modeling and Optimization: Theory and Applications 2023 (MOPTA 2023), Bethlehem, USA. Aug. 2022: Oral speaker (in-person) on 10th International Conference on Intelligent Biology and Medicine (ICIBM 2022), Philadelphia, USA. Mar. 2022: Poster presenter (online) on 19th IEEE International Symposium on Biomedical Imaging (ISBI 2022), Kolkata, India. Sept. 2019: Poster presenter (in-person) on 26th IEEE International Conference on Image Processing (ICIP 2019), Taipei, China. Aug. 2018: Volunteer on 7th China Conference on Data Mining (CCDM 2018), Jinan, China. Aug. 2018: Volunteer on 1st CCF International Conference on Artificial Intelligence (CCF-ICAI 2018), Jinan, China. Aug. 2018: Oral speaker on 10th International Conference on Internet Multimedia Computing and Service (ICIMCS 2018), Nanjing, China. May 2017: Student of the first Advanced Lectures on Image and Graphics (CSIG 2017), Beijing, China. Scholarships Sept. 2021: University Fellowship, Lehigh University. (Deferred from Sept. 2020 due to the pandemic disruption). Sept. 2019: China National Scholarship, Shandong University. (Rank TOP 1 in the School of Computer Science and Technology). Sept. 2018: Second-class Postgraduate Scholarship, Shandong University. Sept. 2017: Third-class Entrance Scholarship, Shandong University. Sept. 2016: Research and Innovation Scholarship, Shandong University. Sept. 2015: Research and Innovation Scholarship, Shandong University. Hornors Aug. 2022: Travel award (up to $600) on 10th International Conference on Intelligent Biology and Medicine (ICIBM 2022). Sept. 2019: Advanced individual in innovation and entrepreneurship. Sept. 2016: First prize of Intramural Mathematical Contest in Modeling, Shandong University. Sept. 2016: Advanced individual in innovation and entrepreneurship. Sept. 2015: Advanced individual in innovation and entrepreneurship. Dec. 2015: National first prize of China Undergraduate Mathematical Contest in Modeling (Top 1% papers, Jun Yu is the team leader). Jan. 2015: Meritorious Winner of the Mathematical Contest In Modeling (Top 7% papers, Jun Yu is the team leader). Nov. 2014: The first prize of the China Undergraduate Mathematical Contest in Modeling in Shandong Province. Experience Sept. 2023 — Jun. 2024: Work as a a research assistant with Prof. Vinood Ranboodiri on developing Sept. 2022 — Sept. 2023: Work as a visiting student to UPenn together with Prof. Yong Chen on developing federated learning, transfer learning, multi-task learning methods and algorithms. June 2022 — Sept. 2022: Work as a research assistant at Computational Uncertainty Lab with Prof. Thomas Mcandrew, aiming to model and forecast the U.S. covid-19 outbreak. July 2020 — Aug. 2020: Work part-time at Shandong Coduck Programming Technology Inc. as a C++ teacher."},{"title":"其他链接","date":"2021-07-04T19:25:10.000Z","updated":"2022-03-21T18:59:57.000Z","comments":true,"path":"links/index.html","permalink":"https://junfish.github.io/links/index.html","excerpt":"","text":""},{"title":"Publications","date":"2021-07-04T19:00:02.000Z","updated":"2023-03-05T23:35:01.000Z","comments":false,"path":"publications/index.html","permalink":"https://junfish.github.io/publications/index.html","excerpt":"","text":"论文发表（Papers） [11] Ce Zhou*, Qian Li*, Chen Li*, Jun Yu*, Yixin Liu*, Guangjing Wang, Kai Zhang, Cheng Ji, Qiben Yan, Lifang He, Hao Peng, Jianxin Li, Jia Wu, Ziwei Liu, Pengtao Xie, Caiming Xiong, Jian Pei, Philip S. Yu, and Lichao Sun. (*Equally Contributed). \"A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT\" In arXiv, 2023. [Paper] [10] Jun Yu, Benjamin Zalatan, Yong Chen, Li Shen, and Lifang He. \"Tensor-Based Multi-Modal Multi-Target Regression for Alzheimer’s Disease Prediction\" In 2022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), 2022. 19.8% acceptance rate. [Paper] [Slides] [Video] [9] 申朕, 崔超然, 董桂鑫, 余俊, 黄瑾, 尹义龙. 基于深度多任务学习的图像美感与情感联合预测研究. 软件学报，2022. Zhen Shen, Chaoran Cui, Guixin Dong, Jun Yu, Jin Huang, and Yilong Yin. Unified Image Aesthetic and Emotional Prediction Based on Deep Multi-task Learning. Ruan Jian Xue Bao/Journal of Software, 2022. DOI: 10.13328/j.cnki.jos.006487. [Paper] [8] Jun Yu, Yong Chen, Li Shen, and Lifang He. \"Tensor-Based Multi-Modality Multi-Target Regression for Alzheimer’s Disease Diagnosis.\" In 10th International Conference on Intelligent Biology and Medicine (ICIBM), 2022. Abstract Paper. [Paper] [Slides] [7] Jun Yu. \"Tensor Learning in Brain Network Analysis.\" Ph.D. student poster internal display. Computer Science & Engineering Department, Lehigh University. In Building C, May 9th, 2022. [Poster] Nothing to show here. Please click on Poster. [6] Jun Yu, Zhaoming Kong, Liang Zhan, Li Shen, and Lifang He. \"Tensor-based Multi-Modality Feature Selection and Regression for Alzheimer’s Disease Diagnosis.\" In 8th International Conference on Bioinformatics & Biosciences (BIOS), 2022. [Paper] [Slides] [Code] [5] Jun Yu, Zhaoming Kong, Aditya Kendre, Hao Peng, Carl Yang, Lichao Sun, Alex Leow, and Lifang He. \"Structure-Preserving Graph Kernel for Brain Network Classification.\" In 19th IEEE International Symposium on Biomedical Imaging (ISBI), pp. 1-5. 2022. [Paper] [Poster] [Slides] [Video] [4] 余俊. 基于深度多任务学习的图像美感和情感联合感知研究 [D]. 山东大学硕士毕业论文, 2020. Jun Yu. Research on Unified Aesthetics and Emotion Perception in Images Based on Deep Multi-Task Learning. Master Thesis. Shandong University, 2020. [Paper] [Code] [3] Jin Huang, Chaoran Cui, Chunyun Zhang, Zhen Shen, Jun Yu, and Yilong Yin. \"Learning Multi-Scale Attentive Features for Series Photo Selection.\" In 45th IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 2742-2746. 2020. [Paper] [2] Yuling Ma, Chaoran Cui, Jun Yu, Jie Guo, Gongping Yang, and Yilong Yin. \"Multi-task MIML learning for pre-course student performance prediction.\" Frontiers of Computer Science 14, no. 5: 1-10. 2020. [Paper] [1] Jun Yu, Chaoran Cui, LeiLei Geng, Yuling Ma, and Yilong Yin. \"Towards Unified Aesthetics and Emotion Prediction in Images.\" In 26th IEEE International Conference on Image Processing (ICIP), pp. 2526-2530. 2019. [Paper] [Dataset] [Code] 发明专利（Patents） [1] 《基于深度多任务学习的图像美感和情感联合分类方法及系统》（申请号：CN201910272826.6；主分类号：G06K 9/62；公告号：CN109978074A；发明人：崔超然，余俊，杨文雅；法律状态：公开，在审中）。余俊为除导师外第一完成人。 [著录信息] [全文] 软件著作权（Software） [1] 《面向案件全流程的审判风险多级智能推送系统 V1.0》（软著登字第：2020R11L608691）。余俊为著作权人之一。"},{"title":"Repositories","date":"2023-08-31T02:01:44.756Z","updated":"2021-07-03T12:59:17.000Z","comments":false,"path":"repository/index.html","permalink":"https://junfish.github.io/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2023-08-31T02:01:44.772Z","updated":"2021-07-03T12:59:17.000Z","comments":false,"path":"tags/index.html","permalink":"https://junfish.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"THC (Drug) Experience","slug":"thc-experience","date":"2023-10-26T19:23:16.000Z","updated":"2023-10-27T02:43:31.988Z","comments":true,"path":"2023/10/26/thc-experience/","link":"","permalink":"https://junfish.github.io/2023/10/26/thc-experience/","excerpt":"","text":"THC（四氢大麻酚）科普 四氢大麻酚（Delta-9-tetrahydrocannabinol）是大麻植物中的主要精神活性成分，又名 Δ9\\Delta^9Δ9-THC，大麻素（Cannabinoids）之一。本文讨论大麻素中引起致幻与神经中毒的成分“四氢大麻酚”，大麻素另一无毒成分大麻二酚（CBD）不做详细展开讨论。这里是关于 THC 的一些基本信息： 分子结构图[1, 2] Fun Facts THC 天然存在于大麻科植物大麻属的植物中，尤其在其花和叶的腺体所分泌的树脂中。 THC 是由以色列科学家 Raphael Mechoulam 和他的团队于 1964 年首次从大麻植物中提取并合成的。 近年来，通过选择性培育，一些大麻株的 THC 含量已经显著提高[3]。 1980s: 1%−4%1\\% - 4\\%1%−4% 1990s: 4%−8%4\\% - 8\\%4%−8% 2000s: ≃10%\\simeq10\\%≃10% 2010s: 20%−30%20\\% - 30\\%20%−30% 很多国家以法律形式明文规 定：THC 含量低于 0.3%0.3\\%0.3%（干物质重量百分比）的大麻为工业大麻。工业大麻因其 THC 含量极低，已不具有毒品利用价值，但具有极高的经济利用价值。[4] THC 可以在使用后的几周内仍然在体内检测到，尽管它的精神活性效果通常在几小时内消失。 如何起作用 作用机制：THC 通过模拟体内天然产生的化学物质（内源性大麻素）来作用，主要影响大脑中的大麻素受体。 效果：使用 THC 可以产生多种效果，包括欣快感、放松、食欲增加、时间感知改变、记忆力减退、幻觉（在高剂量时）等。 法律状态 不同国家和地区对THC的法律态度不同。在一些地方，THC 及其所在的大麻产品是合法\\textcolor{green}{合法}合法的，而在其他地方则是非法\\textcolor{red}{非法}非法的。 中国\\textcolor{red}{中国}中国：对所有形式的大麻都持严格的禁止态度，包括 THC。法律严格禁止大麻的种植、销售、运输和使用。 日本\\textcolor{red}{日本}日本：大麻和其相关成分，包括 THC，都是非法的。日本对大麻的法律非常严格，禁止种植、销售、运输和使用大麻。即使是极小量的THC都可能导致刑事起诉。被发现使用或持有大麻的人可能面临长期监禁和重罚。日本政府对于毒品的打击非常严厉，而且日本社会普遍对大麻持负面态度。 韩国\\textcolor{red}{韩国}韩国：大麻及其所有衍生物，包括 THC，都是非法的。韩国对于毒品的控制非常严格。即使是韩国公民在国外使用大麻，回国后也可能面临刑事起诉。 印度\\textcolor{orange}{印度}印度：大麻的法律状态复杂，部分地区允许消费传统形式的大麻制品，但在全国范围内大麻是非法的。 美国\\textcolor{orange}{美国}美国：在联邦层面上大麻被分类为一类管制药物（Schedule I substance），但许多州已经通过法律允许了大麻的医疗或娱乐使用。各州的法律各不相同，一些州完全合法化了大麻，而其他州仍然严格禁止。下面给出我经常活动的三个州 THC 的法律状态[5]： Pennsylvania\\textcolor{red}{\\text{Pennsylvania}}Pennsylvania：截止目前，宾州尚未将娱乐大麻合法化。大麻在该州仍被视为一种非法物质，非法拥有或销售大麻可能导致刑事处罚。不过，一些城市，如费城和匹兹堡，已经通过地方立法，将小量大麻拥有的刑罚降低到类似违规行为的级别。 New Jersey\\textcolor{green}{\\text{New Jersey}}New Jersey：在2020年11月的选举中，新泽西州的选民通过了一项宪法修正案，支持将娱乐性大麻合法化。于2021年2月，新泽西州州长Phil Murphy签署了三项法案，正式将21岁及以上成年人使用娱乐大麻合法化。 New York\\textcolor{green}{\\text{New York}}New York：纽约州在2021年3月通过了《大麻管理和税收法案》（Marijuana Regulation and Taxation Act, MRTA），将娱乐大麻合法化。这使得21岁及以上的成年人能够合法购买和拥有最多3盎司（约85克）的大麻花和最多24克的大麻浓缩物。公共吸食大麻的地方也受到与香烟相同的限制。州政府还成立了大麻管理办公室（Office of Cannabis Management）来监管大麻的生产、销售和分配。 加拿大\\textcolor{green}{加拿大}加拿大：在2018年成为世界上第二个（继乌拉圭之后）全国范围内合法化大麻用于娱乐目的的国家。成年人可以合法购买、拥有和使用限量的大麻。 英国\\textcolor{red}{英国}英国：大麻仍然是一种被分类为B类药物的非法物质，但政府已经允许极为有限的医疗使用大麻。 德国\\textcolor{orange}{德国}德国：小量的大麻拥有在一些州是容忍的，主要取决于个人的年龄和拥有的数量。然而，这并不意味着大麻是合法的，只是在某些情况下不会导致刑事起诉。销售和生产大麻仍然是非法的，并且会受到严厉的惩罚。 法国\\textcolor{red}{法国}法国：任何形式的大麻使用（包括拥有、销售和生产）都是非法的。法国对于大麻的法律非常严格，被发现拥有大麻可能导致重罚和监禁。2018年，法国政府引入了一项新的法律，允许警察对大麻拥有者进行快速罚款，而不是进行刑事起诉。 意大利\\textcolor{red}{意大利}意大利：拥有少量大麻用于个人使用在某种程度上是被容忍的，但这并不意味着它是合法的。拥有小量大麻可能不会导致刑事起诉，但仍然可能会受到行政处罚，如罚款或暂时吊销驾驶执照。然而，贩卖、运输或种植大麻都是严重的犯罪行为，可能会导致长期监禁。从2016年开始，意大利允许“轻大麻”（含有不超过 0.6%0.6\\%0.6% THC 的大麻）的销售，主要用于制造绳索和化妆品等产品。这些产品通常不会导致精神活性效果，但它们在意大利社会和法律界仍然是一个争议话题。 荷兰\\textcolor{green}{荷兰}荷兰：因其对大麻相对宽松的态度而闻名，特别是在阿姆斯特丹。虽然技术上大麻仍然是非法的，但政府已经将其拥有和销售小量大麻合法化。 俄罗斯\\textcolor{red}{俄罗斯}俄罗斯：大麻被列为非法物质。拥有即使是很小量的大麻或 THC 也可能导致刑事起诉。俄罗斯对于毒品相关犯罪的处罚非常严厉，个人如果被发现拥有大麻，可能面临长期监禁和高额罚金。大麻及其成分甚至在医疗上的使用也是非法的。 澳大利亚\\textcolor{orange}{澳大利亚}澳大利亚：大麻法律因州而异，一些州允许医疗使用大麻，而其他州则有更严格的限制。 在中国，大麻的法律状态详细情况： 种植：尽管中国是世界上最大的工业大麻生产国之一，但这主要用于纺织和制造，而不是用于提取大麻中的活性成分。工业大麻种植需要严格的许可和监管。非法种植大麻是犯罪行为，可导致严重的法律后果。 拥有或消费：拥有或消费任何形式的大麻（包括但不限于烟草、食品或油）都是非法的。这包括含有大麻成分的任何制品，无论 THC 的含量如何。被发现拥有大麻可能会导致刑事起诉，情节严重的可判处死刑。 销售或贩卖：销售或贩卖大麻是一个严重的犯罪行为，可能导致长期监禁和高额罚款。政府对毒品贩卖行为采取零容忍的态度，严惩涉毒犯罪。 医疗：尽管一些国家已经开始认可并合法化大麻在医疗上的应用，但在中国，大麻及其成分（甚至包括 CBD）在医疗上的使用仍然受到限制。中国没有医疗大麻计划，相关的法律法规非常严格。 总结：在中国境内，无论是出于娱乐目的还是医疗需求，大麻的使用都是严格禁止的。遵守中国的法律规定是我们每一个中国公民，以及在华居住或旅行的外国朋友的基本责任和义务。 医疗用途 止痛：THC在一些医疗大麻产品中用于缓解疼痛。 减缓恶心：用于化疗患者的恶心和呕吐缓解。 食欲刺激：有助于刺激食欲，特别是对于艾滋病患者和化疗患者。 减轻肌肉紧张与痉挛：THC 显示出对减轻肌肉紧张和痉挛的潜在效果，这对患有多发性硬化症或其他神经肌肉疾病的患者可能是有帮助的。 改善睡眠：THC有助于改善睡眠质量，对于那些患有失眠或其他睡眠障碍的人来说可能是有益的。 抗炎作用：THC具有抗炎作用，可能有助于减轻炎症和与之相关的症状。 缓解焦虑和抑郁：虽然大量使用THC可能导致焦虑和抑郁，但在一些研究和临床实践中，低剂量的THC显示出对缓解焦虑和抑郁症状的潜在效果。 注意事项：虽然THC在医疗领域显示出了广泛的潜在用途，但其使用仍然是一个复杂且有争议的话题。THC的使用可能伴随着认知和心理副作用，特别是在长期或大量使用时。因此，在考虑使用THC或其他大麻相关产品作为治疗手段时，务必咨询医疗专业人员的意见，并遵循相关法律规定。 副作用与风险 记忆和注意力问题：THC 会影响短期记忆和注意力，导致使用者难以集中精力和记住事情。 反应时间减慢：THC 可导致反应时间延长，这在驾驶或操作重机时尤为危险。 感知改变：使用者可能会经历感知失调，比如时间感失真或视觉变化。 焦虑和抑郁：尽管低剂量的 THC 可能有缓解焦虑和抑郁的作用，但高剂量或长期使用可能会增加焦虑和抑郁症状。 妄想和幻觉：大剂量的 THC 可能导致妄想和幻觉。 成瘾性：虽然 THC 的成瘾潜力不如尼古丁或酒精，但长期或大量使用仍有可能导致依赖和成瘾。戒断症状可能包括焦虑、抑郁、失眠和食欲改变。 心理健康：过量使用 THC 可能与心理健康问题相关，包括焦虑、抑郁和妄想。 认知与记忆：THC 的使用可能影响注意力、判断力和记忆力。 长期风险：长期使用THC可能对脑发育造成影响，特别是在青少年时期，这是大脑仍在发育的关键时期。此外，长期吸烟大麻可能对肺部健康产生负面影响。 使用方式 吸烟：最常见的使用方式。 食用：通过大麻食品，如糖果、蛋糕等。 蒸汽吸入：使用蒸汽器吸入。 点滴或涂抹：THC 油或膏剂直接涂抹于皮肤。 强烈程度：食用 &gt; 吸烟/蒸汽 &gt; 点滴或涂抹 个人体验 今年的 International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS 2023) 大会在纽约召开，在这样的一个参会背景下由于机缘巧合尝试了 THC 糖果。 人物关系：朋友 A（Irish, Female），同学 B（Indian, Male） 药物摄入时间：2:30 PM 体验描述时间：2:30 PM 后 72 小时 故事描述方式：在我的视角里是线性叙事，但真实性存疑。请原谅，对于一个嗑嗨了的人还可以如此理智的记住这么多东西，已经很不容易了😭。 THC 糖果本身和普通的糖果没啥区别，不过仔细看的话会有 THC 警告语，我非常关注了药效顶峰时间为口服后 2–4 h。吃的时候很随意轻松，但是当我意识到我吞入了 “drug” 后还是不免有些担心和忧虑，当然这和我本身有着轻微的焦虑症有关。于是和朋友 A 说自己很担心药效会对自己造成严重的损伤。A 简单做了一些科普，说不用太担心，这东西和你吃褪黑素差不多，哈哈，不过比那个对精神的影响要大得多。然后谈笑间我让她也吃了，哈哈，当然只是为了缓解我自己的焦虑感。我和同学 B 去酒店办理入住之后我们便计划去时代广场玩玩。于是出发前往最近的地铁站，因为在纽约开车实在不是一个明智的选择。我们在会场（罗斯福岛）因为找不到停车位被罚了120刀😭。 在走路去地铁站的过程中，我就感觉我的药效开始发作了，很明显的是心跳加速，内心开始产生丰富的情感，嘴巴发干，对于我而言，更明显的是一种强烈的不安全感，这种不安全感既来源于我对于新鲜事物第一次尝试的恐惧感，也来源于我自己本来就有的焦虑症。在走路的过程中，我和同学 B 说 ”Can I hold your hands? I felt like I was going to die bro. Please don’t let me fall down.“ 然后我就紧紧的握住了他的手。B 非常贴心的告诉我 ”Nothing will happen. It’s just the effects of the drug you know.“ 然后我就握住他的手走了一段路，期间就一直在表达自己的恐惧感。在走路中，我转过头对 A 说： ​ ”My hearbeat was so fast. Is that normal?“ 然后拉住她的手放在我的胸口让她感受我急速的心跳。 ​ ”It’s definitely normal. You see, my heartbeat is racing even faster than yours!“ 她也让拉着我的手放在她的胸口感受她的心跳。 当然在那种情况下，我压根没有心思关注别人，我只能听到自己的心跳，对周围的一切感知都开始变得很细微。不过还有残存的理智，感觉到拉着男生的手走在大街上很不好，也不应该拉着女生的手。可是我真的只是因为安全感完全丧失，感觉自己只是个无助的小孩😭，我好需要别人的保护啊😭。能不能带我去医院，不然我会死掉的😭。不过我还是像 A 表达了礼貌性的担忧： ​ ”You know I didn’t mean it. I feel so sorry I have to hold your hand. Since I feel unsafe about my surroundings.“ 说罢举起和她拉在一起的手，并且打算换成去拉同学 B 的手，”转头对 B 说 “I am not a gay actually. I just … just feel so danguous.” ​ ”No! It’s OK. It’s America. U can do anything if you like it.“ 然后说，”You can hold his hands. In America, it means you are friends. It’s not a big deal.“ ​ 同学 B 没怎么说话，只是转头看了一眼 A，感觉好像在怪她为啥要带这种糖果出来。在动作上非常照顾我的心理，握紧了我的手。 我看了眼我的手心，手心流出了汗，因为真的很紧张。一紧张就更紧张，我这个时候用理性感知这个药物的效果就是放大你的一切感性，没准我可以和它很好的相处？放下一些戒备。模糊间听见同学 B 说 “Just calm down. You are OK. Don’t worry about anything. We are all here.” 于是我就非常愿意去听他的话。这个时候我突然想起来 “听话水”，从我当时的感知来说，我愿意听他们说的任何话，我就开始相信这个世界上真的是有这种从事犯罪的 “听话水” 的存在，因为在那个时刻我的感受就是这样的——因为丧失安全感，所以很轻易的听信别人。于是我开始让自己冷静，那一瞬间，世界为我安静，我感受到宁静带来的强大，和我的两个朋友继续走在路上。时不时地用手搓鼻子，对，就是那种吸毒后的搓鼻子😓。一瞬间脑海里闪过——我不会是个吸毒人员吧？路上的人看见我这样子肯定觉得我嗨大了。于是又开始了无限的担忧与后悔，期间扭过头表达了对 A 的不信任： ​ “Why are you treating me this way? I didn’t want to be someone who uses drugs.” 说罢幽怨地、很委屈地看了她一眼。 ​ “OK. You don’t trust me?” A 然后展现出了失落感，好像过了几秒钟没说话。（请不要相信我的时间感知，我感觉是混乱的，包括上述的动作言语的先后顺序）。 ​ 不知怎么的，我好像进入了地铁站，期间好像还逃票了？A 刷了自己的卡我们三个人都进去了。我记得工作人员喊了句什么，然后 A 说 &quot;Just Go!&quot;不过我相信她应该是嫌买票麻烦吧，而且她自己也有可能嗑药嗑嗨了。谁知道呢？ ​ 等地铁的时候，我看着地铁轨道又开始充满恐惧感，于是尽量远离轨道。同学 B 扶着我坐在了长椅上，然后靠近我，感觉他应该是怕我做出什么出格的举动吧。后来恍惚间上了地铁，才发现不知道啥时候开始一直拉着 A 的手。于是我幽怨地疑惑地看着她，不想说话。她笑着说 “What?” 这个动作和她笑着说 “What？”重复了两三次。同学 B 看我们的表情就觉得很无语，我从他的眼神里看出了对 A 的不信任。我们偶尔聊聊天，我说我们下地铁后我要买水喝，冲刷掉我的 “drug effect”，甚至开始用我蹩脚的口语开始造词 “I want to deeffect.” 不知道过了多久，下了地铁后我表达出我想去医院坐着，因为我怕自己死掉。于是他们带我去了最近的 CVS Pharmacy。反正折腾之后需要我自助地填排队信息表，我就开始填自己的信息，姓名、生日、手机号等等。朋友 B 说： ​ “I am pretty sure you are good. If you can fill this form, you are good.” 说罢没管我，在旁边走来走去看周围的场景。 ​ 我知道这是他第一次来纽约，所以很好奇周围的一切。他的这种不照顾我的随意感让我反而觉得自己又行了起来，哈哈哈哈。恍惚间好像又来到了外面，我不知怎么的又想去医院，因为我开始感觉到自己周围的一切都不真实，开始变得虚幻起来。我看时间好像药效过了大约一个半小时。期间朋友 A 一直在打电话问自己的朋友 NYC 附近有哪些便宜的走诊。我感觉过了很久。期间我感觉她好像在骗我，我在想，如果她打电话喊来一些我不认识的人，而我那时候又到了药效最顶峰的时候，我该怎么办？我现在内心深处又爆发着可以听任何的人话的想法（可能这就是孩子的心智吧）。但是另外一个问题来了—我为什么可以相信同学 B ?这不合理，我开始陷入纠结，我该相信谁？我该怎么办？他们两可能就是一伙来给我吃药把我迷晕然后害我。我开始陷入无限的恐惧中，我该不该向周围的人大喊救我？可是这样做会伤害到 A 和 B，万一他们两真的是我认识的人那怎么办？这时候，我用自己最残存的理智告诉自己，快找到一些线索！快找到最安全的办法！突然，我意识到，我和 B 试出来一起开会的，我们之间有工作上的关系，工作上的关系如果造假成本上可能需要提前铺设好几年，这不可能。于是，我一瞬间的想法告诉我，相信 B，看看问他两能不能让 B 带着我走，我不想和 A 一起，因为我内心感觉她打电话的样子很恐怖，好像再找其他人来害我。我陷入极深的被害妄想，此时时间快到了两小时了，我不记得看表时候的具体时间。A 有些许生气，问我 “Do you want me to leave?” 然后表现出伤心和惊讶。我那时候想不了那么多，我只知道我很怕她，我吃了她带给我的“糖果”变成现在这个样子。远离她会让我更有安全感。 ​ 和 A 分开后我对 B 说：“Tell me I did the right thing, right? She is so dangerous.” ​ “Yes. I mean… You know, as a friend, you can’t just give this pill to others in this easy way. And, I don’t know what would happen if you choose to go with her tonight.” 朋友 B 边走边说着。 ​ “Did she follow us?” 我鬼鬼祟祟地问同学 B，期间偷偷地回头看。 ​ “No, she didn’t. Do you want to find some place to have a seat?” 他关心地问我。 ​ “No problem. Actually, the hospital is any place without her. She just made me feel soooo… unsafe.” 我一路上用着蹩脚英语继续神神叨叨。 然后我们坐在时代广场的一处公园长椅上（记不清了）。抬头可以看见大屏幕上印着的红底大字 “Time Square”。我注意了一下时间，是 5:47 PM（后面会揭晓为什么我会记住这个时间）。我朋友期间给他的朋友打了个电话，我开始怀疑起来。为什么 B 和 A 的反应一样，也开始打电话了？难道是喊他朋友来害我？我陷入了疑惑，分不清现实与虚拟。但是我残存的理智告诉我，我们一起来纽约的路上他提到过他有个朋友在纽约，刚工作不久。我想，我和 B 是来自于同一个实验室的，这是个事实，他和他朋友打电话我之前也知道，应该没什么问题。但是，我告诉自己 “不要放松警惕，尤其在这种迷幻的情况下”。周围的一切都好慢啊，行人像是游戏设定一般，只顾低头走路，我到底在哪？感觉周围的一切都是假的。我在想，我如果突然冲大马路上自杀会不会打破这个虚拟的世界？然后把我拉回到现实？但是我没必要冒这个风险，就静静地坐着等待时间过去就好，时间会帮我，时间会帮我，时间会帮我，我不断地暗示自己。可是，周围的一切都开始不真实起来，我为什么会在美国？我只是一个小镇做题家，为什么可以坐在纽约的时代广场？是不是这一切都是我自己幻想出来的？在那一瞬间，恐惧感从天而降完全笼罩了我，我意识到自己可能不是真实的。可是我又同时感觉到身体很轻，好像很舒服，浑身每一个毛孔好像都在高潮，如果要形容的话，我只能说是大于性高潮和尼古丁给我带来的快感和爽感的。但是这种快感更多的像是现在时空里的我在回忆那时候的感觉，感觉很好。可是我记忆中我那时候同时也是很害怕的，恐惧感，无限的恐惧感，我很确信是我之前焦虑症发作时候的濒死感，只是要强上好几倍，可是那时候的我居然可以享受那种以前让我很慌乱的濒死感。在思考与幻觉期间好像同学 B 电话也打完了，我们就开始有一句没一句地聊着，我好像向他透露了我的不安全感来自于我前导师经常威胁我说如果 Performance 不好就不要我了，他好像问了我什么，淡淡的，我记不得了，恍惚间我陷入彻底的幻觉了，如果我不是在幻觉中，那么为什么时间没流动了呢？我看了表，还是 5:47 PM。我看破了第一层虚拟，原来他不是我的同学，他是我的心理医生，他正在为我“疗伤”。我之前的一切经历都是我自己幻想出来的，我从来没有办法出国，凭什么？靠自己一个人 DIY，家里人没有任何帮助的情况下，这是不可能的事情。我其实在国内就疯掉了，刚刚的同学 A 是我在医院吃药后激发出来隐藏的另一个人格，然后随着药效的发挥，我把她赶跑了，我成功了。接下来我只要安安静静的，听“医生”的话，一切都会好起来，我会回到真正的现实——在医院里。在幻想中，我有恐惧，恐惧的是自己居然是个精神病患者，但是更多的是幸福感，被安全感笼罩了。为什么呢？因为我的焦虑症很多时候是害怕自己死掉，可是现在我在医院，医生就在我的旁边，他们怎么会让我死掉呢？于是，我获得了无限的爽感。还有一个细节就是其实我前几天开罐头不小心切到的手其实是我自己自残，只是我把它幻想成开罐头不小心导致的。逐渐地，我感觉好像我是精神病人也不是什么坏事，没准我是一个很高级的多人格“被研究对象”，“真实的我”作为一个在医院里的精神病人，可能因为我的特殊性与复杂性在世界各地都有一定的声誉。瞬间，我幸福了。可是我还想知道在这样现实下的真正的现实，我可以醒过来么？至少知道自己做在医院的玻璃房内也好啊，可是周围的一切都是我的幻想。于是我在偷偷观察我的“心理医生”，看看能不能看出端倪。于是我在偷看他有没有在观察我，我没发现。我问他啥时候带我去吃饭？他说一会就去，可是迟迟不去，时间过了很久很久。。。我就静静地等待药效过去，我就能看到“真实的医院了”，于是我问“医生”，再过一个小时我就会好了么，他说是的，一切都会恢复正常。这时候我抓住了一个线索，有点像是盗梦空间中的信标，让我知道其实我一直在现实中，那就是如果我在医院，我需要等的是药效发挥作用，而不是等药效消失。于是，我就抓住这个细节，让自己镇静下来不胡思乱想。之前因为自己还在医院里面陷入身处时代广场的幻觉，还会有各种奇怪动作，一会笑，一会儿紧张的看周围的人。现在可以更镇定一点了。可是偶尔腿还是会有点发抖。后面朋友 B 带我一起去吃饭，我路过一些路口的时候恍惚间觉得我在医院，我拐个弯就像在在医院过道拐弯，可是我从始至终没有看见我要的“真正的现实”——身处医院。后续的去吃了印度菜，吃饭的时候腿还在发抖，我让自己保持镇静，后续的就等药效退散我感觉自己就可以正常了。回去的路上感觉尿意很强，硬憋到了回房间，撒完尿，感觉自己清醒了许多，用酒店房间的笔奋笔疾书记录了今天的一切，怕忘掉这些感觉没有任何记录。渐渐地时间来到了大约八点钟，心率也逐渐降低到 120 左右。逐渐地感到很舒服，一种正常的舒服，就是感觉胃有点不舒服，胸口也有点疼（这个是我早上起来就有一点，可能因为早起没睡好的缘故），期间和女友一直聊天描述今天的感受，很庆幸她没有对我有偏见，知道我只是体验。然后大约到了一点，感觉很困了，可是还是担心自己死掉，在女朋友的保证下，安然入眠。梦里都很舒服，睡觉的时候都会有梦吟。这里有我一整天的心率变化图，和上述线性叙事应该可以大致吻合： 第二天起来，一切正常，说话比平时多，药效还是有的，胃不舒服，手会偶尔颤抖一下，人很累，但似乎和我的焦虑症和解了许多，感到轻松。 第三天起来，一切正常，累感比昨天多或者差不多，因为在会场需要和人交流，有些感兴趣的 topic 需要集中注意力，所以分不清是药物作用还是本身就很累。 整体感觉：体验之后无计划尝试第二次，因为我能清醒地认识到这种不真实感不是我所需要的。THC 作为神经药物与大脑的神经细胞产生反应，伤害一定是有的。不得不说，这是我最难用理智控制自己行为的一次体验，我很感谢勉强做到了并且还记录了一些感受。我很庆幸我还能找到属于我自己的现实并且耐心等待自己回归正轨。以后的人生，我想我会更在乎自己的感受，放弃很多虚妄，那些在药物作用下变幻莫测的情感有时候在日常生活中也会困扰我们。但是，我们可以选择性的忽略，比如在他人心中的感觉或者印象，好像一切都没那么重要。握牢属于自己的现实，为自己而活，不求绚烂，但求真实！ 结语 I used to think that my life was a tradegy, but now I realize it’s a fucking comedy. ——Arthur Fleck, Joker 当你凝视深渊时，深渊也在凝视你。 ——尼采《善恶的彼岸》 Reference [1] Wikipedia Tetrahydrocannabinol. [2] 百度百科 四氢大麻酚. [3] 数据来源于 GPT-4 inquery “大麻株的 THC 含量随时间变化情况”. [4] 陈璇, 杨明, 郭鸿彦. 大麻植物中大麻素成分研究进展. 植物学报. 2011 Mar 1;46(2):197. [5] 数据来源于 GPT-4 inquery “美国 xx 州 THC 法律情况”. [6] 大麻素小百科 - 纳米脑的文章 - 知乎 https://zhuanlan.zhihu.com/p/510367128.","categories":[{"name":"Recreation","slug":"Recreation","permalink":"https://junfish.github.io/categories/Recreation/"}],"tags":[{"name":"大麻","slug":"大麻","permalink":"https://junfish.github.io/tags/%E5%A4%A7%E9%BA%BB/"},{"name":"THC","slug":"THC","permalink":"https://junfish.github.io/tags/THC/"},{"name":"致幻","slug":"致幻","permalink":"https://junfish.github.io/tags/%E8%87%B4%E5%B9%BB/"}]},{"title":"应大学本科导员孙朋朋老师邀约给大二学子分享经验","slug":"share-my-experience","date":"2022-10-04T18:33:10.000Z","updated":"2022-10-04T18:53:27.000Z","comments":true,"path":"2022/10/04/share-my-experience/","link":"","permalink":"https://junfish.github.io/2022/10/04/share-my-experience/","excerpt":"","text":"感觉自己这一路走来很久没有静下心来写点东西，思考一下自己的过去。很感谢孙老师给了我这样的一个机会，既能帮到在我曾瓜皮过的软件园学习的学弟学妹们，又能小小地总结一下我自己最近几年的得失。我可能并没有太刻意地去组织我这样的一篇“小作文”，但是我的人生信条里是始终有着真实这样的一个词汇萦绕在心中和脑海，所以未经修饰的最原始的想法恰好处处闪烁着真实。当然，在这里还是要请同学们原谅我在词汇量匮乏（语文常年90分）和时间紧张（ddl缠身）双debuff加持下，无法给大家呈现一篇脍炙人口的，处处闪烁着智慧光芒的经验分享。 谈到经验分享，直入主题，我脑海里迅速地闪过两个和我人生息息相关的方法论，不见得正确，就当做茶余饭后的促膝谈心。 第一点是想办法往自己的特长面去造势，听起来蛮复杂的，大家听我慢慢的讲我的故事。我的学习生涯并不顺风顺水，甚至说我一直很想逃离CS系，原因么可能有很多，一方面我并没有很早的接触电脑，当身边的同学已经开始打开eclipse疯狂敲击键盘迸射智慧的火花时，我默默地下载了金山打字。你要问我为啥？简单说也简单，两个字——瓜皮。让我解释一下的话，我当时觉得工欲善其事必先利其器，你看呀，我要coding是不是打字速度得快呀，那我是不是得好好练练打字？所以我就是在这样的一种错误思考错误学习的条件下挣扎着度过了我的第一学期，当然最后几大计算机核心课程也就60分，60分意味着什么大家应该比我更清楚吧？给大家一个等式61-60&gt;1，大家自行体会。那大家会想，我肯定是一无是处的废物了？其实也不见得，我对数学有着一种近乎痴狂的热爱，我记得我的高数应该是98吧，如果我没记错的话，年代久远不太可考了，孙老师可以帮我查查，哈哈。所以大一我想的还是如何转系，当然转的是山大最好的数学系，当然我没转成功，不然也轮不到我给大家分享什么经验。所以，我带着对计算机无限地抵触留在了软件学院，那时候你要问我人生是不是一片黑暗，其实也还好，大概和梦魇开大差不多吧，还是能看得见自己在哪的。我tmd还在软件学院啊，真是日了狗了。可是，日子不是很好过，生活还得继续呀。这个时候我就开始转变思路了，回到我开篇谈到的第一个方法论，是什么来着，对，就是“想办法往自己的特长面去造势”。当时我就暗暗问过自己两个问题，在计算机学院能不能活下去？答案是可以，怎么活？跪着。第二个问题，活下来能不能学数学？答案是可以，怎么学？无人知晓地学，什么意思，没人关注你在做啥，即使你做得再好。所以，我就跪着把数学学了，这就是我的当时条件下最本真的思考。那么，我在这样的条件下是如何“造势”的呢？我就问大家，软件学院和数学最有关系的数学老师是哪一位？那就是数学建模通识课老师刘保东，我人生中最重要的一位恩师，下次见到他麻烦大家帮我向他问一声好，说一声余俊一直想着您，在这里谢谢大家了。那么我是怎么一步步勾搭上这么一位我当时感觉我需要靠近的恩师的呢？首先我查到刘老师其实以前就是数学系的老师，曾经是山大的工程数学所所长，因为工作变动调到计算机学院工作，那时候计软还是一家亲，等等。。。。。。这么说来刘老师应该去青岛工作了吧？算了，帮我问好的事情当我没说。言归正传，这样一位来自数学系的老师，我必须要享受到这份上天的“馈赠”，所以我义不容辞地选了他的数学建模课，建模课成了我一个人的必修课，我努力完成老师所有的任务，当然我所做的不仅于此，课上提到的任何软件，数学库，教科书，我都看过一遍，苦嘛累嘛？其实还好，最惨的是什么，我前面提到过，学得再好没办法装逼呀，只能无人知晓地学。那时候的我一直默默地提醒自己，我就差一个机会，一个能让我被大家知道的机会，在这个机会来之前，我一定要准备好一切，一切都是值得的。这个机会我想大家应该都知道，就是一年一度的大学生数学建模竞赛，13年本科入学，14年我就第一次参赛，很可惜，我没有抓住机会，我拿了省一等奖，甚至没有入围国家奖的选拔。当然，我也没有像我幻想的一样一鸣惊人，这就是人生，不尽如人意十之八九，对我这种平庸的人来说是这样的。可是我并没有放弃，原因很简单，我没有为自己造就足够我起飞的“势”，怎么办，我只能继续去学，默默无闻，无人知晓，没办法装逼地去学。第二年的竞赛，我一如既往地参加。在组队方面，我更加用心，我不在迷恋大神，我打造了一支属于我自己的队伍，第一次的失败告诉我，知根知底地合作比个人能力重要，这个经验算是旁菜赠送给大家的，不用客气，尽情享用。当然，这只是我个人的理解，尽信书不如无书。我的感觉是，在能力达标的情况下，合作比更强的个人能力重要，重要的太多太多太多。这一次，我终于拿到了国家一等奖，不过我还是没有等到我所期望的荣誉加身，因为，计算机学院，大家更在乎的似乎是ACM，或者intel杯，当然我也释怀了，我得到了我想要的，就足够了，大家看得起我，也就够了，还要啥自行车？后续的，我拿到了美赛一等奖。据我了解，我应该我们学院第一个国赛美赛双一等奖buff加身的人，不过也不重要了，也没人care这些。但是，我想说的重点是什么呢，我一直在往我的优势面上去靠，去造势，像后来我抓住人工智能的热潮研究机器学习，加入MLA人工智能实验室（尹义龙老师团队），也是因为机器学习是计算机学科和数学学科最完美最有机的结合。对了，大家见到尹老师也麻烦帮我说一声我想他了，对，没错，他也是我人生中最重要的恩师之一，我承认我有点花心。 第二点我想说的是不要给自己设限，如果说上一部分是我成功的一些经历，这一部分讲的都是我失败的经历了。回过头来看，其实我是能学好计算机的，因为后来我考研发现计算机也没那么难，包括复试的机试，我是能学好的。你要问我为什么拿了国一没有保研，因为我是跪着拿到国一的，什么意思？单列保研基本要求是绩点全校前50%，对，我没达到，跪着学完计算机本科课程。总结起来就是苏轼的两句词“十年生死两茫茫，不思量，自难忘。相顾无言，惟有泪千行。”扯远了，刚说到我觉得计算机也没那么难，那为什么我跪着学？因为我给自己设限，我始终暗示自己学不好计算机，其实并不是这样的，我只是没有找到很好的工程思维方式去学。希望大家能多思考思考如何不给自己设限，让自己的人生有更多的可能性，在这方面我是反面教材，大家以我为戒。还有一件我给自己设限的亲身经历就是我在申请我的PHD导师的时候，我觉得我英语口语很烂，不敢找非华人导师，我甚至拒绝了雪城大学的一位非华裔导师给我下的offer，现在想想，只有后悔。为什么？因为因此失去的机会会让你将来的路越走越窄，最终还是自己买单。然而我来到美国之后发现，美国人对语言的容忍力极高，我给自己的语言设置了一个比美国人心中对 international students 更高的 bar，导致我失去，甚至说直接放弃了很多机会。我希望大家在未来的人生追求当中，胆子大点，永远不要给自己设限，勇于尝试，勇于挑战。因为尝试孕育机会，挑战改变命运。 最后，诸君一切皆顺。 2022年十月三日凌晨于 Mountaintop Campus","categories":[{"name":"小作文","slug":"小作文","permalink":"https://junfish.github.io/categories/%E5%B0%8F%E4%BD%9C%E6%96%87/"}],"tags":[{"name":"个人感悟","slug":"个人感悟","permalink":"https://junfish.github.io/tags/%E4%B8%AA%E4%BA%BA%E6%84%9F%E6%82%9F/"}]},{"title":"Failed to initialize NVML: Driver/library version mismatch","slug":"nvidia-driver-mismatch","date":"2022-09-23T20:12:13.000Z","updated":"2022-09-23T21:37:23.000Z","comments":true,"path":"2022/09/23/nvidia-driver-mismatch/","link":"","permalink":"https://junfish.github.io/2022/09/23/nvidia-driver-mismatch/","excerpt":"","text":"Question: When I run nvidia-smi to check the usage of GPUs, the Linux feedbacks the following message: 1Failed to initialize NVML: Driver/library version mismatch This error may happen even you could still use this command 10 minutes ago. Diagnosis: The Ubuntu system set up an auto-updating for the nvidia GPU driver and create this driver/kernel mismatch. Solutions: Check the version of your GPU kernel module. cat /proc/driver/nvidia/version The feedback is something like this: 12NVRM version: NVIDIA UNIX x86_64 Kernel Module 460.106.00 Tue Sep 28 12:05:58 UTC 2021GCC version: gcc version 9.4.0 (Ubuntu 9.4.0-1ubuntu1~20.04.1) Check the recommended nvidia driver version. ubuntu-drivers devices You will get the feedback in the following: 12345678== /sys/devices/pci0000:00/0000:00:01.1/0000:01:00.0 ==modalias : pci:v000010DEd00002231sv000010DEsd0000147Ebc03sc00i00vendor : NVIDIA Corporationdriver : nvidia-driver-460 - third-party non-free recommendeddriver : nvidia-driver-515-server - distro non-freedriver : nvidia-driver-470-server - distro non-freedriver : nvidia-driver-510-server - distro non-freedriver : xserver-xorg-video-nouveau - distro free builtin Note: You will see a mismatch between the recommended version and existed version for your nvidia driver. Remove the mismatched driver sudo apt-get --purge remove nvidia* Install the recommended nvidia driver version sudo apt install nvidia-driver-460 Reboot your machine sudo reboot Then, check the GPU status again nvidia-smi. Reference [1] Nvidia NVML Driver/library version mismatch [closed] [2] ubuntu20.04 nvidia-smi命令报错Failed to initialize NVML: Driver/library version mismatch解决办法–重启电脑","categories":[{"name":"Debugging","slug":"Debugging","permalink":"https://junfish.github.io/categories/Debugging/"}],"tags":[{"name":"Nvidia","slug":"Nvidia","permalink":"https://junfish.github.io/tags/Nvidia/"},{"name":"GPU","slug":"GPU","permalink":"https://junfish.github.io/tags/GPU/"},{"name":"driver","slug":"driver","permalink":"https://junfish.github.io/tags/driver/"}]},{"title":"The Matrix Calculus","slug":"matrix-calculus","date":"2022-08-25T02:03:22.000Z","updated":"2023-09-14T02:09:14.041Z","comments":true,"path":"2022/08/24/matrix-calculus/","link":"","permalink":"https://junfish.github.io/2022/08/24/matrix-calculus/","excerpt":"","text":"介绍 Introduction In this post, we hope to solve all derivative problems with matrix via the matrix differentiation + trace trick. We denote by lowercase letter xxx, bold lowercase letter x\\boldsymbol{x}x, and bold uppercase letter X\\boldsymbol{X}X a scalar, a vector, and a matrix, respectively. If we denote the entry of a vector and a matrix by xix_ixi​ and xi,jx_{i,j}xi,j​, and f(X)f(\\boldsymbol{X})f(X) denotes the function of matrix X\\boldsymbol{X}X, then we can intuitively define the dirivative of fff to X\\boldsymbol{X}X as: ∇Xf=[∂f∂x1,1⋯∂f∂x1,n⋮⋱⋮∂f∂xm,1⋯∂f∂xm,n]\\nabla_{\\boldsymbol{X}}f = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_{1,1}} &amp; \\cdots &amp; \\frac{\\partial f}{\\partial x_{1,n}} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\frac{\\partial f}{\\partial x_{m,1}} &amp; \\cdots &amp; \\frac{\\partial f}{\\partial x_{m,n}} \\end{bmatrix}∇X​f=⎣⎢⎢⎢⎡​∂x1,1​∂f​⋮∂xm,1​∂f​​⋯⋱⋯​∂x1,n​∂f​⋮∂xm,n​∂f​​⎦⎥⎥⎥⎤​ Futhermore, we can build the connection between this derivation and matrix calculus as follows: df=∑i=1m∑j=1n∂f∂xi,j=tr[(∇Xf)⊤dX]\\text{d}f=\\sum_{i=1}^m\\sum_{j=1}^n\\frac{\\partial f}{\\partial x_{i,j}}=\\text{tr}[(\\nabla_{\\boldsymbol{X}}f)^\\top\\text{d}\\boldsymbol{X}]df=∑i=1m​∑j=1n​∂xi,j​∂f​=tr[(∇X​f)⊤dX]. 在这篇博客中，我们通过微分的思想来统一解决矩阵的一系列求导问题。我们用小写字母 xxx, 小写粗体字母 x\\boldsymbol{x}x, 大写粗体字母 X\\boldsymbol{X}X 分别表示标量，向量和矩阵。 其中向量的元素表示为 xix_ixi​, 矩阵的元素表示为 xi,jx_{i,j}xi,j​。 如果 f(X)f(\\boldsymbol{X})f(X) 表示关于矩阵X\\boldsymbol{X}X的函数，则fff关于矩阵X\\boldsymbol{X}X的导数可以直觉地定义为: ∇Xf=[∂f∂x1,1⋯∂f∂x1,n⋮⋱⋮∂f∂xm,1⋯∂f∂xm,n]\\nabla_{\\boldsymbol{X}}f = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_{1,1}} &amp; \\cdots &amp; \\frac{\\partial f}{\\partial x_{1,n}} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\frac{\\partial f}{\\partial x_{m,1}} &amp; \\cdots &amp; \\frac{\\partial f}{\\partial x_{m,n}} \\end{bmatrix}∇X​f=⎣⎢⎢⎢⎡​∂x1,1​∂f​⋮∂xm,1​∂f​​⋯⋱⋯​∂x1,n​∂f​⋮∂xm,n​∂f​​⎦⎥⎥⎥⎤​ 从而，我们可以建立起矩阵与微分的关联： df=∑i=1m∑j=1n∂f∂xi,j=tr[(∇Xf)⊤dX]\\text{d}f=\\sum_{i=1}^m\\sum_{j=1}^n\\frac{\\partial f}{\\partial x_{i,j}}=\\text{tr}[(\\nabla_{\\boldsymbol{X}}f)^\\top\\text{d}\\boldsymbol{X}]df=∑i=1m​∑j=1n​∂xi,j​∂f​=tr[(∇X​f)⊤dX]. The operational criterion for matrix differentiation 矩阵微分运算法则 d(X±Y)=dX±dY\\color{green} \\text{d}(\\boldsymbol{X}\\pm\\boldsymbol{Y})=\\text{d}\\boldsymbol{X}\\pm\\text{d}\\boldsymbol{Y}d(X±Y)=dX±dY d（XY）=(dX)Y+XdY\\color{green}\\text{d}（\\boldsymbol{X}\\boldsymbol{Y}）=(\\text{d}\\boldsymbol{X})\\boldsymbol{Y}+\\boldsymbol{X}\\text{d}\\boldsymbol{Y}d（XY）=(dX)Y+XdY d(X⊤)=(dX)⊤\\color{green}\\text{d}(\\boldsymbol{X}^\\top) = (\\text{d}\\boldsymbol{X})^\\topd(X⊤)=(dX)⊤ d(tr(X))=tr(dX)\\color{green}\\text{d}(\\text{tr}(\\boldsymbol{X})) = \\text{tr}(\\text{d}\\boldsymbol{X})d(tr(X))=tr(dX) dX−1=−X−1(dX)X−1\\color{green}\\text{d} \\boldsymbol{X}^{-1} = -\\boldsymbol{X}^{-1}(\\text{d}\\boldsymbol{X})\\boldsymbol{X}^{-1}dX−1=−X−1(dX)X−1 d∣X∣=∣X∣tr(X−1dX)\\color{green}\\text{d}|\\boldsymbol{X}| = |\\boldsymbol{X}|\\text{tr}(\\boldsymbol{X}^{-1}\\text{d}\\boldsymbol{X})d∣X∣=∣X∣tr(X−1dX) d(X⊙Y)=dX⊙Y+X⊙dY\\color{green}\\text{d} (\\boldsymbol{X}\\odot\\boldsymbol{Y}) = \\text{d}\\boldsymbol{X}\\odot\\boldsymbol{Y} + \\boldsymbol{X}\\odot \\text{d}\\boldsymbol{Y}d(X⊙Y)=dX⊙Y+X⊙dY dσ(X)=σ′(X)⊙dX，其中 σ(⋅) 为在位函数操作\\color{green}\\text{d} \\sigma(\\boldsymbol{X}) = \\sigma^{\\prime}(\\boldsymbol{X})\\odot \\text{d}\\boldsymbol{X}\\text{，其中}~\\sigma(\\cdot)~为在位函数操作dσ(X)=σ′(X)⊙dX，其中 σ(⋅) 为在位函数操作 Derivative of the Scalar to Matrix Trace Trick a=tr(a)\\color{green}a=\\text{tr}(a)a=tr(a) tr(A)=tr(A⊤)\\color{green}\\text{tr}(\\boldsymbol{A})=\\text{tr}(\\boldsymbol{A}^\\top)tr(A)=tr(A⊤) tr(A±B)=tr(A)±tr(B)\\color{green}\\text{tr}(\\boldsymbol{A}\\pm\\boldsymbol{B}) = \\text{tr}(\\boldsymbol{A}) \\pm \\text{tr}(\\boldsymbol{B})tr(A±B)=tr(A)±tr(B) tr(A⊤B)=∑i∑jai,jbi,j\\color{green}\\text{tr}(\\boldsymbol{A}^\\top\\boldsymbol{B}) = \\sum_i\\sum_j a_{i,j}b_{i,j}tr(A⊤B)=∑i​∑j​ai,j​bi,j​ tr(A⊤B)=tr(BA⊤)=tr(B⊤A)=tr(AB⊤)\\color{green}\\text{tr}(\\boldsymbol{A}^\\top\\boldsymbol{B}) = \\text{tr}(\\boldsymbol{B}\\boldsymbol{A}^\\top) = \\text{tr}(\\boldsymbol{B}^\\top\\boldsymbol{A}) = \\text{tr}(\\boldsymbol{A}\\boldsymbol{B}^\\top)tr(A⊤B)=tr(BA⊤)=tr(B⊤A)=tr(AB⊤) tr[A⊤(B⊙C)]=tr[(A⊙B)⊤C]=∑i∑jai,jbi,jci,j\\color{green}\\text{tr}[\\boldsymbol{A}^\\top(\\boldsymbol{B}\\odot\\boldsymbol{C})] = \\text{tr}[(\\boldsymbol{A}\\odot\\boldsymbol{B})^\\top\\boldsymbol{C}] = \\sum_i\\sum_j a_{i,j}b_{i,j}c_{i,j}tr[A⊤(B⊙C)]=tr[(A⊙B)⊤C]=∑i​∑j​ai,j​bi,j​ci,j​ 例1. 构造函数 No.1 f=a⊤Xb,a∈Rm×1,X∈Rm×n,b∈Rn×1f = \\boldsymbol{a}^\\top \\boldsymbol{X} \\boldsymbol{b}, \\boldsymbol{a}\\in\\mathbb{R}^{m\\times 1}, \\boldsymbol{X}\\in\\mathbb{R}^{m\\times n}, \\boldsymbol{b}\\in\\mathbb{R}^{n\\times1}f=a⊤Xb,a∈Rm×1,X∈Rm×n,b∈Rn×1. Process: df\\text{d} fdf $ = \\text{d}(\\boldsymbol{a}^\\top\\boldsymbol{X}\\boldsymbol{b})$ =tr[d(a⊤Xb)]= \\text{tr}[\\text{d}(\\boldsymbol{a}^\\top\\boldsymbol{X}\\boldsymbol{b})]=tr[d(a⊤Xb)] =tr[a⊤(dX)b]= \\text{tr}[\\boldsymbol{a}^\\top(\\text{d}\\boldsymbol{X})\\boldsymbol{b}]=tr[a⊤(dX)b] =tr(ba⊤dX)= \\text{tr} (\\boldsymbol{b}\\boldsymbol{a}^\\top\\text{d}\\boldsymbol{X})=tr(ba⊤dX) =tr[(ab⊤)⊤dX]= \\text{tr} [(\\boldsymbol{a}\\boldsymbol{b}^\\top)^\\top\\text{d}\\boldsymbol{X}]=tr[(ab⊤)⊤dX] Answer: ∂f∂X=ab⊤\\frac{\\partial f}{\\partial \\boldsymbol{X}} = \\boldsymbol{a}\\boldsymbol{b}^\\top∂X∂f​=ab⊤ 例 2. 构造函数 No.2 f=a⊤eXb,a∈Rm×1,X∈Rm×n,b∈Rn×1f = \\boldsymbol{a}^\\top e^{\\boldsymbol{X}\\boldsymbol{b}}, \\boldsymbol{a}\\in\\mathbb{R}^{m\\times 1}, \\boldsymbol{X}\\in\\mathbb{R}^{m\\times n}, \\boldsymbol{b}\\in\\mathbb{R}^{n\\times 1}f=a⊤eXb,a∈Rm×1,X∈Rm×n,b∈Rn×1. Process: df\\text{d} fdf $ = \\text{d}(\\boldsymbol{a}^\\top e^{\\boldsymbol{X}\\boldsymbol{b}}) = \\text{tr}[\\boldsymbol{a}\\top\\text{d}(e{\\boldsymbol{X}\\boldsymbol{b}})]$ =tr{a⊤[eXb⊙d(Xb)]}= \\text{tr} \\{\\boldsymbol{a}^\\top [e^{\\boldsymbol{X}\\boldsymbol{b}}\\odot\\text{d}(\\boldsymbol{X}\\boldsymbol{b})]\\}=tr{a⊤[eXb⊙d(Xb)]} =tr[(a⊙eXb)⊤d(Xb)]= \\text{tr} [{(\\boldsymbol{a}\\odot e^{\\boldsymbol{X}\\boldsymbol{b}})}^\\top \\text{d}(\\boldsymbol{X}\\boldsymbol{b})]=tr[(a⊙eXb)⊤d(Xb)] =tr[(a⊙eXb)⊤(dX)b]= \\text{tr} [{(\\boldsymbol{a}\\odot e^{\\boldsymbol{X}\\boldsymbol{b}})}^\\top (\\text{d}\\boldsymbol{X})\\boldsymbol{b}]=tr[(a⊙eXb)⊤(dX)b] =tr[b(a⊙eXb)⊤dX]= \\text{tr} [\\boldsymbol{b}{(\\boldsymbol{a}\\odot e^{\\boldsymbol{X}\\boldsymbol{b}})}^\\top \\text{d}\\boldsymbol{X}]=tr[b(a⊙eXb)⊤dX] =tr{[(a⊙eXb)b⊤]⊤dX}= \\text{tr} \\{[(\\boldsymbol{a}\\odot e^{\\boldsymbol{X}\\boldsymbol{b}})\\boldsymbol{b}^\\top]^\\top \\text{d}\\boldsymbol{X}\\}=tr{[(a⊙eXb)b⊤]⊤dX} Answer: ∂f∂X=(a⊙eXb)b⊤\\frac{\\partial f}{\\partial \\boldsymbol{X}} = (\\boldsymbol{a}\\odot e^{\\boldsymbol{X}\\boldsymbol{b}})\\boldsymbol{b}^\\top∂X∂f​=(a⊙eXb)b⊤ 例 3. 构造函数 No.3 f=tr(Y⊤MY),Y=σ(WX),W∈Rl×m,X∈Rm×n,M∈Rl×lf = tr(\\boldsymbol{Y}^\\top \\boldsymbol{M}\\boldsymbol{Y}), Y = \\sigma(\\boldsymbol{W}\\boldsymbol{X}), \\boldsymbol{W}\\in\\mathbb{R}^{l\\times m}, \\boldsymbol{X}\\in\\mathbb{R}^{m\\times n}, \\boldsymbol{M}\\in\\mathbb{R}^{l\\times l}f=tr(Y⊤MY),Y=σ(WX),W∈Rl×m,X∈Rm×n,M∈Rl×l. Process: df\\text{d} fdf $ = \\text{tr} [\\text{d} (\\boldsymbol{Y}^\\top\\boldsymbol{M}\\boldsymbol{Y})]$ =tr[d(Y⊤)MY+Y⊤MdY]= \\text{tr} [\\text{d} (\\boldsymbol{Y}^\\top) \\boldsymbol{M}\\boldsymbol{Y} + \\boldsymbol{Y}^\\top\\boldsymbol{M}\\text{d}\\boldsymbol{Y}]=tr[d(Y⊤)MY+Y⊤MdY] =tr[(dY)⊤MY]+tr(Y⊤MdY)= \\text{tr}[(\\text{d}\\boldsymbol{Y})^\\top\\boldsymbol{M}\\boldsymbol{Y}] + \\text{tr} (\\boldsymbol{Y}^\\top\\boldsymbol{M}\\text{d}\\boldsymbol{Y})=tr[(dY)⊤MY]+tr(Y⊤MdY) =tr(Y⊤M⊤dY)+tr(Y⊤MdY)= \\text{tr}(\\boldsymbol{Y}^\\top\\boldsymbol{M}^\\top\\text{d}\\boldsymbol{Y}) + \\text{tr} (\\boldsymbol{Y}^\\top\\boldsymbol{M}\\text{d}\\boldsymbol{Y})=tr(Y⊤M⊤dY)+tr(Y⊤MdY) =tr[Y⊤(M⊤+M)dY]= \\text{tr} [\\boldsymbol{Y}^\\top(\\boldsymbol{M}^\\top + \\boldsymbol{M})\\text{d}\\boldsymbol{Y}]=tr[Y⊤(M⊤+M)dY] =tr[Y⊤(M⊤+M)dσ(WX)]= \\text{tr} [\\boldsymbol{Y}^\\top(\\boldsymbol{M}^\\top + \\boldsymbol{M})\\text{d}\\sigma(\\boldsymbol{W}\\boldsymbol{X})]=tr[Y⊤(M⊤+M)dσ(WX)] =tr{Y⊤(M⊤+M)[σ′(WX)⊙d(WX)]}= \\text{tr} \\{\\boldsymbol{Y}^\\top(\\boldsymbol{M}^\\top + \\boldsymbol{M})[\\sigma^{\\prime}(\\boldsymbol{W}\\boldsymbol{X}) \\odot \\text{d}(\\boldsymbol{W}\\boldsymbol{X})]\\}=tr{Y⊤(M⊤+M)[σ′(WX)⊙d(WX)]} =tr{{[(M⊤+M)⊤Y]⊙σ′(WX)}⊤d(WX)}= \\text{tr} \\left\\{\\{[(\\boldsymbol{M}^\\top + \\boldsymbol{M})^\\top\\boldsymbol{Y}]\\odot\\sigma^{\\prime}(\\boldsymbol{W}\\boldsymbol{X})\\}^\\top\\text{d}(\\boldsymbol{W}\\boldsymbol{X})\\right\\}=tr{{[(M⊤+M)⊤Y]⊙σ′(WX)}⊤d(WX)} =tr{{[(M⊤+M)Y]⊙σ′(WX)}⊤WdX}= \\text{tr} \\left\\{\\{[(\\boldsymbol{M}^\\top + \\boldsymbol{M})\\boldsymbol{Y}]\\odot\\sigma^{\\prime}(\\boldsymbol{W}\\boldsymbol{X})\\}^\\top\\boldsymbol{W}\\text{d}\\boldsymbol{X}\\right\\}=tr{{[(M⊤+M)Y]⊙σ′(WX)}⊤WdX} =tr{{W⊤{[(M⊤+M)Y]⊙σ′(WX)}}⊤dX}= \\text{tr} \\left\\{\\left\\{\\boldsymbol{W}^\\top\\{[(\\boldsymbol{M}^\\top + \\boldsymbol{M})\\boldsymbol{Y}]\\odot\\sigma^{\\prime}(\\boldsymbol{W}\\boldsymbol{X})\\}\\right\\}^\\top\\text{d}\\boldsymbol{X}\\right\\}=tr{{W⊤{[(M⊤+M)Y]⊙σ′(WX)}}⊤dX} Answer: ∂f∂X=W⊤{[(M+M⊤)σ(WX)]⊙σ′(WX)}\\frac{\\partial f}{\\partial \\boldsymbol{X}} = \\boldsymbol{W}^\\top\\{[(\\boldsymbol{M} + \\boldsymbol{M}^\\top)\\sigma(\\boldsymbol{W}\\boldsymbol{X})] \\odot \\sigma^{\\prime}(\\boldsymbol{W}\\boldsymbol{X})\\}∂X∂f​=W⊤{[(M+M⊤)σ(WX)]⊙σ′(WX)} 例 4. Linear Regression ℓ=∥Xw−y∥22,X∈Rm×n,w∈Rn×1,y∈Rm×1\\ell = \\|\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y}\\|_2^2, \\boldsymbol{X}\\in\\mathbb{R}^{m\\times n}, \\boldsymbol{w}\\in\\mathbb{R}^{n\\times 1}, \\boldsymbol{y}\\in\\mathbb{R}^{m\\times 1}ℓ=∥Xw−y∥22​,X∈Rm×n,w∈Rn×1,y∈Rm×1. Process: $\\text{d} l $ =d[(Xw−y)⊤(Xw−y)]= \\text{d} [(\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y})^\\top(\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y})]=d[(Xw−y)⊤(Xw−y)] =tr{[d(Xw−y)⊤](Xw−y)+(Xw−y)⊤d(Xw−y)}= \\text{tr}\\{[\\text{d} (\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y})^\\top] (\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y}) + (\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y})^\\top \\text{d}(\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y})\\}=tr{[d(Xw−y)⊤](Xw−y)+(Xw−y)⊤d(Xw−y)} =tr{(Xdw)⊤(Xw−y)+(Xw−y)⊤(Xdw)}= \\text{tr}\\{(\\boldsymbol{X}\\text{d}\\boldsymbol{w})^\\top(\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y}) + (\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y})^\\top(\\boldsymbol{X}\\text{d}\\boldsymbol{w})\\}=tr{(Xdw)⊤(Xw−y)+(Xw−y)⊤(Xdw)} =tr[(Xdw)⊤(Xw−y)+(Xw−y)⊤(Xdw)]= \\text{tr}[(\\boldsymbol{X}\\text{d}\\boldsymbol{w})^\\top(\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y}) + (\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y})^\\top(\\boldsymbol{X}\\text{d}\\boldsymbol{w})]=tr[(Xdw)⊤(Xw−y)+(Xw−y)⊤(Xdw)] =tr[(Xw−y)⊤(Xdw)+(Xw−y)⊤(Xdw)]= \\text{tr}[(\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y})^\\top(\\boldsymbol{X}\\text{d}\\boldsymbol{w}) + (\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y})^\\top(\\boldsymbol{X}\\text{d}\\boldsymbol{w})]=tr[(Xw−y)⊤(Xdw)+(Xw−y)⊤(Xdw)] =tr[2(Xw−y)⊤Xdw]= \\text{tr}[2(\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y})^\\top\\boldsymbol{X}\\text{d}\\boldsymbol{w}]=tr[2(Xw−y)⊤Xdw] =tr{2[X⊤(Xw−y)]⊤dw}= \\text{tr}\\{2[\\boldsymbol{X}^\\top(\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y})]^\\top\\text{d}\\boldsymbol{w}\\}=tr{2[X⊤(Xw−y)]⊤dw} Answer: ∂ℓ∂w=2X⊤Xw−2X⊤y→w=(X⊤X)−1X⊤y\\frac{\\partial \\ell}{\\partial \\boldsymbol{w}} = 2\\boldsymbol{X}^\\top\\boldsymbol{X}\\boldsymbol{w} - 2\\boldsymbol{X}^\\top\\boldsymbol{y} \\rightarrow \\boldsymbol{w} = (\\boldsymbol{X}^\\top\\boldsymbol{X})^{-1}\\boldsymbol{X}^\\top\\boldsymbol{y}∂w∂ℓ​=2X⊤Xw−2X⊤y→w=(X⊤X)−1X⊤y 例 5. Maximum Likelihood Estimation (MLE) for the Multivariate Normal Distribution x1,⋯ ,xN∼N(μ,Σ),ℓ=MLE(Σ)=log⁡∣Σ∣+1N∑i=1N(xi−x‾)⊤Σ−1(xi−x‾),x‾=1N∑i=1Nxi,Σ∈Rm×m\\boldsymbol{x}_1, \\cdots, \\boldsymbol{x}_N \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma}), \\ell = MLE(\\boldsymbol{\\Sigma}) = \\log |\\boldsymbol{\\Sigma}| + \\frac{1}{N}\\sum_{i=1}^N{(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})}^\\top\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}}), \\overline{\\boldsymbol{x}} = \\frac{1}{N}\\sum_{i=1}^N\\boldsymbol{x}_i, \\boldsymbol{\\Sigma}\\in\\mathbb{R}^{m\\times m}x1​,⋯,xN​∼N(μ,Σ),ℓ=MLE(Σ)=log∣Σ∣+N1​∑i=1N​(xi​−x)⊤Σ−1(xi​−x),x=N1​∑i=1N​xi​,Σ∈Rm×m. Process: $\\text{d} \\ell $ =tr[d(log⁡∣Σ∣)+1N∑i=1N(xi−x‾)⊤(dΣ−1)(xi−x‾)]= \\text{tr} [\\text{d} (\\log|\\boldsymbol{\\Sigma}|) + \\frac{1}{N}\\sum_{i=1}^N(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})^\\top(\\text{d}\\boldsymbol{\\Sigma}^{-1})(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})]=tr[d(log∣Σ∣)+N1​∑i=1N​(xi​−x)⊤(dΣ−1)(xi​−x)] =tr(1∣Σ∣⊙d∣Σ∣)+1N∑i=1Ntr[(xi−x‾)⊤(dΣ−1)(xi−x‾)]= \\text{tr} (\\frac{1}{|\\boldsymbol{\\Sigma}|}\\odot\\text{d}|\\boldsymbol{\\Sigma}|) + \\frac{1}{N}\\sum_{i=1}^N\\text{tr}[(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})^\\top(\\text{d}\\boldsymbol{\\Sigma}^{-1})(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})]=tr(∣Σ∣1​⊙d∣Σ∣)+N1​∑i=1N​tr[(xi​−x)⊤(dΣ−1)(xi​−x)] =tr{1∣Σ∣⋅∣Σ∣tr(Σ−1dΣ)}+1N∑i=1Ntr[(xi−x‾)(xi−x‾)⊤(dΣ−1)]= \\text{tr} \\{\\frac{1}{|\\boldsymbol{\\Sigma}|}\\cdot|\\boldsymbol{\\Sigma}|\\text{tr}(\\boldsymbol{\\Sigma}^{-1}\\text{d}\\boldsymbol{\\Sigma})\\} + \\frac{1}{N}\\sum_{i=1}^N\\text{tr}[(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})^\\top(\\text{d}\\boldsymbol{\\Sigma}^{-1})]=tr{∣Σ∣1​⋅∣Σ∣tr(Σ−1dΣ)}+N1​∑i=1N​tr[(xi​−x)(xi​−x)⊤(dΣ−1)] =tr(Σ−1dΣ)−1N∑i=1Ntr{(xi−x‾)(xi−x‾)⊤[Σ−1(dΣ)Σ−1]}= \\text{tr}(\\boldsymbol{\\Sigma}^{-1}\\text{d}\\boldsymbol{\\Sigma}) - \\frac{1}{N}\\sum_{i=1}^N\\text{tr}\\{(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})^\\top[\\boldsymbol{\\Sigma}^{-1}(\\text{d}\\boldsymbol{\\Sigma})\\boldsymbol{\\Sigma}^{-1}]\\}=tr(Σ−1dΣ)−N1​∑i=1N​tr{(xi​−x)(xi​−x)⊤[Σ−1(dΣ)Σ−1]} =tr(Σ−1dΣ)−1N∑i=1Ntr[Σ−1(xi−x‾)(xi−x‾)⊤Σ−1dΣ]= \\text{tr}(\\boldsymbol{\\Sigma}^{-1}\\text{d}\\boldsymbol{\\Sigma}) - \\frac{1}{N}\\sum_{i=1}^N\\text{tr}[\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})^\\top\\boldsymbol{\\Sigma}^{-1}\\text{d}\\boldsymbol{\\Sigma}]=tr(Σ−1dΣ)−N1​∑i=1N​tr[Σ−1(xi​−x)(xi​−x)⊤Σ−1dΣ] =tr{[Σ−1−1N∑i=1NΣ−1(xi−x‾)(xi−x‾)⊤Σ−1]dΣ}= \\text{tr}\\left\\{[\\boldsymbol{\\Sigma}^{-1} - \\frac{1}{N}\\sum_{i=1}^N \\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})^\\top\\boldsymbol{\\Sigma}^{-1}]\\text{d}\\boldsymbol{\\Sigma}\\right\\}=tr{[Σ−1−N1​∑i=1N​Σ−1(xi​−x)(xi​−x)⊤Σ−1]dΣ} Answer: ∂ℓ∂Σ={Σ−1−1N∑i=1NΣ−1[(xi−x‾)(xi−x‾)⊤]Σ−1}⊤\\frac{\\partial \\ell}{\\partial \\boldsymbol{\\Sigma}} = {\\{\\boldsymbol{\\Sigma}^{-1} - \\frac{1}{N}\\sum_{i=1}^N\\boldsymbol{\\Sigma}^{-1}[(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}}){(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})}^\\top]\\boldsymbol{\\Sigma}^{-1}\\}}^\\top∂Σ∂ℓ​={Σ−1−N1​∑i=1N​Σ−1[(xi​−x)(xi​−x)⊤]Σ−1}⊤ 例 6. Multinomial Logistic Regression. ℓ=−y⊤log⁡softmax(Wx),y is a one-hot encoding vector with size m,W∈Rm×n,x∈Rn×1,y∈Rm×1,softmax(a)=ea1⊤ea\\ell = -\\boldsymbol{y}^\\top \\log softmax(\\boldsymbol{W}\\boldsymbol{x}), \\boldsymbol{y} \\text{ is a one-hot encoding vector with size } m, \\boldsymbol{W}\\in\\mathbb{R}^{m\\times n}, \\boldsymbol{x}\\in\\mathbb{R}^{n\\times 1}, \\boldsymbol{y}\\in\\mathbb{R}^{m\\times 1}, softmax(\\boldsymbol{a}) = \\frac{e^{\\boldsymbol{a}}}{\\boldsymbol{1}^\\top e^{\\boldsymbol{a}}}ℓ=−y⊤logsoftmax(Wx),y is a one-hot encoding vector with size m,W∈Rm×n,x∈Rn×1,y∈Rm×1,softmax(a)=1⊤eaea​. Process: $\\ell $ =−y⊤log⁡softmax(Wx)= -\\boldsymbol{y}^\\top\\log \\text{softmax}(\\boldsymbol{W}\\boldsymbol{x})=−y⊤logsoftmax(Wx) =−y⊤log⁡eWx1⊤eWx= -\\boldsymbol{y}^\\top\\log \\frac{\\text{e}^{\\boldsymbol{W}\\boldsymbol{x}}}{\\boldsymbol{1}^\\top\\text{e}^{\\boldsymbol{W}\\boldsymbol{x}}}=−y⊤log1⊤eWxeWx​ =−y⊤(Wx)+y⊤log⁡[1⋅(1⊤eWx)]= -\\boldsymbol{y}^\\top (\\boldsymbol{W}\\boldsymbol{x}) + \\boldsymbol{y}^\\top\\log [\\boldsymbol{1}\\cdot(\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}})]=−y⊤(Wx)+y⊤log[1⋅(1⊤eWx)] =−y⊤(Wx)+(y⊤1)log⁡(1⊤eWx)= -\\boldsymbol{y}^\\top (\\boldsymbol{W}\\boldsymbol{x}) + (\\boldsymbol{y}^\\top\\boldsymbol{1})\\log (\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}})=−y⊤(Wx)+(y⊤1)log(1⊤eWx) =−y⊤(Wx)+log⁡(1⊤eWx)= -\\boldsymbol{y}^\\top (\\boldsymbol{W}\\boldsymbol{x}) + \\log (\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}})=−y⊤(Wx)+log(1⊤eWx) $\\text{d} \\ell $ =tr[−y⊤(dW)x+11⊤eWxd(1⊤eWx)]= \\text{tr} [-\\boldsymbol{y}^\\top(\\text{d}\\boldsymbol{W})\\boldsymbol{x} + \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}}\\text{d}(\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}})]=tr[−y⊤(dW)x+1⊤eWx1​d(1⊤eWx)] =tr[−y⊤(dW)x+11⊤eWx⋅1⊤deWx]= \\text{tr} [-\\boldsymbol{y}^\\top(\\text{d}\\boldsymbol{W})\\boldsymbol{x} + \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}}\\cdot\\boldsymbol{1}^\\top\\text{d}e^{\\boldsymbol{W}\\boldsymbol{x}}]=tr[−y⊤(dW)x+1⊤eWx1​⋅1⊤deWx] =tr{−y⊤(dW)x+11⊤eWx⋅1⊤[eWx⊙d(Wx)]}= \\text{tr} \\{-\\boldsymbol{y}^\\top(\\text{d}\\boldsymbol{W})\\boldsymbol{x} + \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}}\\cdot \\boldsymbol{1}^\\top [e^{\\boldsymbol{W}\\boldsymbol{x}}\\odot\\text{d}(\\boldsymbol{W}\\boldsymbol{x})]\\}=tr{−y⊤(dW)x+1⊤eWx1​⋅1⊤[eWx⊙d(Wx)]} =tr[−y⊤(dW)x]+11⊤eWxtr{1⊤[eWx⊙d(Wx)]}= \\text{tr} [-\\boldsymbol{y}^\\top(\\text{d}\\boldsymbol{W})\\boldsymbol{x}] + \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}}\\text{tr} \\{\\boldsymbol{1}^\\top [e^{\\boldsymbol{W}\\boldsymbol{x}}\\odot\\text{d}(\\boldsymbol{W}\\boldsymbol{x})]\\}=tr[−y⊤(dW)x]+1⊤eWx1​tr{1⊤[eWx⊙d(Wx)]} =tr[−y⊤(dW)x]+11⊤eWxtr[(1⊙eWx)⊤d(Wx)]= \\text{tr} [-\\boldsymbol{y}^\\top(\\text{d}\\boldsymbol{W})\\boldsymbol{x}] + \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}}\\text{tr} [(\\boldsymbol{1}\\odot e^{\\boldsymbol{W}\\boldsymbol{x}})^\\top\\text{d}(\\boldsymbol{W}\\boldsymbol{x})]=tr[−y⊤(dW)x]+1⊤eWx1​tr[(1⊙eWx)⊤d(Wx)] =tr(−xy⊤dW)+11⊤eWxtr[(1⊙eWx)⊤(dW)x]= \\text{tr} (-\\boldsymbol{x}\\boldsymbol{y}^\\top\\text{d}\\boldsymbol{W}) + \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}}\\text{tr} [(\\boldsymbol{1}\\odot e^{\\boldsymbol{W}\\boldsymbol{x}})^\\top(\\text{d}\\boldsymbol{W})\\boldsymbol{x}]=tr(−xy⊤dW)+1⊤eWx1​tr[(1⊙eWx)⊤(dW)x] =tr{[−xy⊤+x(eWx)⊤1⊤eWx]dW}= \\text{tr} \\{[-\\boldsymbol{x}\\boldsymbol{y}^\\top + \\boldsymbol{x}\\frac{(e^{\\boldsymbol{W}\\boldsymbol{x}})^\\top}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}}]\\text{d}\\boldsymbol{W}\\}=tr{[−xy⊤+x1⊤eWx(eWx)⊤​]dW} =tr{[(eWx1⊤eWx−y)x⊤]⊤dW}= \\text{tr} \\left\\{[(\\frac{e^{\\boldsymbol{W}\\boldsymbol{x}}}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}} - \\boldsymbol{y})\\boldsymbol{x}^\\top]^\\top\\text{d}\\boldsymbol{W}\\right\\}=tr{[(1⊤eWxeWx​−y)x⊤]⊤dW} Answer: ∂ℓ∂W=[softmax(Wx)−y]x⊤\\frac{\\partial \\ell}{\\partial \\boldsymbol{W}} = [softmax(\\boldsymbol{W}\\boldsymbol{x}) - \\boldsymbol{y}]\\boldsymbol{x}^\\top∂W∂ℓ​=[softmax(Wx)−y]x⊤ 例 7. Back Propagation (BP) for Multi-Layer Perceptron (MLP) ℓ=−∑i=1Nyi⊤log⁡softmax[W2σ(W1xi+b1)+b2],xi∈Rn×1,yi is a one-hot encoding vector with size m,\\ell = - \\sum_{i=1}^N \\boldsymbol{y}_i^\\top\\log softmax[\\boldsymbol{W}_2 \\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2], \\boldsymbol{x}_i \\in \\mathbb{R}^{n\\times 1}, \\boldsymbol{y}_i \\text{ is a one-hot encoding vector with size } m,ℓ=−∑i=1N​yi⊤​logsoftmax[W2​σ(W1​xi​+b1​)+b2​],xi​∈Rn×1,yi​ is a one-hot encoding vector with size m, W1∈Rp×n,b1∈Rp×1,W2∈Rm×p,b2∈Rm×1\\boldsymbol{W}_1 \\in \\mathbb{R}^{p\\times n}, \\boldsymbol{b}_1 \\in \\mathbb{R}^{p\\times 1}, \\boldsymbol{W}_2 \\in \\mathbb{R}^{m\\times p}, \\boldsymbol{b}_2 \\in \\mathbb{R}^{m\\times 1}W1​∈Rp×n,b1​∈Rp×1,W2​∈Rm×p,b2​∈Rm×1. Process: $\\ell $ =−∑i=1Nyi⊤log⁡softmax[W2σ(W1xi+b1)+b2]= -\\sum_{i=1}^N\\boldsymbol{y}_i^{\\top}\\log\\text{softmax}[\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2]=−∑i=1N​yi⊤​logsoftmax[W2​σ(W1​xi​+b1​)+b2​] =−∑i=1Nyi⊤log⁡eW2σ(W1xi+b1)+b21⊤eW2σ(W1xi+b1)+b2= -\\sum_{i=1}^N \\boldsymbol{y}_i^\\top \\log\\frac{e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}}=−∑i=1N​yi⊤​log1⊤eW2​σ(W1​xi​+b1​)+b2​eW2​σ(W1​xi​+b1​)+b2​​ =−∑i=1Nyi⊤[W2σ(W1xi+b1)+b2−log⁡(1⋅1⊤eW2σ(W1xi+b1)+b2)]= -\\sum_{i=1}^N \\boldsymbol{y}_i^\\top[\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2 - \\log(\\boldsymbol{1}\\cdot\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2})]=−∑i=1N​yi⊤​[W2​σ(W1​xi​+b1​)+b2​−log(1⋅1⊤eW2​σ(W1​xi​+b1​)+b2​)] =−∑i=1N{yi⊤[W2σ(W1xi+b1)+b2]−(yi⊤1)log⁡(1⊤eW2σ(W1xi+b1)+b2)}= -\\sum_{i=1}^N\\left\\{\\boldsymbol{y}_i^\\top[\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2] - (\\boldsymbol{y}_i^\\top\\boldsymbol{1})\\log(\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2})\\right\\}=−∑i=1N​{yi⊤​[W2​σ(W1​xi​+b1​)+b2​]−(yi⊤​1)log(1⊤eW2​σ(W1​xi​+b1​)+b2​)} =−∑i=1N{yi⊤[W2σ(W1xi+b1)+b2]−log⁡(1⊤eW2σ(W1xi+b1)+b2)}= -\\sum_{i=1}^N\\left\\{\\boldsymbol{y}_i^\\top[\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2] - \\log(\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2})\\right\\}=−∑i=1N​{yi⊤​[W2​σ(W1​xi​+b1​)+b2​]−log(1⊤eW2​σ(W1​xi​+b1​)+b2​)} dℓ\\text{d} \\elldℓ $ = -\\sum_{i=1}^N \\text{tr}\\left{\\boldsymbol{y}_i^\\top\\text{d} [\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2] - \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} \\text{d} [\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}]\\right}$ =====w.r.t. W2−∑i=1Ntr{yi⊤(dW2)σ(W1xi+b1)−11⊤eW2σ(W1xi+b1)+b2[1⊤deW2σ(W1xi+b1)+b2]}\\overset{\\text{w.r.t.}~\\boldsymbol{W}_2}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\boldsymbol{y}_i^\\top(\\text{d}\\boldsymbol{W}_2)\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) - \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} [\\boldsymbol{1}^\\top \\text{d} e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}]\\right\\}=====w.r.t. W2​−∑i=1N​tr{yi⊤​(dW2​)σ(W1​xi​+b1​)−1⊤eW2​σ(W1​xi​+b1​)+b2​1​[1⊤deW2​σ(W1​xi​+b1​)+b2​]} =====w.r.t. W2−∑i=1Ntr{yi⊤(dW2)σ(W1xi+b1)−1⊤{eW2σ(W1xi+b1)+b2⊙d[W2σ(W1xi+b1)]}1⊤eW2σ(W1xi+b1)+b2}\\overset{\\text{w.r.t.}~\\boldsymbol{W}_2}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\boldsymbol{y}_i^\\top(\\text{d}\\boldsymbol{W}_2)\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) - \\frac{\\boldsymbol{1}^\\top \\{e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2} \\odot \\text{d}[\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1)]\\}}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} \\right\\}=====w.r.t. W2​−∑i=1N​tr{yi⊤​(dW2​)σ(W1​xi​+b1​)−1⊤eW2​σ(W1​xi​+b1​)+b2​1⊤{eW2​σ(W1​xi​+b1​)+b2​⊙d[W2​σ(W1​xi​+b1​)]}​} =====w.r.t. W2−∑i=1Ntr{yi⊤(dW2)σ(W1xi+b1)−(eW2σ(W1xi+b1)+b2)⊤⋅d[W2σ(W1xi+b1)]1⊤eW2σ(W1xi+b1)+b2}\\overset{\\text{w.r.t.}~\\boldsymbol{W}_2}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\boldsymbol{y}_i^\\top(\\text{d}\\boldsymbol{W}_2)\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) - \\frac{(e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2})^\\top \\cdot \\text{d}[\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1)]}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} \\right\\}=====w.r.t. W2​−∑i=1N​tr{yi⊤​(dW2​)σ(W1​xi​+b1​)−1⊤eW2​σ(W1​xi​+b1​)+b2​(eW2​σ(W1​xi​+b1​)+b2​)⊤⋅d[W2​σ(W1​xi​+b1​)]​} =====w.r.t. W2−∑i=1Ntr{yi⊤(dW2)σ(W1xi+b1)−(eW2σ(W1xi+b1)+b2)⊤(dW2)σ(W1xi+b1)1⊤eW2σ(W1xi+b1)+b2}\\overset{\\text{w.r.t.}~\\boldsymbol{W}_2}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\boldsymbol{y}_i^\\top(\\text{d}\\boldsymbol{W}_2)\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) - \\frac{(e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2})^\\top (\\text{d}\\boldsymbol{W}_2)\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1)}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} \\right\\}=====w.r.t. W2​−∑i=1N​tr{yi⊤​(dW2​)σ(W1​xi​+b1​)−1⊤eW2​σ(W1​xi​+b1​)+b2​(eW2​σ(W1​xi​+b1​)+b2​)⊤(dW2​)σ(W1​xi​+b1​)​} =====w.r.t. W2−∑i=1Ntr{σ(W1xi+b1)yi⊤dW2−σ(W1xi+b1)(eW2σ(W1xi+b1)+b2)⊤dW21⊤eW2σ(W1xi+b1)+b2}\\overset{\\text{w.r.t.}~\\boldsymbol{W}_2}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1)\\boldsymbol{y}_i^\\top\\text{d}\\boldsymbol{W}_2 - \\frac{\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1)(e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2})^\\top \\text{d}\\boldsymbol{W}_2}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} \\right\\}=====w.r.t. W2​−∑i=1N​tr{σ(W1​xi​+b1​)yi⊤​dW2​−1⊤eW2​σ(W1​xi​+b1​)+b2​σ(W1​xi​+b1​)(eW2​σ(W1​xi​+b1​)+b2​)⊤dW2​​} =====w.r.t. W2∑i=1Ntr{σ(W1xi+b1)[(eW2σ(W1xi+b1)+b2)⊤1⊤eW2σ(W1xi+b1)+b2−yi⊤]dW2}\\overset{\\text{w.r.t.}~\\boldsymbol{W}_2}{=====} \\sum_{i=1}^N \\text{tr}\\left\\{\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1)[\\frac{(e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2})^\\top}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} - \\boldsymbol{y}_i^\\top]\\text{d}\\boldsymbol{W}_2 \\right\\}=====w.r.t. W2​∑i=1N​tr{σ(W1​xi​+b1​)[1⊤eW2​σ(W1​xi​+b1​)+b2​(eW2​σ(W1​xi​+b1​)+b2​)⊤​−yi⊤​]dW2​} =====w.r.t. W2∑i=1Ntr{{[softmax(W2σ(W1xi+b1)+b2)−yi]σ⊤(W1xi+b1)}⊤dW2}\\overset{\\text{w.r.t.}~\\boldsymbol{W}_2}{=====} \\sum_{i=1}^N \\text{tr}\\left\\{\\{[\\text{softmax} (\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2) - \\boldsymbol{y}_i]\\sigma^\\top(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1)\\}^\\top\\text{d}\\boldsymbol{W}_2 \\right\\}=====w.r.t. W2​∑i=1N​tr{{[softmax(W2​σ(W1​xi​+b1​)+b2​)−yi​]σ⊤(W1​xi​+b1​)}⊤dW2​} dℓ=−∑i=1Ntr{yi⊤d[W2σ(W1xi+b1)+b2]−11⊤eW2σ(W1xi+b1)+b2d[1⊤eW2σ(W1xi+b1)+b2]}\\text{d} \\ell = -\\sum_{i=1}^N \\text{tr}\\left\\{\\boldsymbol{y}_i^\\top\\text{d} [\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2] - \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} \\text{d} [\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}]\\right\\}dℓ=−∑i=1N​tr{yi⊤​d[W2​σ(W1​xi​+b1​)+b2​]−1⊤eW2​σ(W1​xi​+b1​)+b2​1​d[1⊤eW2​σ(W1​xi​+b1​)+b2​]} =====w.r.t. b2−∑i=1Ntr{yi⊤db2−11⊤eW2σ(W1xi+b1)+b2[1⊤deW2σ(W1xi+b1)+b2]}\\overset{\\text{w.r.t.}~\\boldsymbol{b}_2}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\boldsymbol{y}_i^\\top\\text{d}\\boldsymbol{b}_2 - \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} [\\boldsymbol{1}^\\top \\text{d} e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}]\\right\\}=====w.r.t. b2​−∑i=1N​tr{yi⊤​db2​−1⊤eW2​σ(W1​xi​+b1​)+b2​1​[1⊤deW2​σ(W1​xi​+b1​)+b2​]} =====w.r.t. b2−∑i=1Ntr{yi⊤db2−1⊤{eW2σ(W1xi+b1)+b2⊙d[W2σ(W1xi+b1)+b2]}1⊤eW2σ(W1xi+b1)+b2}\\overset{\\text{w.r.t.}~\\boldsymbol{b}_2}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\boldsymbol{y}_i^\\top\\text{d}\\boldsymbol{b}_2 - \\frac{\\boldsymbol{1}^\\top \\{e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2} \\odot \\text{d} [\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2]\\}}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}}\\right\\}=====w.r.t. b2​−∑i=1N​tr{yi⊤​db2​−1⊤eW2​σ(W1​xi​+b1​)+b2​1⊤{eW2​σ(W1​xi​+b1​)+b2​⊙d[W2​σ(W1​xi​+b1​)+b2​]}​} =====w.r.t. b2−∑i=1Ntr{yi⊤db2−[eW2σ(W1xi+b1)+b2]⊤d[W2σ(W1xi+b1)+b2]1⊤eW2σ(W1xi+b1)+b2}\\overset{\\text{w.r.t.}~\\boldsymbol{b}_2}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\boldsymbol{y}_i^\\top\\text{d}\\boldsymbol{b}_2 - \\frac{[e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}]^\\top \\text{d} [\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2]}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}}\\right\\}=====w.r.t. b2​−∑i=1N​tr{yi⊤​db2​−1⊤eW2​σ(W1​xi​+b1​)+b2​[eW2​σ(W1​xi​+b1​)+b2​]⊤d[W2​σ(W1​xi​+b1​)+b2​]​} =====w.r.t. b2−∑i=1Ntr{yi⊤db2−[eW2σ(W1xi+b1)+b2]⊤db21⊤eW2σ(W1xi+b1)+b2}\\overset{\\text{w.r.t.}~\\boldsymbol{b}_2}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\boldsymbol{y}_i^\\top\\text{d}\\boldsymbol{b}_2 - \\frac{[e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}]^\\top \\text{d} \\boldsymbol{b}_2}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}}\\right\\}=====w.r.t. b2​−∑i=1N​tr{yi⊤​db2​−1⊤eW2​σ(W1​xi​+b1​)+b2​[eW2​σ(W1​xi​+b1​)+b2​]⊤db2​​} =====w.r.t. b2∑i=1Ntr{(eW2σ(W1xi+b1)+b21⊤eW2σ(W1xi+b1)+b2−yi)⊤db2}\\overset{\\text{w.r.t.}~\\boldsymbol{b}_2}{=====} \\sum_{i=1}^N \\text{tr}\\left\\{ (\\frac{e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} - \\boldsymbol{y}_i)^\\top\\text{d}\\boldsymbol{b}_2 \\right\\}=====w.r.t. b2​∑i=1N​tr{(1⊤eW2​σ(W1​xi​+b1​)+b2​eW2​σ(W1​xi​+b1​)+b2​​−yi​)⊤db2​} =====w.r.t. b2∑i=1Ntr{(softmax(W2σ(W1xi+b1)+b2)−yi)⊤db2}\\overset{\\text{w.r.t.}~\\boldsymbol{b}_2}{=====} \\sum_{i=1}^N \\text{tr}\\left\\{ (\\text{softmax}(\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2) - \\boldsymbol{y}_i)^\\top\\text{d}\\boldsymbol{b}_2 \\right\\}=====w.r.t. b2​∑i=1N​tr{(softmax(W2​σ(W1​xi​+b1​)+b2​)−yi​)⊤db2​} dℓ=−∑i=1Ntr{yi⊤d[W2σ(W1xi+b1)+b2]−11⊤eW2σ(W1xi+b1)+b2d[1⊤eW2σ(W1xi+b1)+b2]}\\text{d} \\ell = -\\sum_{i=1}^N \\text{tr}\\left\\{\\boldsymbol{y}_i^\\top\\text{d} [\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2] - \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} \\text{d} [\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}]\\right\\}dℓ=−∑i=1N​tr{yi⊤​d[W2​σ(W1​xi​+b1​)+b2​]−1⊤eW2​σ(W1​xi​+b1​)+b2​1​d[1⊤eW2​σ(W1​xi​+b1​)+b2​]} =====w.r.t. W1−∑i=1Ntr{yi⊤W2dσ(W1xi+b1)−11⊤eW2σ(W1xi+b1)+b2[1⊤deW2σ(W1xi+b1)+b2]}\\overset{\\text{w.r.t.}~\\boldsymbol{W}_1}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\boldsymbol{y}_i^\\top\\boldsymbol{W}_2\\text{d}\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) - \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} [\\boldsymbol{1}^\\top \\text{d} e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}]\\right\\}=====w.r.t. W1​−∑i=1N​tr{yi⊤​W2​dσ(W1​xi​+b1​)−1⊤eW2​σ(W1​xi​+b1​)+b2​1​[1⊤deW2​σ(W1​xi​+b1​)+b2​]} =====w.r.t. W1−∑i=1Ntr{{yi⊤−[eW2σ(W1xi+b1)+b2]⊤1⊤eW2σ(W1xi+b1)+b2}W2[σ′(W1xi+b1)⊙d(W1xi)]}\\overset{\\text{w.r.t.}~\\boldsymbol{W}_1}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\{\\boldsymbol{y}_i^\\top - \\frac{[e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}]^\\top}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}}\\}\\boldsymbol{W}_2[\\sigma^{\\prime}(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) \\odot\\text{d}(\\boldsymbol{W}_1\\boldsymbol{x}_i)]\\right\\}=====w.r.t. W1​−∑i=1N​tr{{yi⊤​−1⊤eW2​σ(W1​xi​+b1​)+b2​[eW2​σ(W1​xi​+b1​)+b2​]⊤​}W2​[σ′(W1​xi​+b1​)⊙d(W1​xi​)]} =====w.r.t. W1−∑i=1Ntr{{W2⊤[yi−eW2σ(W1xi+b1)+b21⊤eW2σ(W1xi+b1)+b2]}⊤[σ′(W1xi+b1)⊙d(W1xi)]}\\overset{\\text{w.r.t.}~\\boldsymbol{W}_1}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\{ {\\boldsymbol{W}_2}^\\top[\\boldsymbol{y}_i - \\frac{e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}}]\\}^\\top[\\sigma^{\\prime}(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) \\odot\\text{d}(\\boldsymbol{W}_1\\boldsymbol{x}_i)]\\right\\}=====w.r.t. W1​−∑i=1N​tr{{W2​⊤[yi​−1⊤eW2​σ(W1​xi​+b1​)+b2​eW2​σ(W1​xi​+b1​)+b2​​]}⊤[σ′(W1​xi​+b1​)⊙d(W1​xi​)]} =====w.r.t. W1−∑i=1Ntr{{{W2⊤[yi−softmax(W2σ(W1xi+b1)+b2)]}⊙σ′(W1xi+b1)}⊤d(W1xi)}\\overset{\\text{w.r.t.}~\\boldsymbol{W}_1}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\left\\{\\{ {\\boldsymbol{W}_2}^\\top[\\boldsymbol{y}_i - \\text{softmax}(\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2)]\\}\\odot\\sigma^{\\prime}(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1)\\right\\}^\\top\\text{d}(\\boldsymbol{W}_1\\boldsymbol{x}_i)\\right\\}=====w.r.t. W1​−∑i=1N​tr{{{W2​⊤[yi​−softmax(W2​σ(W1​xi​+b1​)+b2​)]}⊙σ′(W1​xi​+b1​)}⊤d(W1​xi​)} =====w.r.t. W1∑i=1Ntr{{{W2⊤[softmax(W2σ(W1xi+b1)+b2)−yi]}⊙σ′(W1xi+b1)⋅xi⊤}⊤dW1}\\overset{\\text{w.r.t.}~\\boldsymbol{W}_1}{=====} \\sum_{i=1}^N \\text{tr}\\left\\{\\left\\{\\{ {\\boldsymbol{W}_2}^\\top[\\text{softmax}(\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2) - \\boldsymbol{y}_i]\\}\\odot\\sigma^{\\prime}(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1)\\cdot\\boldsymbol{x}_i^\\top\\right\\}^\\top\\text{d}\\boldsymbol{W}_1\\right\\}=====w.r.t. W1​∑i=1N​tr{{{W2​⊤[softmax(W2​σ(W1​xi​+b1​)+b2​)−yi​]}⊙σ′(W1​xi​+b1​)⋅xi⊤​}⊤dW1​} dℓ=−∑i=1Ntr{yi⊤d[W2σ(W1xi+b1)+b2]−11⊤eW2σ(W1xi+b1)+b2d[1⊤eW2σ(W1xi+b1)+b2]}\\text{d} \\ell = -\\sum_{i=1}^N \\text{tr}\\left\\{\\boldsymbol{y}_i^\\top\\text{d} [\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2] - \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} \\text{d} [\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}]\\right\\}dℓ=−∑i=1N​tr{yi⊤​d[W2​σ(W1​xi​+b1​)+b2​]−1⊤eW2​σ(W1​xi​+b1​)+b2​1​d[1⊤eW2​σ(W1​xi​+b1​)+b2​]} =====w.r.t. b1−∑i=1Ntr{yi⊤W2dσ(W1xi+b1)−11⊤eW2σ(W1xi+b1)+b2[1⊤deW2σ(W1xi+b1)+b2]}\\overset{\\text{w.r.t.}~\\boldsymbol{b}_1}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\boldsymbol{y}_i^\\top\\boldsymbol{W}_2\\text{d}\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) - \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} [\\boldsymbol{1}^\\top \\text{d} e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}]\\right\\}=====w.r.t. b1​−∑i=1N​tr{yi⊤​W2​dσ(W1​xi​+b1​)−1⊤eW2​σ(W1​xi​+b1​)+b2​1​[1⊤deW2​σ(W1​xi​+b1​)+b2​]} =====w.r.t. b1−∑i=1Ntr{{yi⊤−[eW2σ(W1xi+b1)+b2]⊤1⊤eW2σ(W1xi+b1)+b2}W2[σ′(W1xi+b1)⊙db1]}\\overset{\\text{w.r.t.}~\\boldsymbol{b}_1}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\{\\boldsymbol{y}_i^\\top - \\frac{[e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}]^\\top}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}}\\}\\boldsymbol{W}_2[\\sigma^{\\prime}(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) \\odot\\text{d}\\boldsymbol{b}_1]\\right\\}=====w.r.t. b1​−∑i=1N​tr{{yi⊤​−1⊤eW2​σ(W1​xi​+b1​)+b2​[eW2​σ(W1​xi​+b1​)+b2​]⊤​}W2​[σ′(W1​xi​+b1​)⊙db1​]} =====w.r.t. b1−∑i=1Ntr{{W2⊤[yi−eW2σ(W1xi+b1)+b21⊤eW2σ(W1xi+b1)+b2]}⊤[σ′(W1xi+b1)⊙db1]}\\overset{\\text{w.r.t.}~\\boldsymbol{b}_1}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\{ {\\boldsymbol{W}_2}^\\top[\\boldsymbol{y}_i - \\frac{e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}}]\\}^\\top[\\sigma^{\\prime}(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) \\odot\\text{d}\\boldsymbol{b}_1]\\right\\}=====w.r.t. b1​−∑i=1N​tr{{W2​⊤[yi​−1⊤eW2​σ(W1​xi​+b1​)+b2​eW2​σ(W1​xi​+b1​)+b2​​]}⊤[σ′(W1​xi​+b1​)⊙db1​]} =====w.r.t. b1∑i=1Ntr{{{W2⊤[softmax(W2σ(W1xi+b1)+b2)−yi]}⊙σ′(W1xi+b1)}⊤db1}\\overset{\\text{w.r.t.}~\\boldsymbol{b}_1}{=====} \\sum_{i=1}^N \\text{tr}\\left\\{\\left\\{\\{ {\\boldsymbol{W}_2}^\\top[\\text{softmax}(\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2) - \\boldsymbol{y}_i]\\}\\odot\\sigma^{\\prime}(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1)\\right\\}^\\top\\text{d}\\boldsymbol{b}_1\\right\\}=====w.r.t. b1​∑i=1N​tr{{{W2​⊤[softmax(W2​σ(W1​xi​+b1​)+b2​)−yi​]}⊙σ′(W1​xi​+b1​)}⊤db1​} Answer: ∂ℓ∂W2=∑i=1N{softmax[W2σ(W1xi+b1)+b2]−yi}σ⊤(W1xi+b1)\\frac{\\partial \\ell}{\\partial \\boldsymbol{W}_2} = \\sum_{i=1}^N \\{softmax[\\boldsymbol{W}_2 \\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2] - \\boldsymbol{y}_i\\} \\sigma^\\top(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1)∂W2​∂ℓ​=∑i=1N​{softmax[W2​σ(W1​xi​+b1​)+b2​]−yi​}σ⊤(W1​xi​+b1​) ∂ℓ∂b2=∑i=1Nsoftmax[W2σ(W1xi+b1)+b2]−yi\\frac{\\partial \\ell}{\\partial \\boldsymbol{b}_2} = \\sum_{i=1}^N softmax[\\boldsymbol{W}_2 \\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2] - \\boldsymbol{y}_i∂b2​∂ℓ​=∑i=1N​softmax[W2​σ(W1​xi​+b1​)+b2​]−yi​ ∂ℓ∂W1=∑i=1N{{W2⊤{softmax[W2σ(W1xi+b1)+b2]−yi}}⊙σ′(W1xi+b1)}xi⊤\\frac{\\partial \\ell}{\\partial \\boldsymbol{W}_1} = \\sum_{i=1}^N \\{\\{\\boldsymbol{W}_2^\\top\\{softmax[\\boldsymbol{W}_2 \\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2] - \\boldsymbol{y}_i\\}\\} \\odot \\sigma^{\\prime}(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) \\} \\boldsymbol{x}_i^\\top∂W1​∂ℓ​=∑i=1N​{{W2⊤​{softmax[W2​σ(W1​xi​+b1​)+b2​]−yi​}}⊙σ′(W1​xi​+b1​)}xi⊤​ ∂ℓ∂b1=∑i=1N{W2⊤{softmax[W2σ(W1xi+b1)+b2]−yi}}⊙σ′(W1xi+b1)\\frac{\\partial \\ell}{\\partial \\boldsymbol{b}_1} = \\sum_{i=1}^N \\{\\boldsymbol{W}_2^\\top\\{softmax[\\boldsymbol{W}_2 \\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2] - \\boldsymbol{y}_i\\}\\} \\odot \\sigma^{\\prime}(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1)∂b1​∂ℓ​=∑i=1N​{W2⊤​{softmax[W2​σ(W1​xi​+b1​)+b2​]−yi​}}⊙σ′(W1​xi​+b1​) Derivative of the Matrix to Matrix 假设f(x)∈Rp×1\\boldsymbol{f}(\\boldsymbol{x})\\in\\mathbb{R}^{p\\times 1}f(x)∈Rp×1是关于向量x∈Rn×1\\boldsymbol{x}\\in\\mathbb{R}^{n\\times 1}x∈Rn×1的函数。不失优雅地（不考虑矩阵布局），我们由向量微分与偏导的关联（df=∂f∂x⊤dxd\\boldsymbol{f}=\\frac{\\partial\\boldsymbol{f}}{\\partial\\boldsymbol{x}}^\\top d\\boldsymbol{x}df=∂x∂f​⊤dx），反推给出列向量对列向量的偏导定义如下： ∂f∂x=[∂f1∂x1⋯∂f1∂xn⋮⋱⋮∂fp∂x1⋯∂fp∂xn]∈Rp×n\\frac{\\partial \\boldsymbol{f}}{\\partial \\boldsymbol{x}} = \\begin{bmatrix} \\frac{\\partial f_1}{\\partial x_{1}} &amp; \\cdots &amp; \\frac{\\partial f_1}{\\partial x_n} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\frac{\\partial f_p}{\\partial x_{1}} &amp; \\cdots &amp; \\frac{\\partial f_p}{\\partial x_n} \\end{bmatrix} \\in \\mathbb{R}^{p\\times n}∂x∂f​=⎣⎢⎢⎢⎡​∂x1​∂f1​​⋮∂x1​∂fp​​​⋯⋱⋯​∂xn​∂f1​​⋮∂xn​∂fp​​​⎦⎥⎥⎥⎤​∈Rp×n 该布局默认为分母布局。在分子布局下， ∂f∂x=[∂f1∂x1⋯∂fp∂x1⋮⋱⋮∂f1∂xn⋯∂fp∂xn]∈Rn×p\\frac{\\partial \\boldsymbol{f}}{\\partial \\boldsymbol{x}} = \\begin{bmatrix} \\frac{\\partial f_1}{\\partial x_{1}} &amp; \\cdots &amp; \\frac{\\partial f_p}{\\partial x_1} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\frac{\\partial f_1}{\\partial x_{n}} &amp; \\cdots &amp; \\frac{\\partial f_p}{\\partial x_n} \\end{bmatrix} \\in \\mathbb{R}^{n\\times p}∂x∂f​=⎣⎢⎢⎢⎡​∂x1​∂f1​​⋮∂xn​∂f1​​​⋯⋱⋯​∂x1​∂fp​​⋮∂xn​∂fp​​​⎦⎥⎥⎥⎤​∈Rn×p 在给出矩阵对矩阵的导数定义前，我们先定义矩阵X∈Rm×n\\boldsymbol{X}\\in\\mathbb{R}^{m\\times n}X∈Rm×n的向量化为Vec(X)=[x1,1,x2,1,⋯ ,xm,1,x1,2,⋯ ,xm,n]⊤\\text{Vec}(\\boldsymbol{X})=[x_{1,1},x_{2,1},\\cdots,x_{m,1},x_{1,2},\\cdots,x_{m,n}]^\\topVec(X)=[x1,1​,x2,1​,⋯,xm,1​,x1,2​,⋯,xm,n​]⊤。从而进一步地我们定义矩阵F∈Rp×q\\boldsymbol{F}\\in\\mathbb{R}^{p\\times q}F∈Rp×q对矩阵X∈Rm×n\\boldsymbol{X}\\in\\mathbb{R}^{m\\times n}X∈Rm×n的导数如下： ∂F∂X=∂Vec(F)∂Vec(X)∈Rmn×pq\\frac{\\partial \\boldsymbol{F}}{\\partial \\boldsymbol{X}} = \\frac{\\partial \\text{Vec}(\\boldsymbol{F})}{\\partial \\text{Vec}(\\boldsymbol{X})}\\in\\mathbb{R}^{mn\\times pq}∂X∂F​=∂Vec(X)∂Vec(F)​∈Rmn×pq 同时，导数与微分的联系可以不失一般地表示为： Vec(dF)=(∂Vec(F)∂Vec(X))⊤Vec(dX)=(∂F∂X)⊤Vec(dX)\\text{Vec}(d\\boldsymbol{F}) = (\\frac{\\partial \\text{Vec}(\\boldsymbol{F})}{\\partial \\text{Vec}(\\boldsymbol{X})})^\\top\\text{Vec}(d\\boldsymbol{X}) = (\\frac{\\partial \\boldsymbol{F}}{\\partial \\boldsymbol{X}})^\\top\\text{Vec}(d\\boldsymbol{X})Vec(dF)=(∂Vec(X)∂Vec(F)​)⊤Vec(dX)=(∂X∂F​)⊤Vec(dX). 若FFF降级为标量fff时，为了统一表示，我们记∂f∂X=Vec(∇Xf)\\frac{\\partial f}{\\partial \\boldsymbol{X}} = \\text{Vec}(\\nabla_{\\boldsymbol{X}}f)∂X∂f​=Vec(∇X​f)。在此基础上求二阶导，得到机器学习中常见的 Hessian matrix: ∇X2f=∂2f∂X2=∂(∇Xf)∂X∈Rmn×mn\\nabla^2_{\\boldsymbol{X}}f = \\frac{\\partial^2 f}{\\partial\\boldsymbol{X}^2} = \\frac{\\partial (\\nabla_{\\boldsymbol{X}}f)}{\\partial \\boldsymbol{X}}\\in\\mathbb{R}^{mn\\times mn}∇X2​f=∂X2∂2f​=∂X∂(∇X​f)​∈Rmn×mn. Notice 1: 若从分子布局和分母布局的角度出发，与微分相关联且不失一般性的布局为分母布局，机器学习和优化理论常用此布局。 Notice 2: 矩阵对矩阵求导定义除了分子布局与分母布局外，还可以有其它定义，例如: ∂F∂X=[∂f1,1∂X⋯∂f1,q∂X⋮⋱⋮∂fp,1∂X⋯∂fp,q∂X]=[∂F∂x1,1⋯∂F∂x1,n⋮⋱⋮∂F∂xm,1⋯∂F∂xm,n]\\frac{\\partial \\boldsymbol{F}}{\\partial \\boldsymbol{X}} = \\begin{bmatrix} \\frac{\\partial f_{1,1}}{\\partial \\boldsymbol{X}} &amp; \\cdots &amp; \\frac{\\partial f_{1,q}}{\\partial \\boldsymbol{X}} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\frac{\\partial f_{p,1}}{\\partial \\boldsymbol{X}} &amp; \\cdots &amp; \\frac{\\partial f_{p,q}}{\\partial \\boldsymbol{X}} \\end{bmatrix} = \\begin{bmatrix} \\frac{\\partial \\boldsymbol{F}}{\\partial x_{1,1}} &amp; \\cdots &amp; \\frac{\\partial \\boldsymbol{F}}{\\partial x_{1,n}} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\frac{\\partial \\boldsymbol{F}}{\\partial x_{m,1}} &amp; \\cdots &amp; \\frac{\\partial \\boldsymbol{F}}{\\partial x_{m,n}} \\end{bmatrix}∂X∂F​=⎣⎢⎢⎡​∂X∂f1,1​​⋮∂X∂fp,1​​​⋯⋱⋯​∂X∂f1,q​​⋮∂X∂fp,q​​​⎦⎥⎥⎤​=⎣⎢⎢⎢⎡​∂x1,1​∂F​⋮∂xm,1​∂F​​⋯⋱⋯​∂x1,n​∂F​⋮∂xm,n​∂F​​⎦⎥⎥⎥⎤​ 然而，该定义只可兼容标量对矩阵的求导，无法配合微分进行运算，因此不是&quot;好&quot;的定义。 假设纯在复合函数Y⋅F\\boldsymbol{Y}\\cdot\\boldsymbol{F}Y⋅F，则 Vec(dF)=(∂F∂Y)⊤Vec(dY)=(∂F∂Y)⊤((∂Y∂X)⊤Vec(dX))=(∂Y∂X∂F∂Y)⊤Vec(dX)\\text{Vec}(\\text{d} \\boldsymbol{F}) = {(\\frac{\\partial \\boldsymbol{F}}{\\partial \\boldsymbol{Y}})}^\\top \\text{Vec}(\\text{d} \\boldsymbol{Y}) = {(\\frac{\\partial \\boldsymbol{F}}{\\partial \\boldsymbol{Y}})}^\\top \\left( {(\\frac{\\partial \\boldsymbol{Y}}{\\partial \\boldsymbol{X}})}^\\top \\text{Vec}(\\text{d} \\boldsymbol{X})\\right) = {\\left(\\frac{\\partial \\boldsymbol{Y}}{\\partial \\boldsymbol{X}} \\frac{\\partial \\boldsymbol{F}}{\\partial \\boldsymbol{Y}}\\right)} ^\\top \\text{Vec}(\\text{d} \\boldsymbol{X})Vec(dF)=(∂Y∂F​)⊤Vec(dY)=(∂Y∂F​)⊤((∂X∂Y​)⊤Vec(dX))=(∂X∂Y​∂Y∂F​)⊤Vec(dX). 因此，dFdX=∂Y∂X∂F∂Y\\frac{\\text{d} \\boldsymbol{F}}{\\text{d} \\boldsymbol{X}} = \\frac{\\partial \\boldsymbol{Y}}{\\partial \\boldsymbol{X}} \\frac{\\partial \\boldsymbol{F}}{\\partial \\boldsymbol{Y}}dXdF​=∂X∂Y​∂Y∂F​. Vectorization Trick Vec(A+B)=Vec(A)+Vec(B)\\color{green}\\text{Vec}(\\boldsymbol{A} + \\boldsymbol{B}) = \\text{Vec}(\\boldsymbol{A}) + \\text{Vec}(\\boldsymbol{B})Vec(A+B)=Vec(A)+Vec(B) Vec(AXB)=(B⊤⊗A)Vec(X)，其中 ⊗ 表示 Kronecker Product:\\color{green}\\text{Vec}(\\boldsymbol{A}\\boldsymbol{X}\\boldsymbol{B}) = (\\boldsymbol{B}^\\top\\otimes \\boldsymbol{A})\\text{Vec}(\\boldsymbol{X})，其中~\\otimes~表示~\\text{Kronecker Product}:Vec(AXB)=(B⊤⊗A)Vec(X)，其中 ⊗ 表示 Kronecker Product: A⊗B(A∈Rm×n,B∈Rp×q)=[a1,1B⋯a1,nB⋮⋱⋮am,1B⋯am,nB]\\color{green} \\boldsymbol{A}\\otimes\\boldsymbol{B}(\\boldsymbol{A}\\in\\mathbb{R}^{m\\times n}, \\boldsymbol{B}\\in\\mathbb{R}^{p\\times q}) = \\begin{bmatrix} a_{1,1}\\boldsymbol{B} &amp; \\cdots &amp; a_{1,n}\\boldsymbol{B}\\\\ \\vdots &amp; \\ddots &amp; \\vdots\\\\ a_{m,1}\\boldsymbol{B} &amp; \\cdots &amp; a_{m,n}\\boldsymbol{B} \\end{bmatrix}A⊗B(A∈Rm×n,B∈Rp×q)=⎣⎢⎢⎡​a1,1​B⋮am,1​B​⋯⋱⋯​a1,n​B⋮am,n​B​⎦⎥⎥⎤​ Vec(ab⊤)=b⊗a\\color{green}\\text{Vec}(\\boldsymbol{a}\\boldsymbol{b}^\\top) = \\boldsymbol{b}\\otimes\\boldsymbol{a}Vec(ab⊤)=b⊗a Vec(AT)=KmnVec(A),其中 Kmn 为交换矩阵 (∑iki,j=∑jki,j=1,Kmn=Knm⊤,KmnKnm=I)\\color{green}\\text{Vec}(\\boldsymbol{A}^T)=\\boldsymbol{K}_{mn}\\text{Vec}(\\boldsymbol{A}), 其中~ \\boldsymbol{K}_{mn}~为交换矩阵~(\\sum_i k_{i,j} = \\sum_j k_{i,j} = 1, \\boldsymbol{K}_{mn} = {\\boldsymbol{K}_{nm}}^\\top, \\boldsymbol{K}_{mn}\\boldsymbol{K}_{nm} = \\boldsymbol{I})Vec(AT)=Kmn​Vec(A),其中 Kmn​ 为交换矩阵 (∑i​ki,j​=∑j​ki,j​=1,Kmn​=Knm​⊤,Kmn​Knm​=I) Kp,m(A⊗B)Knq=B⊗A(A∈Rm×n,B∈Rp×q)\\color{green} \\boldsymbol{K}_{p,m}(\\boldsymbol{A}\\otimes\\boldsymbol{B})\\boldsymbol{K}_{nq}=\\boldsymbol{B}\\otimes\\boldsymbol{A}(\\boldsymbol{A}\\in\\mathbb{R}^{m\\times n}, \\boldsymbol{B}\\in\\mathbb{R}^{p\\times q})Kp,m​(A⊗B)Knq​=B⊗A(A∈Rm×n,B∈Rp×q) Proof: Vec(AXB⊤)=B⊗AVec(X),A∈Rm×n,X∈Rn×q,B∈Rp×q\\text{Vec}(\\boldsymbol{A}\\boldsymbol{X}\\boldsymbol{B}^\\top)=\\boldsymbol{B}\\otimes\\boldsymbol{A}\\text{Vec}(X), \\boldsymbol{A}\\in\\mathbb{R}^{m\\times n}, \\boldsymbol{X}\\in\\mathbb{R}^{n\\times q}, \\boldsymbol{B}\\in\\mathbb{R}^{p\\times q}Vec(AXB⊤)=B⊗AVec(X),A∈Rm×n,X∈Rn×q,B∈Rp×q Vec(BX⊤A⊤)=(A⊗B)Vec(X⊤)=(A⊗B)Kn,qVec(X)\\text{Vec}(\\boldsymbol{B}\\boldsymbol{X}^\\top\\boldsymbol{A}^\\top)=(\\boldsymbol{A}\\otimes\\boldsymbol{B})\\text{Vec}(\\boldsymbol{X}^\\top)=(\\boldsymbol{A}\\otimes\\boldsymbol{B})\\boldsymbol{K}_{n,q}\\text{Vec}(\\boldsymbol{X})Vec(BX⊤A⊤)=(A⊗B)Vec(X⊤)=(A⊗B)Kn,q​Vec(X) Vec[(AXB⊤)⊤]=Km,pVec(AXB⊤)=Km,pB⊗AVec(X)\\text{Vec}\\left[(\\boldsymbol{A}\\boldsymbol{X}\\boldsymbol{B}^\\top)^\\top\\right]=\\boldsymbol{K}_{m,p}\\text{Vec}(\\boldsymbol{A}\\boldsymbol{X}\\boldsymbol{B}^\\top)=\\boldsymbol{K}_{m,p}\\boldsymbol{B}\\otimes\\boldsymbol{A}\\text{Vec}(\\boldsymbol{X})Vec[(AXB⊤)⊤]=Km,p​Vec(AXB⊤)=Km,p​B⊗AVec(X) Thus, Kp,m(A⊗B)Kn,qVec(X)=Kp,mKm,pB⊗AVec(X)=B⊗AVec(X)\\boldsymbol{K}_{p,m}(\\boldsymbol{A}\\otimes\\boldsymbol{B})\\boldsymbol{K}_{n,q}\\text{Vec}(\\boldsymbol{X})=\\boldsymbol{K}_{p,m}\\boldsymbol{K}_{m,p}\\boldsymbol{B}\\otimes\\boldsymbol{A}\\text{Vec}(\\boldsymbol{X})=\\boldsymbol{B}\\otimes\\boldsymbol{A}\\text{Vec}(\\boldsymbol{X})Kp,m​(A⊗B)Kn,q​Vec(X)=Kp,m​Km,p​B⊗AVec(X)=B⊗AVec(X) Vec(A⊙B)=Diag(A)Vec(B)，其中 Diag(A) 为对角化操作，即把 Vec(A) 中所有元素排成对角阵(除对角线外其余元素全为零)\\color{green}\\text{Vec}(\\boldsymbol{A}\\odot\\boldsymbol{B}) = \\text{Diag}(\\boldsymbol{A})\\text{Vec}(\\boldsymbol{B})，其中~\\text{Diag}(\\boldsymbol{A})~为对角化操作，即把~\\text{Vec}(\\boldsymbol{A})~中所有元素排成对角阵(除对角线外其余元素全为零)Vec(A⊙B)=Diag(A)Vec(B)，其中 Diag(A) 为对角化操作，即把 Vec(A) 中所有元素排成对角阵(除对角线外其余元素全为零) a⊙b=Vec(a⊙b)=Diag(a)b\\color{green}\\boldsymbol{a}\\odot\\boldsymbol{b}=\\text{Vec}(\\boldsymbol{a}\\odot\\boldsymbol{b})=\\text{Diag}(\\boldsymbol{a})\\boldsymbol{b}a⊙b=Vec(a⊙b)=Diag(a)b (A⊗B)⊤=A⊤⊗B⊤\\color{green}(\\boldsymbol{A}\\otimes\\boldsymbol{B})^\\top = \\boldsymbol{A}^\\top\\otimes\\boldsymbol{B}^\\top(A⊗B)⊤=A⊤⊗B⊤ (A⊗B)(C⊗D)=AC⊗BD\\color{green}(\\boldsymbol{A}\\otimes\\boldsymbol{B})(\\boldsymbol{C}\\otimes\\boldsymbol{D}) = \\boldsymbol{AC}\\otimes\\boldsymbol{BD}(A⊗B)(C⊗D)=AC⊗BD Proof: 构造函数 F=D⊤B⊤XAC=D⊤(B⊤XA)C\\boldsymbol{F}=\\boldsymbol{D}^\\top\\boldsymbol{B}^\\top\\boldsymbol{X}\\boldsymbol{A}\\boldsymbol{C}=\\boldsymbol{D}^\\top(\\boldsymbol{B}^\\top\\boldsymbol{X}\\boldsymbol{A})\\boldsymbol{C}F=D⊤B⊤XAC=D⊤(B⊤XA)C For F=D⊤B⊤XAC,Vec(dF)=Vec(D⊤B⊤dXAC)=[(AC)⊤⊗(D⊤B⊤)]Vec(dX)=[(AC)⊗(BD)]⊤Vec(dX)\\text{For~} \\boldsymbol{F}=\\boldsymbol{D}^\\top\\boldsymbol{B}^\\top\\boldsymbol{X}\\boldsymbol{A}\\boldsymbol{C}, \\text{Vec}(\\text{d}\\boldsymbol{F})=\\text{Vec}(\\boldsymbol{D}^\\top\\boldsymbol{B}^\\top\\text{d}\\boldsymbol{X}\\boldsymbol{A}\\boldsymbol{C})=\\left[(\\boldsymbol{AC})^\\top\\otimes(\\boldsymbol{D}^\\top\\boldsymbol{B}^\\top)\\right]\\text{Vec}(\\text{d}\\boldsymbol{X})=\\left[(\\boldsymbol{A}\\boldsymbol{C})\\otimes(\\boldsymbol{B}\\boldsymbol{D})\\right]^\\top\\text{Vec}(\\text{d}\\boldsymbol{X})For F=D⊤B⊤XAC,Vec(dF)=Vec(D⊤B⊤dXAC)=[(AC)⊤⊗(D⊤B⊤)]Vec(dX)=[(AC)⊗(BD)]⊤Vec(dX) For F=D⊤(B⊤XA)C,Vec(dF)=Vec[D⊤d(B⊤XA)C]=(C⊤⊗D⊤)Vec[d(B⊤XA)]=(C⊤⊗D⊤)Vec[B⊤dXA]\\text{For~} \\boldsymbol{F}=\\boldsymbol{D}^\\top(\\boldsymbol{B}^\\top\\boldsymbol{X}\\boldsymbol{A})\\boldsymbol{C}, \\text{Vec}(\\text{d}\\boldsymbol{F})=\\text{Vec}\\left[\\boldsymbol{D}^\\top\\text{d}(\\boldsymbol{B}^\\top\\boldsymbol{X}\\boldsymbol{A})\\boldsymbol{C}\\right]=(\\boldsymbol{C}^\\top\\otimes\\boldsymbol{D}^\\top)\\text{Vec}\\left[\\text{d}(\\boldsymbol{B}^\\top\\boldsymbol{X}\\boldsymbol{A})\\right]=(\\boldsymbol{C}^\\top\\otimes\\boldsymbol{D}^\\top)\\text{Vec}\\left[\\boldsymbol{B}^\\top\\text{d}\\boldsymbol{X}\\boldsymbol{A}\\right]For F=D⊤(B⊤XA)C,Vec(dF)=Vec[D⊤d(B⊤XA)C]=(C⊤⊗D⊤)Vec[d(B⊤XA)]=(C⊤⊗D⊤)Vec[B⊤dXA] =(C⊤⊗D⊤)(A⊤⊗B⊤)Vec(dX)=[(A⊗B)(C⊗D)]⊤Vec(dX)=(\\boldsymbol{C}^\\top\\otimes\\boldsymbol{D}^\\top)(\\boldsymbol{A}^\\top\\otimes\\boldsymbol{B}^\\top)\\text{Vec}(\\text{d}\\boldsymbol{X})=\\left[(\\boldsymbol{A}\\otimes\\boldsymbol{B})(\\boldsymbol{C}\\otimes\\boldsymbol{D})\\right]^\\top\\text{Vec}(\\text{d}\\boldsymbol{X})=(C⊤⊗D⊤)(A⊤⊗B⊤)Vec(dX)=[(A⊗B)(C⊗D)]⊤Vec(dX) Thus, dFdX=(AC)⊗(BD)=(A⊗B)(C⊗D)\\text{Thus,~}\\frac{\\text{d}\\boldsymbol{F}}{\\text{d}\\boldsymbol{X}}=(\\boldsymbol{A}\\boldsymbol{C})\\otimes(\\boldsymbol{B}\\boldsymbol{D})=(\\boldsymbol{A}\\otimes\\boldsymbol{B})(\\boldsymbol{C}\\otimes\\boldsymbol{D})Thus, dXdF​=(AC)⊗(BD)=(A⊗B)(C⊗D) 例 8. 构造函数 F=AX,X∈Rm×n\\boldsymbol{F} = \\boldsymbol{A}\\boldsymbol{X}, \\boldsymbol{X}\\in\\mathbb{R}^{m\\times n}F=AX,X∈Rm×n Process: Vec(dF)\\text{Vec}(\\text{d}\\boldsymbol{F})Vec(dF) =Vec(AdX)=\\text{Vec}(\\boldsymbol{A}\\text{d}\\boldsymbol{X})=Vec(AdX) =In⊗AVec(dX)=\\boldsymbol{I}_n\\otimes\\boldsymbol{A}\\text{Vec}(\\text{d}\\boldsymbol{X})=In​⊗AVec(dX) Answer: dFdX=In⊗A⊤\\frac{\\text{d}\\boldsymbol{F}}{\\text{d}\\boldsymbol{X}}=\\boldsymbol{I}_n\\otimes\\boldsymbol{A}^\\topdXdF​=In​⊗A⊤ 例 9. 构造函数 f=log∣X∣,X∈Rn×nf = \\text{log} |\\boldsymbol{X}|, \\boldsymbol{X}\\in\\mathbb{R}^{n\\times n}f=log∣X∣,X∈Rn×n，求二阶导（Hessian Matrix）. Process: df\\text{d} fdf $ = \\text{d}\\log|\\boldsymbol{X}|$ =1∣X∣d∣X∣=\\frac{1}{|\\boldsymbol{X}|}\\text{d}|\\boldsymbol{X}|=∣X∣1​d∣X∣ =1∣X∣∣X∣tr(X−1dX)=\\frac{1}{|\\boldsymbol{X}|}|\\boldsymbol{X}|\\text{tr}(\\boldsymbol{X}^{-1}\\text{d}\\boldsymbol{X})=∣X∣1​∣X∣tr(X−1dX) =tr(X−1dX)=\\text{tr}(\\boldsymbol{X}^{-1}\\text{d}\\boldsymbol{X})=tr(X−1dX) Hence, dfdX=Vec[(X−1)⊤], ∇Xf=(X−1)⊤=(X⊤)−1\\frac{\\text{d}f}{\\text{d}\\boldsymbol{X}}=\\text{Vec}\\left[(\\boldsymbol{X}^{-1})^\\top\\right],~\\nabla_{\\boldsymbol{X}} f = (\\boldsymbol{X}^{-1})^\\top=(\\boldsymbol{X}^\\top)^{-1}dXdf​=Vec[(X−1)⊤], ∇X​f=(X−1)⊤=(X⊤)−1 Vec(d∇Xf)\\text{Vec}(\\text{d}\\nabla_{\\boldsymbol{X}}f)Vec(d∇X​f) =−Vec[(X⊤)−1dX⊤(X⊤)−1]=-\\text{Vec}\\left[(\\boldsymbol{X}^\\top)^{-1}\\text{d}\\boldsymbol{X}^\\top(\\boldsymbol{X}^\\top)^{-1}\\right]=−Vec[(X⊤)−1dX⊤(X⊤)−1] =−X−1⊗(X−1)⊤Vec(dX⊤)= -\\boldsymbol{X}^{-1}\\otimes(\\boldsymbol{X}^{-1})^\\top\\text{Vec}(\\text{d}\\boldsymbol{X}^\\top)=−X−1⊗(X−1)⊤Vec(dX⊤) =−X−1⊗(X−1)⊤Kn,nVec(dX)= -\\boldsymbol{X}^{-1}\\otimes(\\boldsymbol{X}^{-1})^\\top\\boldsymbol{K}_{n,n}\\text{Vec}(\\text{d}\\boldsymbol{X})=−X−1⊗(X−1)⊤Kn,n​Vec(dX) Answer: ∇Xf=X−1⊤\\nabla_{\\boldsymbol{X}} f = {\\boldsymbol{X}^{-1}}^\\top∇X​f=X−1⊤ ∇X2f=−Kn,n(X−1)⊤⊗X−1\\nabla^2_{\\boldsymbol{X}} f = -\\boldsymbol{K}_{n,n}(\\boldsymbol{X}^{-1})^\\top\\otimes\\boldsymbol{X}^{-1}∇X2​f=−Kn,n​(X−1)⊤⊗X−1 例 10. 构造函数 F=AeXB,A∈Rl×m,X∈Rm×n,B∈Rn×p.\\boldsymbol{F} = \\boldsymbol{A}e^{\\boldsymbol{X}\\boldsymbol{B}}, \\boldsymbol{A}\\in\\mathbb{R}^{l\\times m}, \\boldsymbol{X}\\in\\mathbb{R}^{m\\times n}, \\boldsymbol{B}\\in\\mathbb{R}^{n\\times p}.F=AeXB,A∈Rl×m,X∈Rm×n,B∈Rn×p. Process: Vec(dF)\\text{Vec}(\\text{d}\\boldsymbol{F})Vec(dF) =Vec{A[eXB⊙(dXB)]}=\\text{Vec}\\left\\{\\boldsymbol{A}\\left[e^{\\boldsymbol{X}\\boldsymbol{B}}\\odot(\\text{d}\\boldsymbol{X}\\boldsymbol{B})\\right]\\right\\}=Vec{A[eXB⊙(dXB)]} =(Ip⊤⊗A)Vec[eXB⊙(dXB)]=(\\boldsymbol{I}_p^\\top\\otimes\\boldsymbol{A})\\text{Vec}\\left[e^{\\boldsymbol{X}\\boldsymbol{B}}\\odot(\\text{d}\\boldsymbol{X}\\boldsymbol{B})\\right]=(Ip⊤​⊗A)Vec[eXB⊙(dXB)] =(Ip⊗A)Diag(eXB)Vec(dXB)=(\\boldsymbol{I}_p\\otimes\\boldsymbol{A})\\text{Diag}(e^{\\boldsymbol{X}\\boldsymbol{B}})\\text{Vec}(\\text{d}\\boldsymbol{X}\\boldsymbol{B})=(Ip​⊗A)Diag(eXB)Vec(dXB) =(Ip⊗A)Diag(eXB)(B⊤⊗Im)Vec(dX)=(\\boldsymbol{I}_p\\otimes\\boldsymbol{A})\\text{Diag}(e^{\\boldsymbol{X}\\boldsymbol{B}})(\\boldsymbol{B}^\\top\\otimes\\boldsymbol{I}_m)\\text{Vec}(\\text{d}\\boldsymbol{X})=(Ip​⊗A)Diag(eXB)(B⊤⊗Im​)Vec(dX) Answer: dFdX=(B⊗Im)Diag(eXB)(Ip⊗A)\\frac{\\text{d}\\boldsymbol{F}}{\\text{d}\\boldsymbol{X}}=(\\boldsymbol{B}\\otimes\\boldsymbol{I}_m)\\text{Diag}(e^{\\boldsymbol{X}\\boldsymbol{B}})(\\boldsymbol{I}_p\\otimes\\boldsymbol{A})dXdF​=(B⊗Im​)Diag(eXB)(Ip​⊗A) 例 11. 一元 logistic 回归 ℓ=−yx⊤w+log⁡(1+ex⊤w)\\ell = -y\\boldsymbol{x}^\\top\\boldsymbol{w} + \\log(1 + e^{\\boldsymbol{x}^\\top\\boldsymbol{w}})ℓ=−yx⊤w+log(1+ex⊤w)，求∇wℓ\\nabla_{\\boldsymbol{w}}\\ell∇w​ℓ和∇w2ℓ\\nabla^2_{\\boldsymbol{w}}\\ell∇w2​ℓ，其中y∈0,1,x,w∈Rn×1y\\in{0,1}, \\boldsymbol{x},\\boldsymbol{w}\\in\\mathbb{R}^{n\\times 1}y∈0,1,x,w∈Rn×1. Process: $\\text{d} \\ell $ =−yx⊤dw+11+ex⊤w[ex⊤w⊙(x⊤dw)]= -y\\boldsymbol{x}^\\top\\text{d}\\boldsymbol{w}+\\frac{1}{1+e^{\\boldsymbol{x}^\\top\\boldsymbol{w}}}\\left[e^{\\boldsymbol{x}^\\top\\boldsymbol{w}}\\odot(\\boldsymbol{x}^\\top\\text{d}\\boldsymbol{w})\\right]=−yx⊤dw+1+ex⊤w1​[ex⊤w⊙(x⊤dw)] =−yx⊤dw+ex⊤w1+ex⊤w(x⊤dw)= -y\\boldsymbol{x}^\\top\\text{d}\\boldsymbol{w}+\\frac{e^{\\boldsymbol{x}^\\top\\boldsymbol{w}}}{1+e^{\\boldsymbol{x}^\\top\\boldsymbol{w}}}(\\boldsymbol{x}^\\top\\text{d}\\boldsymbol{w})=−yx⊤dw+1+ex⊤wex⊤w​(x⊤dw) =(ex⊤w1+ex⊤w−y)x⊤dw= (\\frac{e^{\\boldsymbol{x}^\\top\\boldsymbol{w}}}{1+e^{\\boldsymbol{x}^\\top\\boldsymbol{w}}}-y)\\boldsymbol{x}^\\top\\text{d}\\boldsymbol{w}=(1+ex⊤wex⊤w​−y)x⊤dw d∇wℓ\\text{d}\\nabla_{\\boldsymbol{w}}\\elld∇w​ℓ =xdex⊤w1+ex⊤w={\\color{red}\\boldsymbol{x}} \\text{d}\\frac{e^{\\boldsymbol{x}^\\top\\boldsymbol{w}}}{1+e^{\\boldsymbol{x}^\\top\\boldsymbol{w}}}=xd1+ex⊤wex⊤w​ =xex⊤w(1+ex⊤w)−e2x⊤w(1+ex⊤w)2x⊤dw=\\boldsymbol{x}\\frac{e^{\\boldsymbol{x}^\\top\\boldsymbol{w}}(1+e^{\\boldsymbol{x}^\\top\\boldsymbol{w}})-e^{2\\boldsymbol{x}^\\top\\boldsymbol{w}}}{(1+e^{\\boldsymbol{x}^\\top\\boldsymbol{w}})^2}\\boldsymbol{x}^\\top\\text{d}\\boldsymbol{w}=x(1+ex⊤w)2ex⊤w(1+ex⊤w)−e2x⊤w​x⊤dw =xex⊤w(1+ex⊤w)2x⊤dw=\\boldsymbol{x}\\frac{e^{\\boldsymbol{x}^\\top\\boldsymbol{w}}}{(1+e^{\\boldsymbol{x}^\\top\\boldsymbol{w}})^2}\\boldsymbol{x}^\\top\\text{d}\\boldsymbol{w}=x(1+ex⊤w)2ex⊤w​x⊤dw Answer: dℓdw=∇wℓ=(ex⊤w1+ex⊤w−y)x\\frac{\\text{d}\\ell}{\\text{d}\\boldsymbol{w}} = \\nabla_{\\boldsymbol{w}}\\ell = (\\frac{e^{\\boldsymbol{x}^\\top\\boldsymbol{w}}}{1+e^{\\boldsymbol{x}^\\top\\boldsymbol{w}}}-y)\\boldsymbol{x}dwdℓ​=∇w​ℓ=(1+ex⊤wex⊤w​−y)x ∇w2ℓ=xex⊤w(1+ex⊤w)2x⊤\\nabla^2_{\\boldsymbol{w}}\\ell=\\boldsymbol{x}\\frac{e^{\\boldsymbol{x}^\\top\\boldsymbol{w}}}{(1+e^{\\boldsymbol{x}^\\top\\boldsymbol{w}})^2}\\boldsymbol{x}^\\top∇w2​ℓ=x(1+ex⊤w)2ex⊤w​x⊤ 例 12. 带多重样本的一元 logistic 回归 针对包含多重样本的数据集 {(x1,y1),⋯ ,(xN,yN)}\\{(\\boldsymbol{x}_1, y_1),\\cdots,(\\boldsymbol{x}_N, y_N)\\}{(x1​,y1​),⋯,(xN​,yN​)}，ℓ=∑i=1N[−yixi⊤w+log⁡(1+exi⊤w)]\\ell = \\sum_{i=1}^N\\left[-y_i\\boldsymbol{x}_i^\\top\\boldsymbol{w}+\\log(1+e^{\\boldsymbol{x}_i^\\top\\boldsymbol{w}})\\right]ℓ=∑i=1N​[−yi​xi⊤​w+log(1+exi⊤​w)] Process No.1: The process of 例 11 Answer No.1: dℓdw=∇wℓ=∑i=1N(exi⊤w1+exi⊤w−yi)xi\\frac{\\text{d}\\ell}{\\text{d}\\boldsymbol{w}} = \\nabla_{\\boldsymbol{w}}\\ell = \\sum_{i=1}^N(\\frac{e^{\\boldsymbol{x}_i^\\top\\boldsymbol{w}}}{1+e^{\\boldsymbol{x}_i^\\top\\boldsymbol{w}}}-y_i)\\boldsymbol{x}_idwdℓ​=∇w​ℓ=∑i=1N​(1+exi⊤​wexi⊤​w​−yi​)xi​ ∇w2ℓ=∑i=1Nxiexi⊤w(1+exi⊤w)2xi⊤\\nabla^2_{\\boldsymbol{w}}\\ell=\\sum_{i=1}^N\\boldsymbol{x}_i\\frac{e^{\\boldsymbol{x}_i^\\top\\boldsymbol{w}}}{(1+e^{\\boldsymbol{x}_i^\\top\\boldsymbol{w}})^2}\\boldsymbol{x}_i^\\top∇w2​ℓ=∑i=1N​xi​(1+exi⊤​w)2exi⊤​w​xi⊤​ Process No. 2: X=[x1⊤⋮xN⊤],y=[y1⋮yN],ℓ=−y⊤Xw+1⊤log⁡(1+eXw)\\boldsymbol{X}=\\begin{bmatrix}\\boldsymbol{x}_1^\\top\\\\\\vdots\\\\\\boldsymbol{x}_N^\\top\\end{bmatrix}, \\boldsymbol{y}=\\begin{bmatrix}y_1\\\\\\vdots\\\\y_N\\end{bmatrix},\\ell=-\\boldsymbol{y}^\\top\\boldsymbol{X}\\boldsymbol{w}+\\boldsymbol{1}^\\top\\log(\\boldsymbol{1}+e^{\\boldsymbol{X}\\boldsymbol{w}})X=⎣⎢⎢⎡​x1⊤​⋮xN⊤​​⎦⎥⎥⎤​,y=⎣⎢⎢⎡​y1​⋮yN​​⎦⎥⎥⎤​,ℓ=−y⊤Xw+1⊤log(1+eXw) dℓ\\text{d}\\elldℓ =−y⊤Xdw+1⊤[eXx1+eX⊤w⊙(Xdw)]=-\\boldsymbol{y}^\\top\\boldsymbol{X}\\text{d}\\boldsymbol{w}+\\boldsymbol{1}^\\top\\left[\\frac{e^{\\boldsymbol{X}\\boldsymbol{x}}}{\\boldsymbol{1}+e^{\\boldsymbol{X}^\\top\\boldsymbol{w}}}\\odot(\\boldsymbol{X}\\text{d}\\boldsymbol{w})\\right]=−y⊤Xdw+1⊤[1+eX⊤weXx​⊙(Xdw)] =−y⊤Xdw+(1⊙eXx1+eX⊤w)⊤(Xdw)=-\\boldsymbol{y}^\\top\\boldsymbol{X}\\text{d}\\boldsymbol{w}+(\\boldsymbol{1}\\odot\\frac{e^{\\boldsymbol{X}\\boldsymbol{x}}}{\\boldsymbol{1}+e^{\\boldsymbol{X}^\\top\\boldsymbol{w}}})^\\top(\\boldsymbol{X}\\text{d}\\boldsymbol{w})=−y⊤Xdw+(1⊙1+eX⊤weXx​)⊤(Xdw) =(eXw1+eXw−y)⊤Xdw=\\left(\\frac{e^{\\boldsymbol{X}\\boldsymbol{w}}}{\\boldsymbol{1}+e^{\\boldsymbol{X}\\boldsymbol{w}}}-\\boldsymbol{y}\\right)^\\top\\boldsymbol{X}\\text{d}\\boldsymbol{w}=(1+eXweXw​−y)⊤Xdw d∇wℓ\\text{d}\\nabla_{\\boldsymbol{w}}\\elld∇w​ℓ =X⊤[eXw(1+eXw)2⊙(Xdw)]=\\boldsymbol{X}^\\top\\left[\\frac{e^{\\boldsymbol{X}\\boldsymbol{w}}}{(\\boldsymbol{1}+e^{\\boldsymbol{X}\\boldsymbol{w}})^2}\\odot(\\boldsymbol{X}\\text{d}\\boldsymbol{w})\\right]=X⊤[(1+eXw)2eXw​⊙(Xdw)] =X⊤Diag[eXw(1+eXw)2]Xdw=\\boldsymbol{X}^\\top\\text{Diag}\\left[\\frac{e^{\\boldsymbol{X}\\boldsymbol{w}}}{(\\boldsymbol{1}+e^{\\boldsymbol{X}\\boldsymbol{w}})^2}\\right]\\boldsymbol{X}\\text{d}\\boldsymbol{w}=X⊤Diag[(1+eXw)2eXw​]Xdw Answer No.2: ∇wℓ=X⊤(eXw1+eXw−y)\\nabla_{\\boldsymbol{w}}\\ell = \\boldsymbol{X}^\\top(\\frac{e^{\\boldsymbol{X}\\boldsymbol{w}}}{\\boldsymbol{1}+e^{\\boldsymbol{X}\\boldsymbol{w}}}-\\boldsymbol{y})∇w​ℓ=X⊤(1+eXweXw​−y) ∇w2ℓ=X⊤Diag[eXw(1+eXw)2]X\\nabla_{\\boldsymbol{w}}^2\\ell=\\boldsymbol{X}^\\top\\text{Diag}\\left[\\frac{e^{\\boldsymbol{X}\\boldsymbol{w}}}{(\\boldsymbol{1}+e^{\\boldsymbol{X}\\boldsymbol{w}})^2}\\right]\\boldsymbol{X}∇w2​ℓ=X⊤Diag[(1+eXw)2eXw​]X 例 13. 多元 logistic 回归 ℓ=−y⊤log softmax(Wx)=−y⊤Wx+log(1⊤eWx)\\ell = -\\boldsymbol{y}^\\top\\text{log~softmax}(\\boldsymbol{W}\\boldsymbol{x}) = -\\boldsymbol{y}^\\top\\boldsymbol{W}\\boldsymbol{x} + \\text{log}(\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}})ℓ=−y⊤log softmax(Wx)=−y⊤Wx+log(1⊤eWx)，求∇wl\\nabla_{\\boldsymbol{w}}l∇w​l和∇w2l\\nabla^2_{\\boldsymbol{w}}l∇w2​l，其中y∈Rmy\\in\\mathbb{R}^{m}y∈Rm且为 one-hot 编码, x∈Rn,W∈Rm×n\\boldsymbol{x}\\in\\mathbb{R}^{n}, \\boldsymbol{W}\\in\\mathbb{R}^{m\\times n}x∈Rn,W∈Rm×n. Process: dℓ\\text{d}\\elldℓ =−tr(y⊤dWx)+11⊤eWx⊙d(1⊤eWx)=-\\text{tr}(\\boldsymbol{y}^\\top\\text{d}\\boldsymbol{W}\\boldsymbol{x})+\\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}}\\odot\\text{d}(\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}})=−tr(y⊤dWx)+1⊤eWx1​⊙d(1⊤eWx) =−tr(y⊤dWx)+11⊤eWx1⊤[eWx⊙(dWx)]=-\\text{tr}(\\boldsymbol{y}^\\top\\text{d}\\boldsymbol{W}\\boldsymbol{x})+\\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}}\\boldsymbol{1}^\\top\\left[e^{\\boldsymbol{W}\\boldsymbol{x}}\\odot(\\text{d} \\boldsymbol{W}\\boldsymbol{x})\\right]=−tr(y⊤dWx)+1⊤eWx1​1⊤[eWx⊙(dWx)] =−tr(y⊤dWx)+tr[(eWx1⊤eWx)⊤(dWx)]=-\\text{tr}(\\boldsymbol{y}^\\top\\text{d}\\boldsymbol{W}\\boldsymbol{x})+\\text{tr}\\left[(\\frac{e^{\\boldsymbol{W}\\boldsymbol{x}}}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}})^\\top(\\text{d} \\boldsymbol{W}\\boldsymbol{x})\\right]=−tr(y⊤dWx)+tr[(1⊤eWxeWx​)⊤(dWx)] =tr[[x(eWx1⊤eWx)⊤−xy⊤]dW]=\\text{tr}\\left[[\\boldsymbol{x}(\\frac{e^{\\boldsymbol{W}\\boldsymbol{x}}}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}})^\\top - \\boldsymbol{x}\\boldsymbol{y}^\\top]\\text{d} \\boldsymbol{W}\\right]=tr[[x(1⊤eWxeWx​)⊤−xy⊤]dW] d∇Wℓ\\text{d}\\nabla_{\\boldsymbol{W}}\\elld∇W​ℓ =deWx1⊤eWxx⊤=\\text{d} \\frac{e^{\\boldsymbol{W}\\boldsymbol{x}}}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}} \\boldsymbol{x}^\\top=d1⊤eWxeWx​x⊤ =[d(eWx)1⊤eWx−eWx1⊤d(eWx)(1⊤eWx)2]x⊤=\\left[\\frac{\\text{d}(e^{\\boldsymbol{W}\\boldsymbol{x}})}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}} - \\frac{ {\\color{red}e^{\\boldsymbol{W}\\boldsymbol{x}}}\\boldsymbol{1}^\\top\\text{d}(e^{\\boldsymbol{W}\\boldsymbol{x}})}{(\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}})^2}\\right]\\boldsymbol{x}^\\top=[1⊤eWxd(eWx)​−(1⊤eWx)2eWx1⊤d(eWx)​]x⊤ =[eWx⊙(dWx)1⊤eWx−eWx1⊤[eWx⊙(dWx)](1⊤eWx)2]x⊤=\\left[\\frac{e^{\\boldsymbol{W}\\boldsymbol{x}}\\odot(\\text{d}\\boldsymbol{W}\\boldsymbol{x})}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}} - \\frac{e^{\\boldsymbol{W}\\boldsymbol{x}}\\boldsymbol{1}^\\top[e^{\\boldsymbol{W}\\boldsymbol{x}}\\odot(\\text{d}\\boldsymbol{W}\\boldsymbol{x})]}{(\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}})^2}\\right]\\boldsymbol{x}^\\top=[1⊤eWxeWx⊙(dWx)​−(1⊤eWx)2eWx1⊤[eWx⊙(dWx)]​]x⊤ =[Diag(eWx)(dWx)1⊤eWx−eWx1⊤Diag(eWx)(dWx)(1⊤eWx)2]x⊤=\\left[\\frac{\\text{Diag}(e^{\\boldsymbol{W}\\boldsymbol{x}})(\\text{d}\\boldsymbol{W}\\boldsymbol{x})}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}}-\\frac{e^{\\boldsymbol{W}\\boldsymbol{x}}\\boldsymbol{1}^\\top\\text{Diag}(e^{\\boldsymbol{W}\\boldsymbol{x}})(\\text{d}\\boldsymbol{W}\\boldsymbol{x})}{(\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}})^2}\\right]\\boldsymbol{x}^\\top=[1⊤eWxDiag(eWx)(dWx)​−(1⊤eWx)2eWx1⊤Diag(eWx)(dWx)​]x⊤ =[Diag(eWx)(dWx)1⊤eWx−eWx(eWx)⊤(dWx)(1⊤eWx)2]x⊤=\\left[\\frac{\\text{Diag}(e^{\\boldsymbol{W}\\boldsymbol{x}})(\\text{d}\\boldsymbol{W}\\boldsymbol{x})}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}} - \\frac{e^{\\boldsymbol{W}\\boldsymbol{x}}(e^{\\boldsymbol{W}\\boldsymbol{x}})^\\top(\\text{d}\\boldsymbol{W}\\boldsymbol{x})}{(\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}})^2}\\right]\\boldsymbol{x}^\\top=[1⊤eWxDiag(eWx)(dWx)​−(1⊤eWx)2eWx(eWx)⊤(dWx)​]x⊤ =Diag(eWx)(dW)xx⊤1⊤eWx−eWx(eWx)⊤(dW)xx⊤(1⊤eWx)2=\\frac{\\text{Diag}(e^{\\boldsymbol{W}\\boldsymbol{x}})(\\text{d}\\boldsymbol{W})\\boldsymbol{x}\\boldsymbol{x}^\\top}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}} - \\frac{e^{\\boldsymbol{W}\\boldsymbol{x}}(e^{\\boldsymbol{W}\\boldsymbol{x}})^\\top(\\text{d}\\boldsymbol{W})\\boldsymbol{x}\\boldsymbol{x}^\\top}{(\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}})^2}=1⊤eWxDiag(eWx)(dW)xx⊤​−(1⊤eWx)2eWx(eWx)⊤(dW)xx⊤​ Vec(d∇Wℓ)\\text{Vec}(\\text{d}\\nabla_{\\boldsymbol{W}}\\ell)Vec(d∇W​ℓ) =xx⊤⊗[Diag[softmax(Wx)]−softmax(Wx)softmax(Wx)⊤]Vec(dW)=\\boldsymbol{x}\\boldsymbol{x}^\\top\\otimes\\left[\\text{Diag}[\\text{softmax}(\\boldsymbol{W}\\boldsymbol{x})]-\\text{softmax}(\\boldsymbol{W}\\boldsymbol{x})\\text{softmax}(\\boldsymbol{W}\\boldsymbol{x})^\\top\\right]\\text{Vec}(\\text{d}\\boldsymbol{W})=xx⊤⊗[Diag[softmax(Wx)]−softmax(Wx)softmax(Wx)⊤]Vec(dW) Answer: ∇Wℓ=[eWx1⊤eWx−y]x⊤\\nabla_{\\boldsymbol{W}}\\ell=\\left[\\frac{e^{\\boldsymbol{W}\\boldsymbol{x}}}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}} - \\boldsymbol{y}\\right]\\boldsymbol{x}^\\top∇W​ℓ=[1⊤eWxeWx​−y]x⊤ ∇W2ℓ=xx⊤⊗[Diag[softmax(Wx)]−softmax(Wx)softmax(Wx)⊤]\\nabla_{\\boldsymbol{W}}^2\\ell=\\boldsymbol{x}\\boldsymbol{x}^\\top\\otimes\\left[\\text{Diag}[\\text{softmax}(\\boldsymbol{W}\\boldsymbol{x})]-\\text{softmax}(\\boldsymbol{W}\\boldsymbol{x})\\text{softmax}(\\boldsymbol{W}\\boldsymbol{x})^\\top\\right]∇W2​ℓ=xx⊤⊗[Diag[softmax(Wx)]−softmax(Wx)softmax(Wx)⊤] 写在最后： 注意例 4 和 5 中红色标注部分，不含微分对象的变量尽量左移可以给微分求解过程去除不必要的麻烦。 本文为参考文献所涉及的两篇博客的吸收消化理解精炼，仅供学习参考使用。 Reference [1] 矩阵求导术（上） - 长躯鬼侠的文章 - 知乎 https://zhuanlan.zhihu.com/p/24709748 [2] 矩阵求导术（下） - 长躯鬼侠的文章 - 知乎 https://zhuanlan.zhihu.com/p/24863977","categories":[{"name":"MachineLearning","slug":"MachineLearning","permalink":"https://junfish.github.io/categories/MachineLearning/"}],"tags":[{"name":"Matrix","slug":"Matrix","permalink":"https://junfish.github.io/tags/Matrix/"},{"name":"Calculus","slug":"Calculus","permalink":"https://junfish.github.io/tags/Calculus/"},{"name":"derivative","slug":"derivative","permalink":"https://junfish.github.io/tags/derivative/"}]},{"title":"Markdown Grammer Cheat Sheet","slug":"common-markdown-commands","date":"2022-08-04T03:58:37.000Z","updated":"2022-08-04T06:57:14.000Z","comments":true,"path":"2022/08/03/common-markdown-commands/","link":"","permalink":"https://junfish.github.io/2022/08/03/common-markdown-commands/","excerpt":"","text":"Description syntax Result H1 Title # H1 Title H1 Title H2 Title ## H2 Title H2 Title ... ... ... H5 Title ##### H5 Title H5 Title H6 Title ###### H6 Title H6 Title Bold Text **Bold Text** Bold Text Italic Text *Italic Text* Italic Text Bold and Italic Text **_Bold and Italic Text_** Italic Text Strike-Through Text ~~Strike-Through Text~~ Strike-Through Text Ordered List 1. First point2. Second point3. Third point First point Second point Third point Bullet Point - Bullet Point 1 &ensp; - Indented Point 1.1 &ensp; - Indented Point 1.2 &ensp;&ensp; - Indented Point 1.2.1 &ensp;&ensp;&ensp; - Indented Point 1.2.1.1 &ensp;&ensp;&ensp; - ... - Bullet Point 2 - Bullet Point 3 Bullet Point 1 Indented Point 1.1 Indented Point 1.2 Indented Point 1.2.1 Indented Point 1.2.1.1 … Bullet Point 2 Bullet Point 3 Inline Code `Inline Code` Inline Code Horizontal Rules --- or *** Link [junfish](https://junfish.github.io/) junfish Picture ![example](https://junfish.github.io/photos/images/DSCF0611.jpg) Continuing…","categories":[],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"https://junfish.github.io/tags/Markdown/"},{"name":"Cheatsheet","slug":"Cheatsheet","permalink":"https://junfish.github.io/tags/Cheatsheet/"}]},{"title":"Cheat Sheet of Counting Files or Folders","slug":"counting-files-or-folders","date":"2022-06-18T20:30:55.000Z","updated":"2022-06-18T23:09:55.000Z","comments":true,"path":"2022/06/18/counting-files-or-folders/","link":"","permalink":"https://junfish.github.io/2022/06/18/counting-files-or-folders/","excerpt":"","text":"显示当前文件夹下所有文件 1ls -l | grep &quot;^-&quot; 统计当前文件夹下文件个数 1ls -l ./|grep &quot;^-&quot;|wc -l 统计当前文件夹下文件夹个数 1ls -l ./|grep &quot;^d&quot;|wc -l 递归统计当前文件夹下所有文件个数 1ls -lR | grep &quot;^-&quot;| wc -l 递归统计当前文件夹下所有文件夹个数 1ls -lR | grep &quot;^d&quot;| wc -l","categories":[{"name":"Cheatsheet","slug":"Cheatsheet","permalink":"https://junfish.github.io/categories/Cheatsheet/"}],"tags":[{"name":"commands","slug":"commands","permalink":"https://junfish.github.io/tags/commands/"},{"name":"linux","slug":"linux","permalink":"https://junfish.github.io/tags/linux/"}]},{"title":"Conda Cheat Sheet","slug":"common-conda-commands","date":"2022-05-25T06:17:45.000Z","updated":"2022-06-09T20:47:42.000Z","comments":true,"path":"2022/05/25/common-conda-commands/","link":"","permalink":"https://junfish.github.io/2022/05/25/common-conda-commands/","excerpt":"","text":"新建虚拟环境 12conda create --name my_env_name [python=3.9] # Create the environment from scratchconda env create -f environment.yml # Create the environment from the environment.yml file 列出所有虚拟环境 1conda env list 激活虚拟环境 1conda activate my_env_name 查看虚拟环境内安装包 12conda list -n my_env_name # deactivatedconda list # activated 导出虚拟环境 1conda env export &gt; environment.yml 重建虚拟环境 1conda env create -f environment.yml","categories":[{"name":"Cheatsheet","slug":"Cheatsheet","permalink":"https://junfish.github.io/categories/Cheatsheet/"}],"tags":[{"name":"conda","slug":"conda","permalink":"https://junfish.github.io/tags/conda/"},{"name":"python","slug":"python","permalink":"https://junfish.github.io/tags/python/"},{"name":"virtual environment","slug":"virtual-environment","permalink":"https://junfish.github.io/tags/virtual-environment/"},{"name":"commands","slug":"commands","permalink":"https://junfish.github.io/tags/commands/"}]},{"title":"Tmux Cheat Sheet","slug":"common-tmux-commands","date":"2022-05-24T23:31:35.000Z","updated":"2022-09-28T19:07:58.000Z","comments":true,"path":"2022/05/24/common-tmux-commands/","link":"","permalink":"https://junfish.github.io/2022/05/24/common-tmux-commands/","excerpt":"","text":"Structure Command Start a new session 12tmux new -s &lt;session_name&gt;tmux # 按照 0, 1, 2, ··· 编号 Rename a session 1tmux rename-session -t &lt;target_session_name&gt; &lt;session_new_name&gt; Detach the current session 1tmux detach Show all current sessions 1tmux ls Attach a session 1tmux attach -t &lt;session_name&gt; Kill a session 123tmux kill-session -t &lt;session_name&gt; # kill the specific sessiontmux kill-session -a # kill all sessions but the currenttmux kill-session -a -t &lt;session_name&gt; # kill all sessions but the &lt;session_name&gt; Switch between two sessions 1tmux switch -t &lt;session_name&gt; # switch to the &lt;session_name&gt; Create a new window 1tmux new-window -n &lt;window_name&gt; # create a new window named window_name Select a window 1tmux select-window -t &lt;window_name/window_number&gt; # swap to a specific window Rename a window 1tmux rename-window &lt;new_name&gt; # rename the current window Split a window into two panes 12tmux split-window # divide the window into two top and bottom panestmux split-window -h # divide the window into two left and right panes Move cursor 1tmux select-pane -U/-D/-L/-R # move the cursor to the top/bottom/left/right pane Swap two panes 1tmux swap-pane -U/-D # move the current pane to the top/bottom Reference [1] Tmux 快捷键 &amp; 速查表 &amp; 简明教程 [2] Tmux Cheat Sheet &amp; Quick Reference .markmap-container{display:flex;justify-content:center;margin:0 auto;width:90%;height:500px}.markmap-container svg{width:100%;height:100%}@media(max-width:768px){.markmap-container{height:400px}} document.querySelectorAll('.markmap-container>svg').forEach(mindmap => markmap.Markmap.create(mindmap, null, JSON.parse(mindmap.getAttribute('data'))))","categories":[{"name":"Cheatsheet","slug":"Cheatsheet","permalink":"https://junfish.github.io/categories/Cheatsheet/"}],"tags":[{"name":"Tmux","slug":"Tmux","permalink":"https://junfish.github.io/tags/Tmux/"},{"name":"Linux","slug":"Linux","permalink":"https://junfish.github.io/tags/Linux/"},{"name":"SSH","slug":"SSH","permalink":"https://junfish.github.io/tags/SSH/"}]},{"title":"hexo 中常见错误及其解决方案","slug":"regular-errors-happened-in-hexo","date":"2022-03-27T04:57:40.000Z","updated":"2023-10-27T01:24:16.174Z","comments":true,"path":"2022/03/27/regular-errors-happened-in-hexo/","link":"","permalink":"https://junfish.github.io/2022/03/27/regular-errors-happened-in-hexo/","excerpt":"","text":"menu.Page_Name 问题 众所周知，hexo new page &quot;Page_Name&quot; 可以方便快捷地在 hexo 中创建新页面，但是当我们通过如下方法将新页面添加到主页面的 menu 中时， 123打开 ./MyBlog/themes/pure/_config.yml添加 menu: Page_Name: Page_Name 然而，主页的新增页面却会出现 menu.Page_Name 的情况，这时候我们只需要找到 ./MyBlog/_config.yml 配置文件，检查 language: 字段所指向的文件。例如，我是用默认的英文语言，language: 字段指向的文件为空。这时，我们去到 ./MyBlog/themes/pure/languages/* 文件夹下找到所指向的language 配置文件 default.yml，然后按照其他案例对比添加新增页面的指向即可。 自定义 icon-font 利用网站 https://www.iconfont.cn/ 新建自己的 icon 图标项目（方便后续添加新的 icon），然后在网站中添加自己喜欢的图标到项目中（每个图标在添加项目后仍可编辑）。例如我新建的 hexo 项目如下左图所示： 接着，单击页面顶部右 2 的项目设置按钮，做出如上右图所示的项目设置（需要勾选 Base64 ）。 最后，我们 download 项目至 ./MyBlog/themes/pure/source/fonts/，打开 iconfont.css 并 copy 其中代码覆盖 ./MyBlog/themes/pure/source/css/style.css 中对应部分代码。同时，覆盖 ./MyBlog/themes/pure/source/fonts/ 下四个文件名为 iconfont 的文件。 这时，我们测试修改 ./MyBlog/themes/pure/_config.yml 中关键字如下： 12345678910111213menu_icons: enable: true # 是否启用导航菜单图标 home: icon-home archives: icon-archives categories: icon-folder tags: icon-tags publications: icon-papers repository: icon-code_lib books: icon-books movies: icon-movies travels: icon-plane_departure links: icon-links about: icon-aboutme 可以发现，小破站的 menu 图标均已变成我们自己项目中的内容了： git commit 无法回滚问题 删除 .deploy_git 文件并尝试重新提交（hexo g -d）","categories":[{"name":"站点建设","slug":"站点建设","permalink":"https://junfish.github.io/categories/%E7%AB%99%E7%82%B9%E5%BB%BA%E8%AE%BE/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://junfish.github.io/tags/hexo/"}]},{"title":"Hello World","slug":"hello-world","date":"2022-03-25T21:48:51.000Z","updated":"2022-03-25T21:48:51.000Z","comments":true,"path":"2022/03/25/hello-world/","link":"","permalink":"https://junfish.github.io/2022/03/25/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post 1$ hexo new &quot;My New Post&quot; More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment // 基于准备好的dom，初始化echarts实例 var myChart = echarts.init(document.getElementById('echarts9592')); // 指定图表的配置项和数据 var option = { title: { text: 'Stacked Line' }, tooltip: { trigger: 'axis' }, legend: { data: ['Email', 'Union Ads', 'Video Ads', 'Direct', 'Search Engine'] }, grid: { left: '3%', right: '4%', bottom: '3%', containLabel: true }, toolbox: { feature: { saveAsImage: {} } }, xAxis: { type: 'category', boundaryGap: false, data: ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'] }, yAxis: { type: 'value' }, series: [ { name: 'Email', type: 'line', stack: 'Total', data: [120, 132, 101, 134, 90, 230, 210] }, { name: 'Union Ads', type: 'line', stack: 'Total', data: [220, 182, 191, 234, 290, 330, 310] }, { name: 'Video Ads', type: 'line', stack: 'Total', data: [150, 232, 201, 154, 190, 330, 410] }, { name: 'Direct', type: 'line', stack: 'Total', data: [320, 332, 301, 334, 390, 330, 320] }, { name: 'Search Engine', type: 'line', stack: 'Total', data: [820, 932, 901, 934, 1290, 1330, 1320] } ] }; // 使用刚指定的配置项和数据显示图表。 myChart.setOption(option);","categories":[],"tags":[]},{"title":"Terminology in Billiards","slug":"terminology-in-billiards","date":"2021-10-02T23:11:56.000Z","updated":"2022-04-23T18:22:17.000Z","comments":true,"path":"2021/10/02/terminology-in-billiards/","link":"","permalink":"https://junfish.github.io/2021/10/02/terminology-in-billiards/","excerpt":"","text":"写在前面 这周末和朋友约了场台球，因为台球桌是在 apartment 住处自带的 club 里面，所以并不是每次去都是空闲的。我们这次去的时候运气非常不好的成了替补球员。难受啊马飞~！几个 Indian guys 已经在玩了，怎么办呢？我们就看着他们打，只要我不尴尬，尴尬的就是他们，就等你们邀请我们加入，哈哈。果不其然，他们来了句：Do you wanna join us? 正中心机 boy 下怀，嘿嘿。 但是这种 social activity 很难免的需要交流，我就发现在台球运动上的术语储备太匮乏了，只能尬吹 “great shot”, 所以回来赶紧整理了一下台球相关的术语，有备无患。 鉴于斯诺克的国际赛事每年都很多，相关的术语永远可以找到相应的资料和解说视频可以学习，我们就聚焦于更大众化的十六彩（黑八）。 Terminology 最开始的当然是开球咯，经常看球赛的朋友脑海里一定开始环绕 “Ding Junhui to break.” 没错，就是 break，当然使用 start 或者 begin 之类的也是可以达意的，无伤大雅。 黑八的玩法无论规则如何，无法避免谈及的就是花色与全色。全色球是 solid ball，花色球是 stripe ball。 器具类： billiards: 台球（总称）。但其实我发现老美不太喜欢复杂的术语，你说 billiards 不一定有人懂，但是你说 pool 他们基本都知道。如何在酒吧优雅的回答 “Do you wanna play some pool?” “Sry, I can’t swim.” 化身全场最闪亮的仔。 table: 球台 cushion: 库边，也是我们常说的“颗星”的音译 chalk: 巧克 powder: 滑石粉。为什么这种严重影响手感的玩意会有人用。简直和拿 magic mouse 玩游戏差不多体验。 cue ball: 母球 object ball: 目标球 rest: 架杆 extension: 加长杆 cue (stick): 球杆 tip: 杆头 joint: 非通杆的连接处 triangle: 摆球的三角架 pocket: 球袋 top pocket middle pocket bottom pocket lampshade: 灯罩。至于为啥需要这个词，因为你永远会遇到用球杆捅灯的女孩，画面感是不是有了？ 状态类： ball in hand: 自由球。根据我查的资料其实不是 free ball，free ball 似乎已经成了斯诺克的一个专有名词。 foul: 犯规 snooker: 被遮挡，障碍球。动词化用法也是挺常见的，snookered touching ball: 贴球 frozen: 贴库或咬死的状态 lawed ball: 袋口挤住的球 nominated ball/called ball: 指定球 called pocket: 指定袋 tie: 平局。耳边回荡起马龙的灵魂质问“ tie 什么 tie?” forced off the table: 击球出界。像我这种猛男， dictionary 里必须常备这种短语 杆法类： combination: 传球 bank shot: 翻袋。因为 bank 也可以用来表示库边。 draw shot: 低杆。新手装逼必备杆法。 back spin: 下旋 stop shot: 定杆 stun: 斯登。高手最朴实无华的杆法，却尽显深厚内功，懂的自然懂，好吧。重剑无锋。 follow shot: 高杆 top spin: 上旋 side spin: 加塞旋转 push stroke: 推杆 double hit: 连击。touching ball 处理不当极易由 push stroke 导致这种犯规。 double kiss: 双击。处理库边的 frozen ball 经常出现的情况，不是犯规，而是击球分离角度计算失误造成的。 english/side spin: 弧线球。其实打大球想要出弧线的效果基本只能是扎杆（prick stroke）了。 fluke: 运气球 kick shot: 勾球。和 snooker 是黄金搭档哦😯 jump shot: 跳球。个人认为最应该从规则里剔除的杆法，伤台伤球，又有失优雅。正经人谁跳球啊，你跳球么？我反正不跳。跳起来的球能叫台球么？下贱！ scratch: 摔袋。黑八的噩梦。。。 positioning: 走位 miscue: 滑杆。什么？你说滑杆不是杆法，丁主任比赛看全了吗？ thick cut: 厚切 thin cut 薄切 feather shot: 薄球 ​","categories":[{"name":"Recreation","slug":"Recreation","permalink":"https://junfish.github.io/categories/Recreation/"}],"tags":[{"name":"billiards","slug":"billiards","permalink":"https://junfish.github.io/tags/billiards/"},{"name":"terminology","slug":"terminology","permalink":"https://junfish.github.io/tags/terminology/"}]},{"title":"Practice in Professional Email Writing","slug":"practice-in-email-writing","date":"2021-09-15T22:53:54.000Z","updated":"2022-05-25T17:52:18.000Z","comments":true,"path":"2021/09/15/practice-in-email-writing/","link":"","permalink":"https://junfish.github.io/2021/09/15/practice-in-email-writing/","excerpt":"","text":"Ending &amp; beginning of an email The safe expression in order of formality: Nothing →\\rightarrow→ Thanks →\\rightarrow→ Thank you →\\rightarrow→ Many Thanks →\\rightarrow→ Kind regards →\\rightarrow→ Best regards →\\rightarrow→ Sincerely →\\rightarrow→ Yours SIncerely. “sincerely” can be only used when you know the name of the specific person. The safest expression in any situation to anyone is “Best”. The safe expression of the beginning: Dear __ or Hi __. Don’t use “Dear” if the recipient responds you starting with a “Hi”. Otherwise, it seems a little bit weird and even cold. “Dear” is more formal than “Hi”. Body of the text Start positive and friendly with some basic background information and the reason why you’re writing. Get to the point directly, in the first paragraph or the first sentence, if possible. Give extra details if the recipients are not familiar with the topic. Use bullet points to organize your thoughts and logistics. Keep sentences relatively short: 505050 ≤\\le≤ Total Word Number ≤\\le≤ 150150150; Sentence ≤20\\le20≤20 words; Paragragh ≤7\\le7≤7 sentences (444 or 555 lines). Keep the total length could be viewed entirely under the popular screen size. Don’t be too direct with the British person. It may not be a massive problem, but it’s still important to be polite to anyone in a senior position to you. More hedging expressions can avoid a rude impression about yourself: I was wondering if + modal verb + please + reason: I was just wondering if you might be able to (be possible for you to do ···) ··· so that I can start working on the next step ···. Could you please help me to ···？ Please can you not make me do ···？ I was thinking of doing ···. What do you think? Avoide using “I’ve decided to ···” especially you’re lower down in your working place. Will →change to\\xrightarrow{change\\ to}change to​ Would. (Not always work) Do you think it would be okay to ···? Tell the recipients what they should do after this email. Please let me know if you have any questions. Looking forward to hearing from you soon. Please feel free to contact me. Attachment Be sure to mention clearly and explicitly any attached files. Give more details for the name of your attached files, such as Lehigh_Jun_Yu_Resume.pdf. Psychology-backed tactics Start strong for the subject line and keep it short, using clear and descriptive words. Length: Keep it short, roughly 141414 words. Consider the key point. Clarity: don’t be too vague of the chosen keywords. Consider the better experience of searching and filtering. If you want to convince someone, state the benefits they will get. Give reasons when ask someone to do something. The magic of the word “because” is resulting in more compliance. Recall the action you are requesting again in the last sentence of the first introduction paragraph. Use positive words, but do not over do it. Actually, for the tendency of response, a neutral tone ≤\\le≤ a slightly positive tone ≤\\le≤ a slightly positive tone. Positive words: yes, possible, together, please, ··· Negative words: never, impossible, without, stuck, ··· Use memory tricks in your information statements. Limit lists to 333 items maximum to avoid the difficulties of recalling. Use Familiar-New information flow to make reader absorb information more easily. Always say “Thank you”. Showing appreciation triggers more helpful behavior. More you, less me. In addition, more us, less me. The reason behind it is that we all care more about ourselves. Humans are social animals. They are more likely to provide help if they feel in the same situation with you. Use the recipient’s name and show some emotion and visual language. Emotional words: glad, appreciate, understand, happy, discover, ··· Visual language: see, clear, looks good, visualize, realize, bright, pattern, thin, ··· Tip: Read your writing email loud out before hit the “send” button. Express, not impress. Be concise and clear. Informal, plain English is totally fine; it’s better than poetry language. Use familiar words nad avoid complicated words. More verbs than nouns. Avoid reduntant words. Don’t oversimplify. Avoid too much abbreviations. Use transition words to organize your ideas. Use active voice instead of passive voice. Show authority and confidence and remove weak statements. Balance between being friendly and lacking confidence. Don’t Never use more than one exclamation mark unless you’re writing to a friend. Avoid use exclamation mark in general. Avoid text messaging and misspellings. Don’t write the email with anger, distress or some other negative emotion. Avoid voilating any policies, laws, rules or folkways in the receipient’s culture. Before Sending Check misspellings &amp; typos (Use grammer tools like “Grammarly”). Make sure that Email is better than a phone call or face-to-face communication. Make sure it’s polite to say this email out face to face before your receipient. Read this email to feel if the information flow is logical and it’s easy to get the point. Tips for the email to VIP Let it rest in the drafts and read it many times. Use reviewers’ suggestions. Reference [1] 【撰写英文邮件的技巧规则】 - Susie 戴舒萱的视频 - 知乎 https://www.zhihu.com/zvideo/1382430931886739456 [2] https://www.craftofscientificwriting.com/badge_emails.html [3] How to Write Professional Emails in English, written by Paola Pascual.","categories":[{"name":"WritingSkills","slug":"WritingSkills","permalink":"https://junfish.github.io/categories/WritingSkills/"}],"tags":[{"name":"E-mail","slug":"E-mail","permalink":"https://junfish.github.io/tags/E-mail/"},{"name":"writing","slug":"writing","permalink":"https://junfish.github.io/tags/writing/"}]},{"title":"Definition of Different Multi-X Learning","slug":"difference-between-multi-X-learning","date":"2021-09-10T20:15:11.000Z","updated":"2022-05-25T17:52:04.000Z","comments":true,"path":"2021/09/10/difference-between-multi-X-learning/","link":"","permalink":"https://junfish.github.io/2021/09/10/difference-between-multi-X-learning/","excerpt":"","text":"0. Introduction We discuss Multi-X Learning in two main categories: Multi-input learning and multi-output learning. Their relationships are shown in an imperfect venn diagram as follows. The dotted line implies some special cases would make itself cross the boundaries among these multi-X learning paradigms. 1. Multi-output Level Multi-class classification[1] Label of data is defined as multiple (3+3+3+) classes, but any sample in the dataset is specified into only one of these multiple classes. If we use a one-hot encoding to represent different classes, then all labels in the dataset contain the only 111 and leave the left values as 000. Multi-label classification[2][3][4] It can be understood as a generalization of the multi-class classification problem;there is more than one class assigned to a sample in multi-label problem . Thus, if its label is represented by a one-hot encoding, there is no constraint on the number of 111s or 000s on the entries of the binary vector. Multi-target Regression[5] Multi-target regression aims to simultaneously learn multiple regression responses attached to any instance, in which each response has its own distribution but shares same instance set. Multi-task Learning[6][7] MTL aims to learn mmm related tasks simultaneously to improve the performance of a model by sharing the information among these different tasks. These tasks could be represented by datasets from related but different sources. 2. Multi-input Level Multi-instance Learning[8] Different from multi-label learning with multiple labels per instance, multi-instance learning has just one label per several instances. Multi-instance learning is a special supervised learning paradigm that targets the bags of the instances. If any instance in a bag of instances is labeled as positive, then this bag is labeled as positive, otherwise it’s labeled as negative if all the instances are labeled as negative. However, there is no any label attached to the individual instances. Multi-view Learning[9] Multi-view learning has different sets of features for the single-source data in a single-task learning, such as different color features and texture features extracted from the images; these views may also be obtained from different sources, such as urls and words contained in a web page. Multi-modality learning is a special case of multi-view learning, in which different sets of features are represented by data in different modalities. 3. Transfer Learning[10] Learn representations on a target domain with the help of source domain, which alleviates the dependence on labeled data in target domain and achieves matching results compared with leaning from large-scale annotated dataset. 4. Comparison and Connection[7] Multi-label Learning &amp; Multi-target Regression[5] If all targets in a multi-target regression problem are binary variates (predicted by using logistic regression), we can understand it as a special case of multi-label learning. Multi-label Learning &amp; Multi-task Learning Multi-label learning takes advantage of dataset in which multiple labels are associated with identical data point. However, multi-task learning always targets several datasets from related but different data sources. If each of the multiple labels is separately treated as a task, but learning a sharing machine to predict all labels, then we can also resort to multi-task learning model to solve multi-label problem. Multi-view Learning &amp; Multi-task Learning Multi-view learning is a single task learning with many different sets of features where multi-task learning aims to learn different tasks together. The intersection between them is ∅\\emptyset∅. Transfer Learning &amp; Multi-task Learning Transfer learning aims to improve target task by using source task, but all tasks are equally treated and mutually learn representations from each other in Multi-task learning. On the other hand, target task is learned after source task in transfer learning but all tasks are shared and learned together in multi-task learning. From my point view, transfer learning is a special case of multi-task learning (mutually transfer learning). Reference [1] https://en.wikipedia.org/wiki/Multiclass_classification [2] https://en.wikipedia.org/wiki/Multi-label_classification [3] Zhang, Min-Ling, and Zhi-Hua Zhou. “A review on multi-label learning algorithms.” IEEE transactions on knowledge and data engineering 26.8 (2013): 1819-1837. [4] Zhou, Zhi-Hua, and Min-Ling Zhang. “Multi-label Learning.” (2017): 875-881. [5] Xu, Donna, Yaxin Shi, Ivor W. Tsang, Yew-Soon Ong, Chen Gong, and Xiaobo Shen. “Survey on multi-output learning.” IEEE transactions on neural networks and learning systems 31, no. 7 (2019): 2409-2429. [6] Caruana, Rich. “Multitask learning.” Machine learning 28.1 (1997): 41-75. [7] Zhang, Yu, and Qiang Yang. “A survey on multi-task learning.” arXiv preprint arXiv:1707.08114 (2017). [8] https://www.cs.cmu.edu/~juny/MILL/review.htm [9] Xu, Chang, Dacheng Tao, and Chao Xu. “A survey on multi-view learning.” arXiv preprint arXiv:1304.5634 (2013). [10] Zhuang, Fuzhen, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu Zhu, Hui Xiong, and Qing He. “A comprehensive survey on transfer learning.” Proceedings of the IEEE 109, no. 1 (2020): 43-76.","categories":[{"name":"MachineLearning","slug":"MachineLearning","permalink":"https://junfish.github.io/categories/MachineLearning/"}],"tags":[{"name":"Multi-X Learning","slug":"Multi-X-Learning","permalink":"https://junfish.github.io/tags/Multi-X-Learning/"},{"name":"Multi-class","slug":"Multi-class","permalink":"https://junfish.github.io/tags/Multi-class/"},{"name":"Multi-label","slug":"Multi-label","permalink":"https://junfish.github.io/tags/Multi-label/"},{"name":"Multi-instance","slug":"Multi-instance","permalink":"https://junfish.github.io/tags/Multi-instance/"},{"name":"Multi-view","slug":"Multi-view","permalink":"https://junfish.github.io/tags/Multi-view/"},{"name":"Multi-source","slug":"Multi-source","permalink":"https://junfish.github.io/tags/Multi-source/"},{"name":"Multi-task","slug":"Multi-task","permalink":"https://junfish.github.io/tags/Multi-task/"}]},{"title":"ImageNet 从下载到喂入模型训练","slug":"preprocess-imagenet-ILSVRC2012","date":"2021-07-26T16:03:03.000Z","updated":"2022-10-04T18:43:22.000Z","comments":true,"path":"2021/07/26/preprocess-imagenet-ILSVRC2012/","link":"","permalink":"https://junfish.github.io/2021/07/26/preprocess-imagenet-ILSVRC2012/","excerpt":"","text":"本文目的 鉴于目前网络上并无相关从 imagenet 官网下载竞赛数据到训练的相关教程，本文提供从获取数据到训练的全步骤讲解。 下载并解压数据 进入官网下载页面 https://image-net.org/challenges/LSVRC/2012/2012-downloads.php 获取下载链接。 利用 wget命令下载数据（一共四个数据文件）。 1234wget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_train.tarwget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tarwget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_train_t3.tarwget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_test_v10102019.tar 利用tar命令解压缩数据包放入指定文件夹 首先尝试解压缩部分文件探索数据文件目录结构：tar -xvf ./ILSVRC2012_img_train_t3.tar -C test。然后，通过bash命令批处理删除生成的文件：find ./test -name '*.JPEG' -type f -print -exec rm -rf &#123;&#125; \\;。 经探索发现文件结构如下： 12345678910111213141516171819202122| - - ILSVRC2012_img_train.tar | - - n01440764.tar | - - n01440764_2708.JPEG | - - n01440764_7173.JPEG ··· ···| - - ILSVRC2012_img_val.tar | - - ILSVRC2012_val_00010062.JPEG | - - ILSVRC2012_val_00009546.JPEG ...| - - ILSVRC2012_img_train_t3.tar | - - n02085620.tar | - - n02085620_10074.JPEG | - - n02085620_10131.JPEG ··· ···| - - ILSVRC2012_img_test_v10102019.tar | - - test | - - ILSVRC2012_test_00013640.JPEG | - - ILSVRC2012_test_00020698.JPEG ··· ... 编写python脚本文件批处理解压并删除中间tar文件： 123456789101112131415161718192021222324252627282930313233import tarfileimport osfrom tqdm import tqdmdef get_tar(path): tar_files = [] for name in os.listdir(path): # 遍历当前目录下所有文件和文件夹 if &#x27;.tar&#x27; in name: # 筛选出当前文件夹下需要解压的 .tar 文件 tar_files.append(name) return tar_filesdef untar(ori_file): print(&quot;Untar the file: &quot; + ori_file) new_dir_name = os.path.splitext(ori_file)[0] tar = tarfile.open(ori_file) names = tar.getnames() for name in tqdm(names): tar.extract(name, new_dir_name) if &#x27;.tar&#x27; in name: new_ori_file = os.path.join(new_dir_name, name) # 获取 tar 包内的 tar 包文件 untar(new_ori_file) # 解压 tar 包 os.remove(new_ori_file) # 解压完成后删除 tar 包 tar.close()def main(): abs_path = os.getcwd() # 获取当前文件所在目录绝对路径 tar_files = get_tar(abs_path) # 获取待解压的所有 tar 包 for tar_file in tar_files: ori_file = os.path.join(abs_path, tar_file) untar(ori_file)if __name__ == &quot;__main__&quot;: main() 上述代码保证了解压缩完的数据文件与原始的tar包文件结构一致（去除.tar后缀直接做文件夹名称）。 获取标签 从官网下载 Development Kit，获取1000个分类类别标签。 两个压缩包解压后的目录结构如下所示： 123456789| - - ILSVRC2012_devkit_t12 | - - COPYING | - - data | - - ILSVRC2012_validation_ground_truth.txt | - - meta.mat | - - evaluation | - - *.txt | - - *.m | - - readme.txt 其中，true label 的 value 存储于ILSVRC2012_devkit_t12/data/文件夹下。其中.txt文件包含 50,000 验证集的 class index values，每一行为对应图片（images 按序编号）的 class index label。 另外，其余训练集信息包含于meta.mat文件中，用 matlab 打开该文件，其中大小为1860×11860\\times11860×1的 synsets 结构体包含的数据详情如下截图所示： 其中关键信息为 ILSVRC2012_ID 和 WNID 两列，分别对应 class true label 和训练集文件夹名称。 数据集与标签匹配关系（借用 Cheat Sheet of Counting Files or Folders 探索解压后文件夹结构） 训练集ILSVRC2012_img_train下一级目录名（#1000）均可在 synsets 结构体 WNID 列（#1860）内找到对应，从而可以锁定以 WNID 为目录名下所有图片标签。 验证集ILSVRC2012_img_val下直接存储验证集所有图片（#50000），其文件名为ILSVRC2012_val_00000001到ILSVRC2012_val_00050000。这时我们需要借助ILSVRC2012_devkit_t12/data/ILSVRC2012_validation_ground_truth.txt文件来匹配文件名所对应的 ILSVRC2012_ID，从而在 synsets 结构体中与 WNID 关联。 测试集（#100000）同验证集 综上所述，训练集通过目录名称 -&gt; synsets -&gt; WNID -&gt; ILSVRC2012_ID匹配上标签，验证集和测试集通过文件名 -&gt; ILSVRC2012_validation_ground_truth.txt -&gt; synsets -&gt; ILSVRC2012_ID -&gt; WNID匹配上标签。 数据集整理 训练集目录结构刚好符合 torchvision.datasets.ImageFolder 的目录结构安排。 以此为标准，我做了如下的整理： 训练集结构不变，次级目录名称由 WNID 改为 ILSVRC2012_ID 验证集与测试集按照训练集标准安排结构，类别序号（ILSVRC2012_ID）做目录名称，包含该类别所有图片 编写python脚本按照上述思路整理数据集: 1234567891011121314151617181920212223242526272829303132333435363738import osimport shutilimport scipy.io as siodef rename_train(meta_data, img_root): dir_names = os.listdir(img_root) for dir_name in dir_names: for item in meta_data: if dir_name == item[0][1][0]: os.rename(os.path.join(img_root, dir_name), os.path.join(img_root, str(item[0][0][0][0]))) breakdef group_val(ground_truth, img_dir): with open(ground_truth) as f: lines = f.readlines() labels = [int(line.strip()) for line in lines] filenames = os.listdir(img_dir) for filename in filenames: img_idx = int(filename.split(&#x27;_&#x27;)[-1].split(&#x27;.&#x27;)[0]) ILSVRC_ID = labels[img_idx - 1] output_dir = os.path.join(img_dir, str(ILSVRC_ID)) if not os.path.isdir(output_dir): os.mkdir(output_dir) shutil.move(os.path.join(img_dir, filename), os.path.join(output_dir, filename)) passif __name__ == &quot;__main__&quot;: synsets = &#x27;/data/Datasets/ImageNet2012/ILSVRC2012_devkit_t12/ILSVRC2012_devkit_t12/data/meta.mat&#x27; ground_truth = &#x27;/data/Datasets/ImageNet2012/ILSVRC2012_devkit_t12/ILSVRC2012_devkit_t12/data/ILSVRC2012_validation_ground_truth.txt&#x27; val_dir = &#x27;/data/Datasets/ImageNet2012/ILSVRC2012_img_val&#x27; train_dir = &#x27;/data/Datasets/ImageNet2012/ILSVRC2012_img_train&#x27; meta_data = sio.loadmat(synsets)[&quot;synsets&quot;] a = meta_data[0, 0][1][0] rename_train(meta_data, train_dir) group_val(ground_truth, val_dir) 其中rename_val用于训练集分类别目录重命名，group_val用于验证集图片整理。 整理完的训练集与验证集目录结构如下（同 torchvision.datasets.ImageFolder）： 12345678910111213141516171819| - - ImageNet2012 | - - ILSVRC2012_img_train | - - 1 | - - n02119789_10007.JPEG | - - n02119789_10584.JPEG | - - n02119789_11491.JPEG ... | - - 2 ... ... | - - ILSVRC2012_img_val | - - 1 | - - ILSVRC2012_val_00000756.JPEG | - - ILSVRC2012_val_00006145.JPEG | - - ILSVRC2012_val_00009128.JPEG ... | - - 2 ... ... 根据统计，训练集共有 1,281,167 张图片+标签，验证集有 50,000 张图片+标签，测试集有 100,000 张图片，和官方标准一样。 写在最后 本文目的在于探索一个未知数据集的具体解决思路，从python脚本语言入手简洁明了。为了更加高效，可直接移步pytorch官方bash处理方法 Reference [1] Official pytorch example [2] ILSVRC2012 Official Website [2] ImageNet数据集到底长什么样子？ - 七个太阳的回答 - 知乎 [3] ImageNet使用方法？ - 薰风初入弦的回答 - 知乎 可视化 .markmap-container{display:flex;justify-content:center;margin:0 auto;width:90%;height:500px}.markmap-container svg{width:100%;height:100%}@media(max-width:768px){.markmap-container{height:400px}} document.querySelectorAll('.markmap-container>svg').forEach(mindmap => markmap.Markmap.create(mindmap, null, JSON.parse(mindmap.getAttribute('data'))))","categories":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"https://junfish.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"ImageNet","slug":"ImageNet","permalink":"https://junfish.github.io/tags/ImageNet/"},{"name":"Preprocess","slug":"Preprocess","permalink":"https://junfish.github.io/tags/Preprocess/"},{"name":"预处理","slug":"预处理","permalink":"https://junfish.github.io/tags/%E9%A2%84%E5%A4%84%E7%90%86/"}]},{"title":"Popular Datasets in SSL of CV","slug":"popular-CV-dataset-intro","date":"2021-07-07T17:49:38.000Z","updated":"2022-08-25T02:09:34.000Z","comments":true,"path":"2021/07/07/popular-CV-dataset-intro/","link":"","permalink":"https://junfish.github.io/2021/07/07/popular-CV-dataset-intro/","excerpt":"","text":"Introduction This blog is an excerpt from my own paper 《A survey on pre-trained models in text, image and graph: powerful self-supervised deep learning via big data》 that targets introducing the powerful pre-trained model (PTM) in Self-Supervised Learning (SSL) era. This blog serves as a synopsis of benchmark datasets in SSL in computer vision (CV). Classification The MNIST[1] is a database of handwritten digits containing 60,00060,00060,000 training examples and 10,00010,00010,000 testing examples. The images are fixed-size with 28×2828\\times2828×28 pixels. The pixel values are from 000 to 255.0255.0255.0 in which pixel values smaller than 255.0255.0255.0 can be understood as background (white) and 255 means foreground (black). The labels are from 0 to 9 and only one of these digits exists in an image. Both traditional and deep learning methods are based on this most popular dataset despite advanced methods showing perfect results. Thus, Geoffrey Hinton has described it as “the drosophila of machine learning”. Also in the domain of digit number, The Street View House Numbers (SVHN)[2] dataset collects real-world digit numbers from house numbers in Google Street View images. There are 73,25773,25773,257 digits for training, 26,03226,03226,032 digits for testing, and 531,131531,131531,131 additional, and all of them are 32×3232\\times3232×32 color images with both class labels and character level bounding boxes. As more advanced methods show perfect results on simple dataset, more sophisticated dataset such as CIFAR-10/CIFAR-100[3] are conducted. These two datasets are more close to the real-world object. The CIFAR-10 consists of 50,00050,00050,000 training images and 10,00010,00010,000 testing images, with 6,0006,0006,000 images per class and 32×3232\\times3232×32 pixels in each RGB colour image. The CIFAR-100 is similar to the CIFAR-10 but with more detailed label information. There are 100100100 classes containing 500500500 training images and 100100100 testing images in each class. In addition, these 100100100 “fine” classes are grouped equally into 202020 “coarse” classes. Researchers can adapt it to suitable learning methods. Inspired by the CIFAR-10 dataset, **STL-10[4] is another 96×9696\\times9696×96 color image dataset containing similar 101010 real-world classes. Each class has 500500500 training images and 800800800 test images. The biggest difference is that STL-10 has 100,000100,000100,000 unlabeled images for unsupervised learning. More construction information can be seen in [5]. Caltech-101[6] collects roughly 300×200300\\times200300×200 color images of objects belonging to 101101101 categories, with 404040 to 800800800 images per category and 505050 on average. The outlines of the objects in the pictures are annotated for the convenience of different learning methods. ImageNet[7] is one of the most popular and large-scale dataset on computer vision. It is built according to the hierarchical structure of WordNet[8]. The full ImageNet dataset contains 14,197,12214,197,12214,197,122 images and 21,84121,84121,841 synsets indexed, attaching on average 1,0001,0001,000 images to illustrate each synset. The most frequently-used subset of ImageNet is the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) dataset from 2010 to 2017, containing tasks of classification, localization, and detection. The number of samples in training and testing datasets and the labels of images is determined by the specific task, more details are seen in [9]. In addition to the popular MNIST, there still exist many domain datasets used for the downstream tasks in the classification problem. HMDB51[10][11] is an action video database for a total of 7,0007,0007,000 clips in 515151 action classes. It contains five types of facial actions and body movements. UCF101[12] is another action video data set designed for the more realistic action recognition. It is an extension of UCF50[13] data set containing only 50 action categories with 101101101 action categories, collected from YouTube. What makes it a famous recognition dataset is the workshop in ICCV13 with UCF101 as its main competition benchmark. Food-101[14] is a real-world food dataset of 101101101 food categories, with 750750750 and 250250250 images per class in training and testing dataset respectively. Birdsnap[15] is a large-scale fine-grained visual categorization of birds, with bounding boxes and the locations/annotations of 171717 parts in the object. It contains 49,82949,82949,829 images of 500500500 most common species in North American, with each species containing 696969 to 100100100 images and most species having 100100100. In addition, some images are also labeled as male or female, immature or adult, and breeding or non-breeding plumage. To target the scene categorization, the extensive Scene UNderstanding (SUN)[16][17] database fills the gap of the existing dataset with the limited scope of categories. This database contains 899899899 categories and 130,519130,519130,519 images, and only images with more than 200×200200\\times200200×200 pixels were kept. SUN397 is a more well-sampled subset that maintains 397397397 categories with at least 100100100 images per category, in which other categories containing relatively few unique photographs are discarded. Places205[18] dataset is another large scale scene dataset consists of 2,448,8732,448,8732,448,873 images from 205205205 scene categories. Cars[19] dataset in the domain of cars contains 16,18516,18516,185 color images of 196196196 classes (at the level of Make, Model, Year) of cars. For convenience, this dataset is split into training and test set in roughly equal quantities. Aircraft[20] is another fine-grained visual classification designed for aircraft (also known as FGVC-Aircraft). A popular form of this dataset is the fine-grained recognition challenge 2013 (FGComp2013)[21] ran in parallel with the ILSVRC2013. There exist four-level hierarchy: Model, Variant, Family, Manufacturer, from finer to coarser to organize this database. The more detailed information is shown in [22]. Pets[23] represents The Oxford-IIIT Pet Dataset that collects 373737 pet categories with roughly 200200200 images per category. All images have an associated ground truth annotation of breed for classification, head ROI for detection, and pixel-level trimap for segmentation. Similarly, Flowers[24] is another domain dataset in flowers also collected by Oxford; it contains Oxford-17 Flowers of 171717 categories and Oxford-102 Flowers of 102102102 categories. The Describable Textures Dataset (DTD)[25] is an evolving collection of textural images in the wild, which consists of 5,6405,6405,640 images of 474747 categories, with 120120120 images per category. iNaturallist2018[26] is a large-scale species classification competition conducted on the FGVC5 workshop at CVPR2018. This dataset contains over 8,0008,0008,000 species categories, with more than 450,000450,000450,000 images in the training and validation dataset collected from iNaturalist[27]. Detection COCO[28] is a large-scale data set for object detection, segmentation, and caption; it contains 330,000330,000330,000 rgb images, with more than 200,000200,000200,000 labelled. There are 1.51.51.5 million​ object instances of 808080 object categories involved. Thus, it is one of the most popular benchmark data set in detection and segmentation in parallel with the following PASCAL VOC. The PASCAL VOC project[29] provides standardized image datasets for object class recognition and also has run challenges evaluating performance on object class recognition from 2005 to 2012. The main datasets used in self-supervised learning are VOC07, VOC11, and VOC12. Main competitions in VOC07[30] contains classification and detection tasks; both of them consist of 202020 objects and contain at least one object in each image. Thus, it is common to use VOC07 serving as the downstream task for the detection. Segmentation Both VOC11[31] and VOC12[32] contains classification, detection, and segmentation tasks in the main competition, thus leading to the common use of down stream task for the segmentation. ADE20K[33][34] collects 27,57427,57427,574 images from both the SUN and Places205 databases, in which 25,57425,57425,574 for training and 2,0002,0002,000 for testing. All 707,868707,868707,868 objects from 3,6883,6883,688 categories existing in images are annotated. Especially, this dataset contains 193,238193,238193,238 annotated object parts and parts of parts, and additional attributes, annotation time, depth ordering for the benefit of research community. The NYU-Depth V2[35] is a dataset consists of images and video sequences from 464464464 indoor scenes that are recorded by both the RGB and Depth cameras from 333 cities. It contains 1,4491,4491,449 images with the ground truth of depth, and the original RGB values are also provided. In addition, there are 407,024407,024407,024 new unlabeled frames and additional class labels for the objects in images. Cityscapes[36][37] is a dataset of urban street scenes from 505050 cities with the ground truth of semantic segmentation. The main instances are vehicles, people, and construction. The high-quality dense pixel annotations contain a volume of 5,0005,0005,000 images. In addition to the fine annotations, coarser polygonal annotations are provided for a set of 20,00020,00020,000 images. Moreover, the videos consist of not consistent images with high-quality annotations, and these annotated images with consistent changing views are provided for researchers. LVIS[38] is dataset for large vocabulary instance segmentation. It features that 1) a category or word in one image is related to the only segmentation object; 2) more than 1,2001,2001,200 categories are extracted from roughly 160,000160,000160,000 images; 3) long tails phenomenon exist in these categories; and 4) more than 2,000,0002,000,0002,000,000 high-quality instance segmentation masks. Densely Annotated VIdeo Segmentation (DAVIS)[39] is a video dataset designed for the in-depth analysis of the SOTA in video object segmentation, in which DAVIS 2017[40] contains both semi-supervised (human-guided at test time) and unsupervised (human non-guided at test time) video sequences with multiple annotated instances. Others Paris StreetView dataset[41] is designed for image inpainting task, which contains 14,90014,90014,900 training images and 100 test images collected from street views of Paris. This dataset is collected from Google Street View and mainly focuses on the buildings in the city. Based on MNIST, Moving-MNIST[42] is a video dataset designed for evaluating sequence prediction or reconstruction, which contains 10,00010,00010,000 sequences. Each video is long of 202020 frames and consisted of two digits (possibly overlapped) moving inside a 64×6464\\times6464×64 patch. The first benchmark is reported on [43] by the method of LSTMs. Yahoo Flickr Creative Commons 100100100 Million (YFCC100M) dataset[44][45] is the largest public multimedia collection that is allowed to search by users for their own targets; this dataset can browse both images and videos. It is free and for researchers to explore and investigate subsets of the YFCC100M in real-time. Subsets of the complete dataset can be retrieved by any keyword searching and reviewed directly. In addition, the text information attached to any image or video is abundant, such as containing location information and user tags. Briefly，it is more a multimedia library than a domain dataset. More generalized dataset concept in self-supervised learning era is composed of multimedia website, APP, or search engine such as \\textbf{Instagram}, Flickr, Google Images, etc. I think pictures in the wild will play a major role in the future study in CV because of the quantity of data, the computation source, and the learning power of PTM. Reference [1] http://yann.lecun.com/exdb/mnist/. [2] http://ufldl.stanford.edu/housenumbers/. [3] https://www.cs.toronto.edu/~kriz/index.html. [4] A. Coates, A. Ng, and H. Lee, “An analysis of single-layer networks in unsupervised feature learning,” in Proceedings of the fourteenth international conference on artificial intelligence and statistics, pp. 215–223, JMLR Workshop and Conference Proceedings, 2011. [5] https://cs.stanford.edu/~acoates/stl10/. [6] http://www.vision.caltech.edu/Image_Datasets/Caltech101/. [7] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, “Imagenet: A large-scale hierarchical image database,” in 2009 IEEE conference on computer vision and pattern recognition, pp. 248–255, Ieee, 2009. [8] G. A. Miller, WordNet: An electronic lexical database. MIT press, 1998. [9] https://image-net.org/. [10] H. Kuehne, H. Jhuang, E. Garrote, T. Poggio, and T. Serre, “HMDB: a large video database for human motion recognition,” in Proceedings of the International Conference on Computer Vision (ICCV), 2011. [11] https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/. [12] https://www.crcv.ucf.edu/data/UCF101.php. [13] https://www.crcv.ucf.edu/data/UCF50.php. [14] L. Bossard, M. Guillaumin, and L. Van Gool, “Food-101–mining discriminative components with random forests,” in European conference on computer vision, pp. 446–461, Springer, 2014. [15] T. Berg, J. Liu, S. Woo Lee, M. L. Alexander, D. W. Jacobs, and P. N. Belhumeur, “Birdsnap: Large-scale fine-grained visual categorization of birds,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2014. [16] J. Xiao, J. Hays, K. A. Ehinger, A. Oliva, and A. Torralba, “Sun database: Large-scale scene recognition from abbey to zoo,” in 2010 IEEE computer society conference on computer vision and pattern recognition, pp. 3485–3492, IEEE, 2010. [17] J. Xiao, K. A. Ehinger, J. Hays, A. Torralba, and A. Oliva, “Sun database: Exploring a large collection of scene c International Journal of Computer Vision, vol. 119, no. 1, pp. 3–22, 2016. [18] http://places.csail.mit.edu/downloadData.html. [19] http://ai.stanford.edu/~jkrause/cars/car_dataset.html. [20] S. Maji, J. Kannala, E. Rahtu, M. Blaschko, and A. Vedaldi, “Fine-grained visual classification of aircraft,” tech. rep., 2013. [21] https://sites.google.com/site/fgcomp2013/. [22] https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/. [23] https://www.robots.ox.ac.uk/~vgg/data/pets/. [24] https://www.robots.ox.ac.uk/~vgg/data/flowers/. [25] https://www.robots.ox.ac.uk/~vgg/data/dtd/. [26] https://sites.google.com/view/fgvc5/competitions/inaturalist. [27] https://www.inaturalist.org/. [28] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollár, and C. L. Zitnick, “Microsoft coco: Common objects in context,” in European conference on computer vision, pp. 740–755, Springer, 2014. [29] http://host.robots.ox.ac.uk/pascal/VOC/. [30] http://host.robots.ox.ac.uk/pascal/VOC/voc2007/index.html. [31] http://host.robots.ox.ac.uk/pascal/VOC/voc2011/index.html. [32] http://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html. [33] B. Zhou, H. Zhao, X. Puig, S. Fidler, A. Barriuso, and A. Torralba, “Scene parsing through ade20k dataset,” in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 633–641, 2017. [34] B. Zhou, H. Zhao, X. Puig, T. Xiao, S. Fidler, A. Barriuso, and A. Torralba, “Semantic understanding of scenes through the ade20k dataset,” International Journal of Computer Vision, vol. 127, no. 3, pp. 302–321, 2019. [35] https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html. [36] M. Cordts, M. Omran, S. Ramos, T. Scharwächter, M. Enzweiler, R. Benenson, U. Franke, S. Roth, and B. Schiele, “The cityscapes dataset,” in CVPR Workshop on The Future of Datasets in Vision, 2015. [37] M. Cordts, M. Omran, S. Ramos, T. Rehfeld, M. Enzweiler, R. Benenson, U. Franke, S. Roth, and B. Schiele, “The cityscapes dataset for semantic urban scene understanding,” in Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016. [38] A. Gupta, P. Dollar, and R. Girshick, “LVIS: A dataset for large vocabulary instance segmentation,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2019. [39] https://davischallenge.org/. [40] https://davischallenge.org/davis2017/code.html. [41] C. Doersch, “Data analysis project: What makes paris look like paris?”. [42] http://www.cs.toronto.edu/~nitish/unsupervised_video/. [43] N. Srivastava, E. Mansimov, and R. Salakhudinov, “Unsupervised learning of video representations using lstms,” in International conference on machine learning, pp. 843–852, PMLR, 2015. [44] B. Thomee, D. A. Shamma, G. Friedland, B. Elizalde, K. Ni, D. Poland, D. Borth, and L.-J. Li, “Yfcc100m: The new data in multimedia research,” Communications of the ACM, vol. 59, no. 2, pp. 64–73, 2016. [45] http://projects.dfki.uni-kl.de/yfcc100m/.","categories":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"https://junfish.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"PTM","slug":"PTM","permalink":"https://junfish.github.io/tags/PTM/"},{"name":"SSL","slug":"SSL","permalink":"https://junfish.github.io/tags/SSL/"},{"name":"benchmark datasets","slug":"benchmark-datasets","permalink":"https://junfish.github.io/tags/benchmark-datasets/"},{"name":"CV","slug":"CV","permalink":"https://junfish.github.io/tags/CV/"}]},{"title":"How to import data from Douban API?","slug":"import-douban-data-from-douban-api","date":"2021-07-05T07:24:50.000Z","updated":"2022-03-25T21:49:07.000Z","comments":true,"path":"2021/07/05/import-douban-data-from-douban-api/","link":"","permalink":"https://junfish.github.io/2021/07/05/import-douban-data-from-douban-api/","excerpt":"","text":"写在前面 Hexo 为我们提供了大量的 Plugins 以供需要使用，这些包通过npm install命令可以一键便捷地集成到我们的网站中。大家可以根据个人胃口食用之。因此，本文只是作为一个引子展示 Hexo 有广泛的个性化定制支撑。毕竟，博客作为一个记录功能的存在，我们希望它的建设更加丰富多样的同时不要占据我们太多的工作和学习时间。Time is Money。 安装组件并配置 直接通过官方命令npm install hexo-douban --save安装。 站点根目录下的/_config.yml配置文件末尾加上如下代码： 12345678910111213douban: user: 214963638 # 你的豆瓣ID builtin: true # 将生成页面的功能嵌入hexo s和hexo g中 book: title: &#x27;读后感&#x27; quote: &#x27;This is my book quote&#x27; movie: title: &#x27;观后感&#x27; quote: &#x27;This is my movie quote&#x27; #game: #title: &#x27;This is my game title&#x27; #quote: &#x27;This is my game quote&#x27; timeout: 10000 # 爬取数据的超时时间，也即超时报错（ETIMEOUT）等待时间 通过命令hexo clean &amp;&amp; hexo douban -bgm &amp;&amp; hexo g -d &amp;&amp; hexo s开启豆瓣的数据导入，其中-bgm代表的是 books、games、movies 三个参数，根据需要酌情食用。 ps: builtin参数设置为true将hexo douban -bgm内嵌入hexo g -d或hexo s中，方便网页的下次生成和部署。 在主题配置文件/themes/pure/_config.yml中添加 menu 按钮及其图标代码。 12345678910111213141516171819202122232425menu: Home: / Archives: archives # 归档 Categories: categories # 分类 Tags: tags # 标签 Publications: /publications Repository: repository # github repositories Books: books # 豆瓣书单 Movies: movies # 豆瓣电影 Links: links # 友链 About: about # 关于# Enable/Disable menu iconsmenu_icons: enable: true # 是否启用导航菜单图标 home: icon-home-fill archives: icon-archives-fill categories: icon-folder tags: icon-tags publications: icon-list repository: icon-project books: icon-book-fill movies: icon-douban links: icon-friendship about: icon-cup-fill 常规 Bug 的解决方案 数据导入（hexo douban -bgm）可能出现的常规报错[1]如下所示： 12INFO 0 books have been loaded in 2177 ms, because you are offline or your network is badINFO 0 movies have been loaded in 2351 ms, because you are offline or your network is bad 首先利用node --version检查当前版本，然后通过sudo npm install n -g安装 node 的管理模块，最后通过命令sudo n 12.18.1安装 v12.18.1 版本的node.js 解决上述网络问题导致的 bug。 参考资料 [1] Hexo博客加入豆瓣 [2] 在Hexo博客中加入豆瓣读书页面 [3] node版本降级（mac下）","categories":[{"name":"站点建设","slug":"站点建设","permalink":"https://junfish.github.io/categories/%E7%AB%99%E7%82%B9%E5%BB%BA%E8%AE%BE/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://junfish.github.io/tags/hexo/"},{"name":"plugins","slug":"plugins","permalink":"https://junfish.github.io/tags/plugins/"}]},{"title":"How to import comment system into my blog website?","slug":"import-comment-system","date":"2021-07-04T04:13:38.000Z","updated":"2022-03-25T21:49:02.000Z","comments":true,"path":"2021/07/04/import-comment-system/","link":"","permalink":"https://junfish.github.io/2021/07/04/import-comment-system/","excerpt":"","text":"名词介绍 评论系统（comment system）是指一个为用户提供交互的平台，并且一般还具有对所有评论进行相应的云端存储或管理功能。LeanCloud 是一家为软件开发提供后端的云服务供应商。Valine 是一款快速、简洁且评论者无需注册的便捷评价系统，非常适合博客等访问量不高的网站，可以有效避免博主维护注册用户等的额外开销。 他们之间的逻辑关系为 Valine 是一款评论系统，LeanCloud 作为一个服务商帮助我们一键运维博客内嵌的 Valine 系统。 准备工作 注册 LeanCloud 账号，推荐国际版账号。 创建应用，然后选择自己创建的应用。 按照：设置（Settings）–&gt; 应用 Key（App Keys）–&gt;AppID 和 AppKey。 为了数据安全，可在安全中心中添加自己的博客域名。 插入 Valine Valine 本身可通过导入js包Valine.min.js而在 html 页面中直接插入，代码例子[1]如下： 123456789101112131415161718192021222324&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Valine - A simple comment system based on Leancloud.&lt;/title&gt; &lt;!--Leancloud 操作库:--&gt; &lt;script src=&quot;//cdn1.lncld.net/static/js/3.0.4/av-min.js&quot;&gt;&lt;/script&gt; &lt;!--Valine 的核心代码库:--&gt; &lt;script src=&quot;./dist/Valine.min.js&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div class=&quot;comment&quot;&gt;&lt;/div&gt; &lt;script&gt; new Valine(&#123; // AV 对象来自上面引入av-min.js(老司机们不要开车➳♡゛扎心了老铁) av: AV, el: &#x27;.comment&#x27;, // app_id: &#x27;Your APP ID&#x27;, // 这里填写上面得到的APP ID app_key: &#x27;Your APP KEY&#x27;, // 这里填写上面得到的APP KEY placeholder: &#x27;ヾﾉ≧∀≦)o来啊，快活啊!&#x27; // [v1.0.7 new]留言框占位提示文字 &#125;); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 然而，在我们使用的 hexo 主题模板中，只需要通过./themes/pure/_config.yml文件即可激活我们的 Valine 系统。找到comment项如下所示： 123456789101112131415161718192021222324252627282930comment: type: valine # 启用哪种评论系统 disqus: youyan: uid: livere: uid: gitment: githubID: repo: ClientID: ClientSecret: lazy: false gitalk: owner: admin: repo: ClientID: ClientSecret: valine: appid: # your leancloud application appid appkey: # your leancloud application appkey notify: false # mail notifier , https://github.com/xCss/Valine/wiki verify: true # Verification code placeholder: Please comment here! This box has full support for Markdown. 请评论！支持 Markdown 语法。 # comment box placeholder avatar: mm # gravatar style meta: nick,mail,link # custom comment header pageSize: 10 # pagination size visitor: true # Article reading statistic https://valine.js.org/visitor.html recordIP: true # 记录评论者IP 需要配置的项已经在上面的yaml文件中注释。 测试与玩转 通过 hexo clean &amp;&amp; hexo g -d来更新并部署添加了评论系统的博客。然后进行评论，并登录 leancloud 进行后台数据的管理。截图如下所示： 参考文献 [1] Valine – 一款极简的评论系统 [2] Hexo 部署 valine 评论的 leancloud 设置","categories":[{"name":"站点建设","slug":"站点建设","permalink":"https://junfish.github.io/categories/%E7%AB%99%E7%82%B9%E5%BB%BA%E8%AE%BE/"}],"tags":[{"name":"comment system","slug":"comment-system","permalink":"https://junfish.github.io/tags/comment-system/"},{"name":"LeanCloud","slug":"LeanCloud","permalink":"https://junfish.github.io/tags/LeanCloud/"},{"name":"Valine","slug":"Valine","permalink":"https://junfish.github.io/tags/Valine/"},{"name":"评论系统","slug":"评论系统","permalink":"https://junfish.github.io/tags/%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F/"}]},{"title":"How to create your own blog on github by hexo?","slug":"how-to-create-blog-md","date":"2021-07-03T05:28:21.000Z","updated":"2023-02-11T00:26:02.000Z","comments":true,"path":"2021/07/03/how-to-create-blog-md/","link":"","permalink":"https://junfish.github.io/2021/07/03/how-to-create-blog-md/","excerpt":"","text":"名词说明 github 网站是一个代码托管平台，经常用于与他人分享自己的项目与成果。github 利用 git 来逻辑化项目的版本控制和团队间的合作交流。github pages 则是 github 推出的一项用于搭建并托管个人网站的服务。hexo 是一个快捷开发个人博客的强大工具，它支持 Makedown 语法写作和很多功能强大的插件。 简而言之，我们将利用 github 来作为服务器托管我们的博客，用 github pages 来初始化存放我们博客的仓库，用 hexo 来创建、调试、发布我们的博客，并关联到我们创建的 github pages 仓库。因此，关键在于 hexo 与 github 服务器上仓库的连接。 准备工作 注册 github 账号 了解并安装 git 安装 brew (mac上强大的软件管理工具) 环境配置 1. 通过 brew 安装 node.js 1brew install node node.js 会包含 npm 的安装，安装完成后检查是否安装成功。 1node -v 1npm -v 输出为版本号，我的输出如下： 1v16.4.1 17.18.1 2. 利用 npm 安装 hexo 1npm install -g hexo-cli 3. 利用 hexo 初始化博客网站 新建一个文件夹（blog）作为本地博客项目管理地址。 1mkdir blog &amp;&amp; cd blog 本地博客的初始化操作： 1hexo init 初始化完成之后我们执行 ls 将会展示全部生成的文件如下： 1234_config.landscape.yml package-lock.json source_config.yml package.json themesdb.json publicnode_modules scaffolds 此时我们执行命令 hexo s 就可以预览我们的博客网站，命令行界面输出如下表示一切正常。 123INFO Validating configINFO Start processingINFO Hexo is running at http://localhost:4000 . Press Ctrl+C to stop. 在浏览器地址栏输入 http://localhost:4000 就会打开我们的博客。此时，我们的电脑即为博客的服务器端，其他设备可通过将字符串 “localhost” 替换为本机 ip 地址的方式来访问我们的博客。 4. 通过 Github Pages 建立远程仓库 官方教程 5. 生成 git 客户端 SSH key 通过 Terminal 配置用户名和邮箱: 12git config --global user.name &quot;username&quot;git config --global user.email &quot;email@gmail.com&quot; 然后通过下面的命令生成 SSH key: 1ssh-keygen -t rsa -C &quot;email@gmail.com&quot; 接着输入如下命令获取 key: 1cat ~/.ssh/id_rsa.pub 6. 与 github 仓库建立远程链接 Github 账户 --&gt; Settings --&gt; SSH and GPG keys --&gt; New SSH key 7. 管理个人博客常用命令与技巧 发布博客：hexo n newblog 清除已生成的静态文件：hexo clean 生成博客：hexo g 部署博客：hexo d 避免重复输入 passphrase：ssh-add -K ~/.ssh/id_rsa。该命令可用于在当前 session 中记住私钥，重启 Terminal 会要求再次输入 passphrase。 一键生成博客并部署：hexo g -d 参考文献 [1] Mac下使用GitHub+Hexo搭建个人博客 [2] git命令行如何设置passphrase for key来避免每次push都需要输入pass for key? [3] GitHub Pages + Hexo免费搭建个人博客_Mac","categories":[{"name":"站点建设","slug":"站点建设","permalink":"https://junfish.github.io/categories/%E7%AB%99%E7%82%B9%E5%BB%BA%E8%AE%BE/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://junfish.github.io/tags/hexo/"},{"name":"github","slug":"github","permalink":"https://junfish.github.io/tags/github/"},{"name":"macintosh","slug":"macintosh","permalink":"https://junfish.github.io/tags/macintosh/"}]},{"title":"Golden Words in Academic Writing","slug":"practice-in-paper-writing","date":"2021-07-03T05:28:21.000Z","updated":"2023-02-16T20:36:13.000Z","comments":true,"path":"2021/07/03/practice-in-paper-writing/","link":"","permalink":"https://junfish.github.io/2021/07/03/practice-in-paper-writing/","excerpt":"","text":"Abstract Commend your own model simple yet effective Introduction Inspired by other works the proposed method follows the spirit of XXX inspired by XXX Similar but different our algorithm/method is similar to xxx with two differences: (1) we … instead of …, and (2) we use xxx as … Judging other works making XXX prohibitive in practice methods","categories":[{"name":"WritingSkills","slug":"WritingSkills","permalink":"https://junfish.github.io/categories/WritingSkills/"}],"tags":[{"name":"writing","slug":"writing","permalink":"https://junfish.github.io/tags/writing/"}]}],"categories":[{"name":"Recreation","slug":"Recreation","permalink":"https://junfish.github.io/categories/Recreation/"},{"name":"小作文","slug":"小作文","permalink":"https://junfish.github.io/categories/%E5%B0%8F%E4%BD%9C%E6%96%87/"},{"name":"Debugging","slug":"Debugging","permalink":"https://junfish.github.io/categories/Debugging/"},{"name":"MachineLearning","slug":"MachineLearning","permalink":"https://junfish.github.io/categories/MachineLearning/"},{"name":"Cheatsheet","slug":"Cheatsheet","permalink":"https://junfish.github.io/categories/Cheatsheet/"},{"name":"站点建设","slug":"站点建设","permalink":"https://junfish.github.io/categories/%E7%AB%99%E7%82%B9%E5%BB%BA%E8%AE%BE/"},{"name":"WritingSkills","slug":"WritingSkills","permalink":"https://junfish.github.io/categories/WritingSkills/"},{"name":"计算机视觉","slug":"计算机视觉","permalink":"https://junfish.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"大麻","slug":"大麻","permalink":"https://junfish.github.io/tags/%E5%A4%A7%E9%BA%BB/"},{"name":"THC","slug":"THC","permalink":"https://junfish.github.io/tags/THC/"},{"name":"致幻","slug":"致幻","permalink":"https://junfish.github.io/tags/%E8%87%B4%E5%B9%BB/"},{"name":"个人感悟","slug":"个人感悟","permalink":"https://junfish.github.io/tags/%E4%B8%AA%E4%BA%BA%E6%84%9F%E6%82%9F/"},{"name":"Nvidia","slug":"Nvidia","permalink":"https://junfish.github.io/tags/Nvidia/"},{"name":"GPU","slug":"GPU","permalink":"https://junfish.github.io/tags/GPU/"},{"name":"driver","slug":"driver","permalink":"https://junfish.github.io/tags/driver/"},{"name":"Matrix","slug":"Matrix","permalink":"https://junfish.github.io/tags/Matrix/"},{"name":"Calculus","slug":"Calculus","permalink":"https://junfish.github.io/tags/Calculus/"},{"name":"derivative","slug":"derivative","permalink":"https://junfish.github.io/tags/derivative/"},{"name":"Markdown","slug":"Markdown","permalink":"https://junfish.github.io/tags/Markdown/"},{"name":"Cheatsheet","slug":"Cheatsheet","permalink":"https://junfish.github.io/tags/Cheatsheet/"},{"name":"commands","slug":"commands","permalink":"https://junfish.github.io/tags/commands/"},{"name":"linux","slug":"linux","permalink":"https://junfish.github.io/tags/linux/"},{"name":"conda","slug":"conda","permalink":"https://junfish.github.io/tags/conda/"},{"name":"python","slug":"python","permalink":"https://junfish.github.io/tags/python/"},{"name":"virtual environment","slug":"virtual-environment","permalink":"https://junfish.github.io/tags/virtual-environment/"},{"name":"Tmux","slug":"Tmux","permalink":"https://junfish.github.io/tags/Tmux/"},{"name":"Linux","slug":"Linux","permalink":"https://junfish.github.io/tags/Linux/"},{"name":"SSH","slug":"SSH","permalink":"https://junfish.github.io/tags/SSH/"},{"name":"hexo","slug":"hexo","permalink":"https://junfish.github.io/tags/hexo/"},{"name":"billiards","slug":"billiards","permalink":"https://junfish.github.io/tags/billiards/"},{"name":"terminology","slug":"terminology","permalink":"https://junfish.github.io/tags/terminology/"},{"name":"E-mail","slug":"E-mail","permalink":"https://junfish.github.io/tags/E-mail/"},{"name":"writing","slug":"writing","permalink":"https://junfish.github.io/tags/writing/"},{"name":"Multi-X Learning","slug":"Multi-X-Learning","permalink":"https://junfish.github.io/tags/Multi-X-Learning/"},{"name":"Multi-class","slug":"Multi-class","permalink":"https://junfish.github.io/tags/Multi-class/"},{"name":"Multi-label","slug":"Multi-label","permalink":"https://junfish.github.io/tags/Multi-label/"},{"name":"Multi-instance","slug":"Multi-instance","permalink":"https://junfish.github.io/tags/Multi-instance/"},{"name":"Multi-view","slug":"Multi-view","permalink":"https://junfish.github.io/tags/Multi-view/"},{"name":"Multi-source","slug":"Multi-source","permalink":"https://junfish.github.io/tags/Multi-source/"},{"name":"Multi-task","slug":"Multi-task","permalink":"https://junfish.github.io/tags/Multi-task/"},{"name":"ImageNet","slug":"ImageNet","permalink":"https://junfish.github.io/tags/ImageNet/"},{"name":"Preprocess","slug":"Preprocess","permalink":"https://junfish.github.io/tags/Preprocess/"},{"name":"预处理","slug":"预处理","permalink":"https://junfish.github.io/tags/%E9%A2%84%E5%A4%84%E7%90%86/"},{"name":"PTM","slug":"PTM","permalink":"https://junfish.github.io/tags/PTM/"},{"name":"SSL","slug":"SSL","permalink":"https://junfish.github.io/tags/SSL/"},{"name":"benchmark datasets","slug":"benchmark-datasets","permalink":"https://junfish.github.io/tags/benchmark-datasets/"},{"name":"CV","slug":"CV","permalink":"https://junfish.github.io/tags/CV/"},{"name":"plugins","slug":"plugins","permalink":"https://junfish.github.io/tags/plugins/"},{"name":"comment system","slug":"comment-system","permalink":"https://junfish.github.io/tags/comment-system/"},{"name":"LeanCloud","slug":"LeanCloud","permalink":"https://junfish.github.io/tags/LeanCloud/"},{"name":"Valine","slug":"Valine","permalink":"https://junfish.github.io/tags/Valine/"},{"name":"评论系统","slug":"评论系统","permalink":"https://junfish.github.io/tags/%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F/"},{"name":"github","slug":"github","permalink":"https://junfish.github.io/tags/github/"},{"name":"macintosh","slug":"macintosh","permalink":"https://junfish.github.io/tags/macintosh/"}]}