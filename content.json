{"meta":{"title":"Jason","subtitle":"","description":"","author":"Jason Yu","url":"https://junfish.github.io","root":"/"},"pages":[{"title":"Paper Reading List (After Oct., 2023)","date":"2023-11-12T21:28:02.000Z","updated":"2023-12-08T02:24:57.615Z","comments":false,"path":"Paper Reading List/index.html","permalink":"https://junfish.github.io/Paper%20Reading%20List/index.html","excerpt":"","text":"论文阅读（Papers） Title Keyword Venue Link Sequential Modeling Enables Scalable Learning for Large Vision Models Large Vision Model (LVM); Unified Vision Dataset (UVD); Auto-Regressive; Pretrained; Transformer arXiv'23 [Paper] [Code] [Dataset] [Project] Learning to Detect Scene Landmarks for Camera Localization Camera Localization; Scene Landmarks; CNN; Indoor-6 CVPR'22 [Paper] [Code] [Dataset] ShareGPT4V: Improving Large Multi-Modal Models with Better Captions GPT-4V; Large Multi-modal Models (LMMs); Pre-training; Image Captioning arXiv'23 [Paper] [Website] From Coarse to Fine: Robust Hierarchical Localization at Large Scale Camera Localization; 6-DoF; SfM; CNN; Hierarchical Framework CVPR'19 [Paper] [Code] NavMarkAR: A Landmark-based Augmented Reality (AR) Wayfinding System for Enhancing Spatial Learning of Older Adults HCI; Augmented Reality (AR); Indoor Navigation; Multimodal Interaction; Older Adults arXiv'23 [Paper] SparsePose: Sparse-View Camera Pose Regression and Refinement Camera Pose Regression; Sparse Set; Wide-Baseline Images CVPR'23 [Paper] [Code] Image Captioning State-of-the-Art: Is it enough for the Guidance of Visually Impaired in an Environment? Image Captioning; VIPs CSA'22 [Paper] Grounding Answers for Visual Questions Asked by Visually Impaired People Visual Question Answering (VQA); Answer Grounding; VIPs; Viz-Wiz-VQA-Grounding CVPR'22 [Paper] [Dataset] Structure-from-Motion Revisited SfM; 3D Reconstruction; COLMAP CVPR'16 [Paper] [Code (COLMAP)] ViNav: A Vision-Based Indoor Navigation System for Smartphones Indoor Navigation System; Smartphone System; SfM; OCR; Dead Reckoning; WiFi Fingerprinting TMC'18 [Paper] Understanding the Limitations of CNN-based Absolute Camera Pose Regression PoseNet; MapNet; Image Retrieval; Absolute Camera pose Regression (APR); Relative camera Pose Regression (RPR) CVPR'19 [Paper] [Code] A Preliminary Study on the Possibility of Scene Captioning Model Integration as an Improvement in Assisted Navigation for Visually Impaired Users Visually Impaired (VI); NAS; Image Captioning; RGB-D AsiaSim'23 [Paper] ClipCap: CLIP Prefix for Image Captioning Image Captioning; Prefix; CLIP; GPT; VLP; arXiv'21 [Paper] [Code] \"I Want to Figure Things Out\": Supporting Exploration in Navigation for People with Visual Impairments Human Computer Interaction (HCI); Visually Impaired People (VIPs); Navigation Assistance Systems (NASs); Accessibility PACMHCI'23 [Paper] Segment Anything Promptable Segmentation; PFM; SA-1B ICCV'23 [Paper] [Code] [Website] Camera Pose Auto-Encoders for Improving Pose Regression Camera Pose Regression; Auto-Encoders; Image Reconstruction ECCV'22 [Paper] [Code] PoseNet: A Convolutional Network for Real-Time 6-DOF Camera Relocalization Camera Pose Regression; 6-DoF; CNN; Cambridge Landmarks ICCV'15 [Paper] [Code] [Dataset] Real-time Vision-based Navigation for a Robot in an Indoor Environment SAM; Obstacle Avodiance; BEV; Path Planning; A* Algorithm arXiv'23 [Paper] [Code] [Appendix] [Dataset] [Video] IBeaconMap: Automated Indoor Space Representation for Beacon-Based Wayfinding Indoor Navigation; Beacon Planning; Floor Plan ICCHP'20 [Paper] 综述阅读（Surveys） Title Keyword Venue Link Vision-language navigation: a survey and taxonomy Vision-and-Language Navigation (VLN); Taxonomy NCA'23 [Paper] Indoor Navigation Systems for Visually Impaired Persons: Mapping the Features of Existing Technologies to User Needs VIPs; Indoor Navigation System; Sensor; Assisstive Device; Meta Analysis Sensors'20 [Paper] A Critical Analysis of Image-based Camera Pose Estimation Techniques Camera Pose Regression; Structure-Based Localization; Absolute/Relative Pose Regression arXiv'22 [Paper] 基准测试（Benchmarking） Title Keyword Venue Link Fiducial Markers for Pose Estimation: Overview, Applications and Experimental Comparison of the ARTag, AprilTag, ArUco and STag Markers Fiducial Markers; Pose Estimation; Localization JINT'21 [Paper]"},{"title":"分类","date":"2023-11-28T04:26:23.641Z","updated":"2021-07-05T18:02:59.000Z","comments":false,"path":"categories/index.html","permalink":"https://junfish.github.io/categories/index.html","excerpt":"","text":""},{"title":"About Me","date":"2023-12-01T04:02:57.428Z","updated":"2023-12-01T04:02:36.311Z","comments":false,"path":"about/index.html","permalink":"https://junfish.github.io/about/index.html","excerpt":"","text":"Academic Activities Oct. 2023: First time Attendee (in-person) at the 25th International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS 2023), New York, NY, USA. Aug. 2023: Oral speaker (in-person) at the Modeling and Optimization: Theory and Applications (MOPTA 2023), Bethlehem, PA, USA. Dec. 2022: Oral speaker (in-person) at the International Conference on Bioinformatics and Biomedicine (BIBM 2022), Las Vegas, NV, USA. Dec. 2022: First time Attendee (in-person) at the 36th Conference on Neural Information Processing Systems (NeurIPS 2022), New Orleans, LA, USA. Oct. 2022: Oral speaker (online) at the 8th International Conference on Bioinformatics &amp; Biosciences (BIOS 2022), Vienna, Austria. Aug. 2022: Oral speaker (in-person) at the 10th International Conference on Intelligent Biology and Medicine (ICIBM 2022), Philadelphia, PA, USA. Mar. 2022: Poster presenter (online) at the 19th IEEE International Symposium on Biomedical Imaging (ISBI 2022), Kolkata, India. Sept. 2019: Poster presenter (in-person) at the 26th IEEE International Conference on Image Processing (ICIP 2019), Taipei, China. Aug. 2018: Volunteer at the 7th China Conference on Data Mining (CCDM 2018), Jinan, China. Aug. 2018: Volunteer at the 1st CCF International Conference on Artificial Intelligence (CCF-ICAI 2018), Jinan, China. Aug. 2018: Oral speaker at the 10th International Conference on Internet Multimedia Computing and Service (ICIMCS 2018), Nanjing, China. May 2017: Student of the 1st Advanced Lectures on Image and Graphics (CSIG 2017), Beijing, China. Scholarships Sept. 2021: University Fellowship, Lehigh University. (Deferred from Sept. 2020 due to the pandemic disruption). Sept. 2019: China National Scholarship, Shandong University. (Rank TOP 1 in the School of Computer Science and Technology). Sept. 2018: Second-class Postgraduate Scholarship, Shandong University. Sept. 2017: Third-class Entrance Scholarship, Shandong University. Sept. 2016: Research and Innovation Scholarship, Shandong University. Sept. 2015: Research and Innovation Scholarship, Shandong University. Hornors Aug. 2022: Travel award (up to $600) on 10th International Conference on Intelligent Biology and Medicine (ICIBM 2022). Sept. 2019: Advanced individual in innovation and entrepreneurship. Sept. 2016: First prize of Intramural Mathematical Contest in Modeling, Shandong University. Sept. 2016: Advanced individual in innovation and entrepreneurship. Sept. 2015: Advanced individual in innovation and entrepreneurship. Dec. 2015: National first prize of China Undergraduate Mathematical Contest in Modeling (Top 1% papers, Jun Yu is the team leader). Jan. 2015: Meritorious Winner of the Mathematical Contest In Modeling (Top 7% papers, Jun Yu is the team leader). Nov. 2014: The first prize of the China Undergraduate Mathematical Contest in Modeling in Shandong Province. Experience Sept. 2023 — Jun. 2024: Work as a a research assistant with Prof. Vinood Namboodiri on developing an indoor navigation solution for disabilities. Sept. 2022 — Sept. 2023: Work as a visiting student at PennCIL Lab with Prof. Yong Chen on PASC (aka Long COVID) subphenotyping. June 2022 — Sept. 2022: Work as a research assistant at Computational Uncertainty Lab with Prof. Thomas Mcandrew, aiming to model and forecast the U.S. covid-19 outbreak. July 2020 — Aug. 2020: Work part-time at Shandong Coduck Programming Technology Inc. as a C++ teacher."},{"title":"Repositories","date":"2023-11-28T04:26:23.614Z","updated":"2021-07-03T12:59:17.000Z","comments":false,"path":"repository/index.html","permalink":"https://junfish.github.io/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2023-11-28T04:26:23.620Z","updated":"2021-07-03T12:59:17.000Z","comments":false,"path":"tags/index.html","permalink":"https://junfish.github.io/tags/index.html","excerpt":"","text":""},{"title":"其他链接","date":"2021-07-04T19:25:10.000Z","updated":"2022-03-21T18:59:57.000Z","comments":true,"path":"links/index.html","permalink":"https://junfish.github.io/links/index.html","excerpt":"","text":""},{"title":"Publications","date":"2021-07-04T19:00:02.000Z","updated":"2023-11-12T23:46:30.120Z","comments":false,"path":"publications/index.html","permalink":"https://junfish.github.io/publications/index.html","excerpt":"","text":"论文发表（Papers） [11] Ce Zhou*, Qian Li*, Chen Li*, Jun Yu*, Yixin Liu*, Guangjing Wang, Kai Zhang, Cheng Ji, Qiben Yan, Lifang He, Hao Peng, Jianxin Li, Jia Wu, Ziwei Liu, Pengtao Xie, Caiming Xiong, Jian Pei, Philip S. Yu, and Lichao Sun. (*Equally Contributed). \"A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT\" In arXiv, 2023. [Paper] [10] Jun Yu, Benjamin Zalatan, Yong Chen, Li Shen, and Lifang He. \"Tensor-Based Multi-Modal Multi-Target Regression for Alzheimer’s Disease Prediction\" In 2022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), 2022. 19.8% acceptance rate. [Paper] [Slides] [Video] [9] 申朕, 崔超然, 董桂鑫, 余俊, 黄瑾, 尹义龙. 基于深度多任务学习的图像美感与情感联合预测研究. 软件学报，2022. Zhen Shen, Chaoran Cui, Guixin Dong, Jun Yu, Jin Huang, and Yilong Yin. Unified Image Aesthetic and Emotional Prediction Based on Deep Multi-task Learning. Ruan Jian Xue Bao/Journal of Software, 2022. DOI: 10.13328/j.cnki.jos.006487. [Paper] [8] Jun Yu, Yong Chen, Li Shen, and Lifang He. \"Tensor-Based Multi-Modality Multi-Target Regression for Alzheimer’s Disease Diagnosis.\" In 10th International Conference on Intelligent Biology and Medicine (ICIBM), 2022. Abstract Paper. [Paper] [Slides] [7] Jun Yu. \"Tensor Learning in Brain Network Analysis.\" Ph.D. student poster internal display. Computer Science & Engineering Department, Lehigh University. In Building C, May 9th, 2022. [Poster] Nothing to show here. Please click on Poster. [6] Jun Yu, Zhaoming Kong, Liang Zhan, Li Shen, and Lifang He. \"Tensor-based Multi-Modality Feature Selection and Regression for Alzheimer’s Disease Diagnosis.\" In 8th International Conference on Bioinformatics & Biosciences (BIOS), 2022. [Paper] [Slides] [Code] [5] Jun Yu, Zhaoming Kong, Aditya Kendre, Hao Peng, Carl Yang, Lichao Sun, Alex Leow, and Lifang He. \"Structure-Preserving Graph Kernel for Brain Network Classification.\" In 19th IEEE International Symposium on Biomedical Imaging (ISBI), pp. 1-5. 2022. [Paper] [Poster] [Slides] [Video] [4] 余俊. 基于深度多任务学习的图像美感和情感联合感知研究 [D]. 山东大学硕士毕业论文, 2020. Jun Yu. Research on Unified Aesthetics and Emotion Perception in Images Based on Deep Multi-Task Learning. Master Thesis. Shandong University, 2020. [Paper] [Code] [3] Jin Huang, Chaoran Cui, Chunyun Zhang, Zhen Shen, Jun Yu, and Yilong Yin. \"Learning Multi-Scale Attentive Features for Series Photo Selection.\" In 45th IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 2742-2746. 2020. [Paper] [2] Yuling Ma, Chaoran Cui, Jun Yu, Jie Guo, Gongping Yang, and Yilong Yin. \"Multi-task MIML learning for pre-course student performance prediction.\" Frontiers of Computer Science 14, no. 5: 1-10. 2020. [Paper] [1] Jun Yu, Chaoran Cui, LeiLei Geng, Yuling Ma, and Yilong Yin. \"Towards Unified Aesthetics and Emotion Prediction in Images.\" In 26th IEEE International Conference on Image Processing (ICIP), pp. 2526-2530. 2019. [Paper] [Dataset] [Code] 发明专利（Patents） [1] 《基于深度多任务学习的图像美感和情感联合分类方法及系统》（申请号：CN201910272826.6；主分类号：G06K 9/62；公告号：CN109978074A；发明人：崔超然，余俊，杨文雅；法律状态：公开，在审中）。余俊为除导师外第一完成人。 [著录信息] [全文] 软件著作权（Software） [1] 《面向案件全流程的审判风险多级智能推送系统 V1.0》（软著登字第：2020R11L608691）。余俊为著作权人之一。"}],"posts":[{"title":"应大学本科导员孙朋朋老师邀约给大二学子分享经验","slug":"share-my-experience","date":"2022-10-04T18:33:10.000Z","updated":"2022-10-04T18:53:27.000Z","comments":true,"path":"2022/10/04/share-my-experience/","link":"","permalink":"https://junfish.github.io/2022/10/04/share-my-experience/","excerpt":"","text":"感觉自己这一路走来很久没有静下心来写点东西，思考一下自己的过去。很感谢孙老师给了我这样的一个机会，既能帮到在我曾瓜皮过的软件园学习的学弟学妹们，又能小小地总结一下我自己最近几年的得失。我可能并没有太刻意地去组织我这样的一篇“小作文”，但是我的人生信条里是始终有着真实这样的一个词汇萦绕在心中和脑海，所以未经修饰的最原始的想法恰好处处闪烁着真实。当然，在这里还是要请同学们原谅我在词汇量匮乏（语文常年90分）和时间紧张（ddl缠身）双debuff加持下，无法给大家呈现一篇脍炙人口的，处处闪烁着智慧光芒的经验分享。 谈到经验分享，直入主题，我脑海里迅速地闪过两个和我人生息息相关的方法论，不见得正确，就当做茶余饭后的促膝谈心。 第一点是想办法往自己的特长面去造势，听起来蛮复杂的，大家听我慢慢的讲我的故事。我的学习生涯并不顺风顺水，甚至说我一直很想逃离CS系，原因么可能有很多，一方面我并没有很早的接触电脑，当身边的同学已经开始打开eclipse疯狂敲击键盘迸射智慧的火花时，我默默地下载了金山打字。你要问我为啥？简单说也简单，两个字——瓜皮。让我解释一下的话，我当时觉得工欲善其事必先利其器，你看呀，我要coding是不是打字速度得快呀，那我是不是得好好练练打字？所以我就是在这样的一种错误思考错误学习的条件下挣扎着度过了我的第一学期，当然最后几大计算机核心课程也就60分，60分意味着什么大家应该比我更清楚吧？给大家一个等式61-60&gt;1，大家自行体会。那大家会想，我肯定是一无是处的废物了？其实也不见得，我对数学有着一种近乎痴狂的热爱，我记得我的高数应该是98吧，如果我没记错的话，年代久远不太可考了，孙老师可以帮我查查，哈哈。所以大一我想的还是如何转系，当然转的是山大最好的数学系，当然我没转成功，不然也轮不到我给大家分享什么经验。所以，我带着对计算机无限地抵触留在了软件学院，那时候你要问我人生是不是一片黑暗，其实也还好，大概和梦魇开大差不多吧，还是能看得见自己在哪的。我tmd还在软件学院啊，真是日了狗了。可是，日子不是很好过，生活还得继续呀。这个时候我就开始转变思路了，回到我开篇谈到的第一个方法论，是什么来着，对，就是“想办法往自己的特长面去造势”。当时我就暗暗问过自己两个问题，在计算机学院能不能活下去？答案是可以，怎么活？跪着。第二个问题，活下来能不能学数学？答案是可以，怎么学？无人知晓地学，什么意思，没人关注你在做啥，即使你做得再好。所以，我就跪着把数学学了，这就是我的当时条件下最本真的思考。那么，我在这样的条件下是如何“造势”的呢？我就问大家，软件学院和数学最有关系的数学老师是哪一位？那就是数学建模通识课老师刘保东，我人生中最重要的一位恩师，下次见到他麻烦大家帮我向他问一声好，说一声余俊一直想着您，在这里谢谢大家了。那么我是怎么一步步勾搭上这么一位我当时感觉我需要靠近的恩师的呢？首先我查到刘老师其实以前就是数学系的老师，曾经是山大的工程数学所所长，因为工作变动调到计算机学院工作，那时候计软还是一家亲，等等。。。。。。这么说来刘老师应该去青岛工作了吧？算了，帮我问好的事情当我没说。言归正传，这样一位来自数学系的老师，我必须要享受到这份上天的“馈赠”，所以我义不容辞地选了他的数学建模课，建模课成了我一个人的必修课，我努力完成老师所有的任务，当然我所做的不仅于此，课上提到的任何软件，数学库，教科书，我都看过一遍，苦嘛累嘛？其实还好，最惨的是什么，我前面提到过，学得再好没办法装逼呀，只能无人知晓地学。那时候的我一直默默地提醒自己，我就差一个机会，一个能让我被大家知道的机会，在这个机会来之前，我一定要准备好一切，一切都是值得的。这个机会我想大家应该都知道，就是一年一度的大学生数学建模竞赛，13年本科入学，14年我就第一次参赛，很可惜，我没有抓住机会，我拿了省一等奖，甚至没有入围国家奖的选拔。当然，我也没有像我幻想的一样一鸣惊人，这就是人生，不尽如人意十之八九，对我这种平庸的人来说是这样的。可是我并没有放弃，原因很简单，我没有为自己造就足够我起飞的“势”，怎么办，我只能继续去学，默默无闻，无人知晓，没办法装逼地去学。第二年的竞赛，我一如既往地参加。在组队方面，我更加用心，我不在迷恋大神，我打造了一支属于我自己的队伍，第一次的失败告诉我，知根知底地合作比个人能力重要，这个经验算是旁菜赠送给大家的，不用客气，尽情享用。当然，这只是我个人的理解，尽信书不如无书。我的感觉是，在能力达标的情况下，合作比更强的个人能力重要，重要的太多太多太多。这一次，我终于拿到了国家一等奖，不过我还是没有等到我所期望的荣誉加身，因为，计算机学院，大家更在乎的似乎是ACM，或者intel杯，当然我也释怀了，我得到了我想要的，就足够了，大家看得起我，也就够了，还要啥自行车？后续的，我拿到了美赛一等奖。据我了解，我应该我们学院第一个国赛美赛双一等奖buff加身的人，不过也不重要了，也没人care这些。但是，我想说的重点是什么呢，我一直在往我的优势面上去靠，去造势，像后来我抓住人工智能的热潮研究机器学习，加入MLA人工智能实验室（尹义龙老师团队），也是因为机器学习是计算机学科和数学学科最完美最有机的结合。对了，大家见到尹老师也麻烦帮我说一声我想他了，对，没错，他也是我人生中最重要的恩师之一，我承认我有点花心。 第二点我想说的是不要给自己设限，如果说上一部分是我成功的一些经历，这一部分讲的都是我失败的经历了。回过头来看，其实我是能学好计算机的，因为后来我考研发现计算机也没那么难，包括复试的机试，我是能学好的。你要问我为什么拿了国一没有保研，因为我是跪着拿到国一的，什么意思？单列保研基本要求是绩点全校前50%，对，我没达到，跪着学完计算机本科课程。总结起来就是苏轼的两句词“十年生死两茫茫，不思量，自难忘。相顾无言，惟有泪千行。”扯远了，刚说到我觉得计算机也没那么难，那为什么我跪着学？因为我给自己设限，我始终暗示自己学不好计算机，其实并不是这样的，我只是没有找到很好的工程思维方式去学。希望大家能多思考思考如何不给自己设限，让自己的人生有更多的可能性，在这方面我是反面教材，大家以我为戒。还有一件我给自己设限的亲身经历就是我在申请我的PHD导师的时候，我觉得我英语口语很烂，不敢找非华人导师，我甚至拒绝了雪城大学的一位非华裔导师给我下的offer，现在想想，只有后悔。为什么？因为因此失去的机会会让你将来的路越走越窄，最终还是自己买单。然而我来到美国之后发现，美国人对语言的容忍力极高，我给自己的语言设置了一个比美国人心中对 international students 更高的 bar，导致我失去，甚至说直接放弃了很多机会。我希望大家在未来的人生追求当中，胆子大点，永远不要给自己设限，勇于尝试，勇于挑战。因为尝试孕育机会，挑战改变命运。 最后，诸君一切皆顺。 2022年十月三日凌晨于 Mountaintop Campus","categories":[{"name":"小作文","slug":"小作文","permalink":"https://junfish.github.io/categories/%E5%B0%8F%E4%BD%9C%E6%96%87/"}],"tags":[{"name":"个人感悟","slug":"个人感悟","permalink":"https://junfish.github.io/tags/%E4%B8%AA%E4%BA%BA%E6%84%9F%E6%82%9F/"}]},{"title":"Failed to initialize NVML: Driver/library version mismatch","slug":"nvidia-driver-mismatch","date":"2022-09-23T20:12:13.000Z","updated":"2022-09-23T21:37:23.000Z","comments":true,"path":"2022/09/23/nvidia-driver-mismatch/","link":"","permalink":"https://junfish.github.io/2022/09/23/nvidia-driver-mismatch/","excerpt":"","text":"Question: When I run nvidia-smi to check the usage of GPUs, the Linux feedbacks the following message: 1Failed to initialize NVML: Driver/library version mismatch This error may happen even you could still use this command 10 minutes ago. Diagnosis: The Ubuntu system set up an auto-updating for the nvidia GPU driver and create this driver/kernel mismatch. Solutions: Check the version of your GPU kernel module. cat /proc/driver/nvidia/version The feedback is something like this: 12NVRM version: NVIDIA UNIX x86_64 Kernel Module 460.106.00 Tue Sep 28 12:05:58 UTC 2021GCC version: gcc version 9.4.0 (Ubuntu 9.4.0-1ubuntu1~20.04.1) Check the recommended nvidia driver version. ubuntu-drivers devices You will get the feedback in the following: 12345678== /sys/devices/pci0000:00/0000:00:01.1/0000:01:00.0 ==modalias : pci:v000010DEd00002231sv000010DEsd0000147Ebc03sc00i00vendor : NVIDIA Corporationdriver : nvidia-driver-460 - third-party non-free recommendeddriver : nvidia-driver-515-server - distro non-freedriver : nvidia-driver-470-server - distro non-freedriver : nvidia-driver-510-server - distro non-freedriver : xserver-xorg-video-nouveau - distro free builtin Note: You will see a mismatch between the recommended version and existed version for your nvidia driver. Remove the mismatched driver sudo apt-get --purge remove nvidia* Install the recommended nvidia driver version sudo apt install nvidia-driver-460 Reboot your machine sudo reboot Then, check the GPU status again nvidia-smi. Reference [1] Nvidia NVML Driver/library version mismatch [closed] [2] ubuntu20.04 nvidia-smi命令报错Failed to initialize NVML: Driver/library version mismatch解决办法–重启电脑","categories":[{"name":"Debugging","slug":"Debugging","permalink":"https://junfish.github.io/categories/Debugging/"}],"tags":[{"name":"Nvidia","slug":"Nvidia","permalink":"https://junfish.github.io/tags/Nvidia/"},{"name":"GPU","slug":"GPU","permalink":"https://junfish.github.io/tags/GPU/"},{"name":"driver","slug":"driver","permalink":"https://junfish.github.io/tags/driver/"}]},{"title":"The Matrix Calculus","slug":"matrix-calculus","date":"2022-08-25T02:03:22.000Z","updated":"2023-09-14T02:09:14.041Z","comments":true,"path":"2022/08/24/matrix-calculus/","link":"","permalink":"https://junfish.github.io/2022/08/24/matrix-calculus/","excerpt":"","text":"介绍 Introduction In this post, we hope to solve all derivative problems with matrix via the matrix differentiation + trace trick. We denote by lowercase letter xxx, bold lowercase letter x\\boldsymbol{x}x, and bold uppercase letter X\\boldsymbol{X}X a scalar, a vector, and a matrix, respectively. If we denote the entry of a vector and a matrix by xix_ixi​ and xi,jx_{i,j}xi,j​, and f(X)f(\\boldsymbol{X})f(X) denotes the function of matrix X\\boldsymbol{X}X, then we can intuitively define the dirivative of fff to X\\boldsymbol{X}X as: ∇Xf=[∂f∂x1,1⋯∂f∂x1,n⋮⋱⋮∂f∂xm,1⋯∂f∂xm,n]\\nabla_{\\boldsymbol{X}}f = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_{1,1}} &amp; \\cdots &amp; \\frac{\\partial f}{\\partial x_{1,n}} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\frac{\\partial f}{\\partial x_{m,1}} &amp; \\cdots &amp; \\frac{\\partial f}{\\partial x_{m,n}} \\end{bmatrix}∇X​f=⎣⎢⎢⎢⎡​∂x1,1​∂f​⋮∂xm,1​∂f​​⋯⋱⋯​∂x1,n​∂f​⋮∂xm,n​∂f​​⎦⎥⎥⎥⎤​ Futhermore, we can build the connection between this derivation and matrix calculus as follows: df=∑i=1m∑j=1n∂f∂xi,j=tr[(∇Xf)⊤dX]\\text{d}f=\\sum_{i=1}^m\\sum_{j=1}^n\\frac{\\partial f}{\\partial x_{i,j}}=\\text{tr}[(\\nabla_{\\boldsymbol{X}}f)^\\top\\text{d}\\boldsymbol{X}]df=∑i=1m​∑j=1n​∂xi,j​∂f​=tr[(∇X​f)⊤dX]. 在这篇博客中，我们通过微分的思想来统一解决矩阵的一系列求导问题。我们用小写字母 xxx, 小写粗体字母 x\\boldsymbol{x}x, 大写粗体字母 X\\boldsymbol{X}X 分别表示标量，向量和矩阵。 其中向量的元素表示为 xix_ixi​, 矩阵的元素表示为 xi,jx_{i,j}xi,j​。 如果 f(X)f(\\boldsymbol{X})f(X) 表示关于矩阵X\\boldsymbol{X}X的函数，则fff关于矩阵X\\boldsymbol{X}X的导数可以直觉地定义为: ∇Xf=[∂f∂x1,1⋯∂f∂x1,n⋮⋱⋮∂f∂xm,1⋯∂f∂xm,n]\\nabla_{\\boldsymbol{X}}f = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_{1,1}} &amp; \\cdots &amp; \\frac{\\partial f}{\\partial x_{1,n}} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\frac{\\partial f}{\\partial x_{m,1}} &amp; \\cdots &amp; \\frac{\\partial f}{\\partial x_{m,n}} \\end{bmatrix}∇X​f=⎣⎢⎢⎢⎡​∂x1,1​∂f​⋮∂xm,1​∂f​​⋯⋱⋯​∂x1,n​∂f​⋮∂xm,n​∂f​​⎦⎥⎥⎥⎤​ 从而，我们可以建立起矩阵与微分的关联： df=∑i=1m∑j=1n∂f∂xi,j=tr[(∇Xf)⊤dX]\\text{d}f=\\sum_{i=1}^m\\sum_{j=1}^n\\frac{\\partial f}{\\partial x_{i,j}}=\\text{tr}[(\\nabla_{\\boldsymbol{X}}f)^\\top\\text{d}\\boldsymbol{X}]df=∑i=1m​∑j=1n​∂xi,j​∂f​=tr[(∇X​f)⊤dX]. The operational criterion for matrix differentiation 矩阵微分运算法则 d(X±Y)=dX±dY\\color{green} \\text{d}(\\boldsymbol{X}\\pm\\boldsymbol{Y})=\\text{d}\\boldsymbol{X}\\pm\\text{d}\\boldsymbol{Y}d(X±Y)=dX±dY d（XY）=(dX)Y+XdY\\color{green}\\text{d}（\\boldsymbol{X}\\boldsymbol{Y}）=(\\text{d}\\boldsymbol{X})\\boldsymbol{Y}+\\boldsymbol{X}\\text{d}\\boldsymbol{Y}d（XY）=(dX)Y+XdY d(X⊤)=(dX)⊤\\color{green}\\text{d}(\\boldsymbol{X}^\\top) = (\\text{d}\\boldsymbol{X})^\\topd(X⊤)=(dX)⊤ d(tr(X))=tr(dX)\\color{green}\\text{d}(\\text{tr}(\\boldsymbol{X})) = \\text{tr}(\\text{d}\\boldsymbol{X})d(tr(X))=tr(dX) dX−1=−X−1(dX)X−1\\color{green}\\text{d} \\boldsymbol{X}^{-1} = -\\boldsymbol{X}^{-1}(\\text{d}\\boldsymbol{X})\\boldsymbol{X}^{-1}dX−1=−X−1(dX)X−1 d∣X∣=∣X∣tr(X−1dX)\\color{green}\\text{d}|\\boldsymbol{X}| = |\\boldsymbol{X}|\\text{tr}(\\boldsymbol{X}^{-1}\\text{d}\\boldsymbol{X})d∣X∣=∣X∣tr(X−1dX) d(X⊙Y)=dX⊙Y+X⊙dY\\color{green}\\text{d} (\\boldsymbol{X}\\odot\\boldsymbol{Y}) = \\text{d}\\boldsymbol{X}\\odot\\boldsymbol{Y} + \\boldsymbol{X}\\odot \\text{d}\\boldsymbol{Y}d(X⊙Y)=dX⊙Y+X⊙dY dσ(X)=σ′(X)⊙dX，其中 σ(⋅) 为在位函数操作\\color{green}\\text{d} \\sigma(\\boldsymbol{X}) = \\sigma^{\\prime}(\\boldsymbol{X})\\odot \\text{d}\\boldsymbol{X}\\text{，其中}~\\sigma(\\cdot)~为在位函数操作dσ(X)=σ′(X)⊙dX，其中 σ(⋅) 为在位函数操作 Derivative of the Scalar to Matrix Trace Trick a=tr(a)\\color{green}a=\\text{tr}(a)a=tr(a) tr(A)=tr(A⊤)\\color{green}\\text{tr}(\\boldsymbol{A})=\\text{tr}(\\boldsymbol{A}^\\top)tr(A)=tr(A⊤) tr(A±B)=tr(A)±tr(B)\\color{green}\\text{tr}(\\boldsymbol{A}\\pm\\boldsymbol{B}) = \\text{tr}(\\boldsymbol{A}) \\pm \\text{tr}(\\boldsymbol{B})tr(A±B)=tr(A)±tr(B) tr(A⊤B)=∑i∑jai,jbi,j\\color{green}\\text{tr}(\\boldsymbol{A}^\\top\\boldsymbol{B}) = \\sum_i\\sum_j a_{i,j}b_{i,j}tr(A⊤B)=∑i​∑j​ai,j​bi,j​ tr(A⊤B)=tr(BA⊤)=tr(B⊤A)=tr(AB⊤)\\color{green}\\text{tr}(\\boldsymbol{A}^\\top\\boldsymbol{B}) = \\text{tr}(\\boldsymbol{B}\\boldsymbol{A}^\\top) = \\text{tr}(\\boldsymbol{B}^\\top\\boldsymbol{A}) = \\text{tr}(\\boldsymbol{A}\\boldsymbol{B}^\\top)tr(A⊤B)=tr(BA⊤)=tr(B⊤A)=tr(AB⊤) tr[A⊤(B⊙C)]=tr[(A⊙B)⊤C]=∑i∑jai,jbi,jci,j\\color{green}\\text{tr}[\\boldsymbol{A}^\\top(\\boldsymbol{B}\\odot\\boldsymbol{C})] = \\text{tr}[(\\boldsymbol{A}\\odot\\boldsymbol{B})^\\top\\boldsymbol{C}] = \\sum_i\\sum_j a_{i,j}b_{i,j}c_{i,j}tr[A⊤(B⊙C)]=tr[(A⊙B)⊤C]=∑i​∑j​ai,j​bi,j​ci,j​ 例1. 构造函数 No.1 f=a⊤Xb,a∈Rm×1,X∈Rm×n,b∈Rn×1f = \\boldsymbol{a}^\\top \\boldsymbol{X} \\boldsymbol{b}, \\boldsymbol{a}\\in\\mathbb{R}^{m\\times 1}, \\boldsymbol{X}\\in\\mathbb{R}^{m\\times n}, \\boldsymbol{b}\\in\\mathbb{R}^{n\\times1}f=a⊤Xb,a∈Rm×1,X∈Rm×n,b∈Rn×1. Process: df\\text{d} fdf $ = \\text{d}(\\boldsymbol{a}^\\top\\boldsymbol{X}\\boldsymbol{b})$ =tr[d(a⊤Xb)]= \\text{tr}[\\text{d}(\\boldsymbol{a}^\\top\\boldsymbol{X}\\boldsymbol{b})]=tr[d(a⊤Xb)] =tr[a⊤(dX)b]= \\text{tr}[\\boldsymbol{a}^\\top(\\text{d}\\boldsymbol{X})\\boldsymbol{b}]=tr[a⊤(dX)b] =tr(ba⊤dX)= \\text{tr} (\\boldsymbol{b}\\boldsymbol{a}^\\top\\text{d}\\boldsymbol{X})=tr(ba⊤dX) =tr[(ab⊤)⊤dX]= \\text{tr} [(\\boldsymbol{a}\\boldsymbol{b}^\\top)^\\top\\text{d}\\boldsymbol{X}]=tr[(ab⊤)⊤dX] Answer: ∂f∂X=ab⊤\\frac{\\partial f}{\\partial \\boldsymbol{X}} = \\boldsymbol{a}\\boldsymbol{b}^\\top∂X∂f​=ab⊤ 例 2. 构造函数 No.2 f=a⊤eXb,a∈Rm×1,X∈Rm×n,b∈Rn×1f = \\boldsymbol{a}^\\top e^{\\boldsymbol{X}\\boldsymbol{b}}, \\boldsymbol{a}\\in\\mathbb{R}^{m\\times 1}, \\boldsymbol{X}\\in\\mathbb{R}^{m\\times n}, \\boldsymbol{b}\\in\\mathbb{R}^{n\\times 1}f=a⊤eXb,a∈Rm×1,X∈Rm×n,b∈Rn×1. Process: df\\text{d} fdf $ = \\text{d}(\\boldsymbol{a}^\\top e^{\\boldsymbol{X}\\boldsymbol{b}}) = \\text{tr}[\\boldsymbol{a}\\top\\text{d}(e{\\boldsymbol{X}\\boldsymbol{b}})]$ =tr{a⊤[eXb⊙d(Xb)]}= \\text{tr} \\{\\boldsymbol{a}^\\top [e^{\\boldsymbol{X}\\boldsymbol{b}}\\odot\\text{d}(\\boldsymbol{X}\\boldsymbol{b})]\\}=tr{a⊤[eXb⊙d(Xb)]} =tr[(a⊙eXb)⊤d(Xb)]= \\text{tr} [{(\\boldsymbol{a}\\odot e^{\\boldsymbol{X}\\boldsymbol{b}})}^\\top \\text{d}(\\boldsymbol{X}\\boldsymbol{b})]=tr[(a⊙eXb)⊤d(Xb)] =tr[(a⊙eXb)⊤(dX)b]= \\text{tr} [{(\\boldsymbol{a}\\odot e^{\\boldsymbol{X}\\boldsymbol{b}})}^\\top (\\text{d}\\boldsymbol{X})\\boldsymbol{b}]=tr[(a⊙eXb)⊤(dX)b] =tr[b(a⊙eXb)⊤dX]= \\text{tr} [\\boldsymbol{b}{(\\boldsymbol{a}\\odot e^{\\boldsymbol{X}\\boldsymbol{b}})}^\\top \\text{d}\\boldsymbol{X}]=tr[b(a⊙eXb)⊤dX] =tr{[(a⊙eXb)b⊤]⊤dX}= \\text{tr} \\{[(\\boldsymbol{a}\\odot e^{\\boldsymbol{X}\\boldsymbol{b}})\\boldsymbol{b}^\\top]^\\top \\text{d}\\boldsymbol{X}\\}=tr{[(a⊙eXb)b⊤]⊤dX} Answer: ∂f∂X=(a⊙eXb)b⊤\\frac{\\partial f}{\\partial \\boldsymbol{X}} = (\\boldsymbol{a}\\odot e^{\\boldsymbol{X}\\boldsymbol{b}})\\boldsymbol{b}^\\top∂X∂f​=(a⊙eXb)b⊤ 例 3. 构造函数 No.3 f=tr(Y⊤MY),Y=σ(WX),W∈Rl×m,X∈Rm×n,M∈Rl×lf = tr(\\boldsymbol{Y}^\\top \\boldsymbol{M}\\boldsymbol{Y}), Y = \\sigma(\\boldsymbol{W}\\boldsymbol{X}), \\boldsymbol{W}\\in\\mathbb{R}^{l\\times m}, \\boldsymbol{X}\\in\\mathbb{R}^{m\\times n}, \\boldsymbol{M}\\in\\mathbb{R}^{l\\times l}f=tr(Y⊤MY),Y=σ(WX),W∈Rl×m,X∈Rm×n,M∈Rl×l. Process: df\\text{d} fdf $ = \\text{tr} [\\text{d} (\\boldsymbol{Y}^\\top\\boldsymbol{M}\\boldsymbol{Y})]$ =tr[d(Y⊤)MY+Y⊤MdY]= \\text{tr} [\\text{d} (\\boldsymbol{Y}^\\top) \\boldsymbol{M}\\boldsymbol{Y} + \\boldsymbol{Y}^\\top\\boldsymbol{M}\\text{d}\\boldsymbol{Y}]=tr[d(Y⊤)MY+Y⊤MdY] =tr[(dY)⊤MY]+tr(Y⊤MdY)= \\text{tr}[(\\text{d}\\boldsymbol{Y})^\\top\\boldsymbol{M}\\boldsymbol{Y}] + \\text{tr} (\\boldsymbol{Y}^\\top\\boldsymbol{M}\\text{d}\\boldsymbol{Y})=tr[(dY)⊤MY]+tr(Y⊤MdY) =tr(Y⊤M⊤dY)+tr(Y⊤MdY)= \\text{tr}(\\boldsymbol{Y}^\\top\\boldsymbol{M}^\\top\\text{d}\\boldsymbol{Y}) + \\text{tr} (\\boldsymbol{Y}^\\top\\boldsymbol{M}\\text{d}\\boldsymbol{Y})=tr(Y⊤M⊤dY)+tr(Y⊤MdY) =tr[Y⊤(M⊤+M)dY]= \\text{tr} [\\boldsymbol{Y}^\\top(\\boldsymbol{M}^\\top + \\boldsymbol{M})\\text{d}\\boldsymbol{Y}]=tr[Y⊤(M⊤+M)dY] =tr[Y⊤(M⊤+M)dσ(WX)]= \\text{tr} [\\boldsymbol{Y}^\\top(\\boldsymbol{M}^\\top + \\boldsymbol{M})\\text{d}\\sigma(\\boldsymbol{W}\\boldsymbol{X})]=tr[Y⊤(M⊤+M)dσ(WX)] =tr{Y⊤(M⊤+M)[σ′(WX)⊙d(WX)]}= \\text{tr} \\{\\boldsymbol{Y}^\\top(\\boldsymbol{M}^\\top + \\boldsymbol{M})[\\sigma^{\\prime}(\\boldsymbol{W}\\boldsymbol{X}) \\odot \\text{d}(\\boldsymbol{W}\\boldsymbol{X})]\\}=tr{Y⊤(M⊤+M)[σ′(WX)⊙d(WX)]} =tr{{[(M⊤+M)⊤Y]⊙σ′(WX)}⊤d(WX)}= \\text{tr} \\left\\{\\{[(\\boldsymbol{M}^\\top + \\boldsymbol{M})^\\top\\boldsymbol{Y}]\\odot\\sigma^{\\prime}(\\boldsymbol{W}\\boldsymbol{X})\\}^\\top\\text{d}(\\boldsymbol{W}\\boldsymbol{X})\\right\\}=tr{{[(M⊤+M)⊤Y]⊙σ′(WX)}⊤d(WX)} =tr{{[(M⊤+M)Y]⊙σ′(WX)}⊤WdX}= \\text{tr} \\left\\{\\{[(\\boldsymbol{M}^\\top + \\boldsymbol{M})\\boldsymbol{Y}]\\odot\\sigma^{\\prime}(\\boldsymbol{W}\\boldsymbol{X})\\}^\\top\\boldsymbol{W}\\text{d}\\boldsymbol{X}\\right\\}=tr{{[(M⊤+M)Y]⊙σ′(WX)}⊤WdX} =tr{{W⊤{[(M⊤+M)Y]⊙σ′(WX)}}⊤dX}= \\text{tr} \\left\\{\\left\\{\\boldsymbol{W}^\\top\\{[(\\boldsymbol{M}^\\top + \\boldsymbol{M})\\boldsymbol{Y}]\\odot\\sigma^{\\prime}(\\boldsymbol{W}\\boldsymbol{X})\\}\\right\\}^\\top\\text{d}\\boldsymbol{X}\\right\\}=tr{{W⊤{[(M⊤+M)Y]⊙σ′(WX)}}⊤dX} Answer: ∂f∂X=W⊤{[(M+M⊤)σ(WX)]⊙σ′(WX)}\\frac{\\partial f}{\\partial \\boldsymbol{X}} = \\boldsymbol{W}^\\top\\{[(\\boldsymbol{M} + \\boldsymbol{M}^\\top)\\sigma(\\boldsymbol{W}\\boldsymbol{X})] \\odot \\sigma^{\\prime}(\\boldsymbol{W}\\boldsymbol{X})\\}∂X∂f​=W⊤{[(M+M⊤)σ(WX)]⊙σ′(WX)} 例 4. Linear Regression ℓ=∥Xw−y∥22,X∈Rm×n,w∈Rn×1,y∈Rm×1\\ell = \\|\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y}\\|_2^2, \\boldsymbol{X}\\in\\mathbb{R}^{m\\times n}, \\boldsymbol{w}\\in\\mathbb{R}^{n\\times 1}, \\boldsymbol{y}\\in\\mathbb{R}^{m\\times 1}ℓ=∥Xw−y∥22​,X∈Rm×n,w∈Rn×1,y∈Rm×1. Process: $\\text{d} l $ =d[(Xw−y)⊤(Xw−y)]= \\text{d} [(\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y})^\\top(\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y})]=d[(Xw−y)⊤(Xw−y)] =tr{[d(Xw−y)⊤](Xw−y)+(Xw−y)⊤d(Xw−y)}= \\text{tr}\\{[\\text{d} (\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y})^\\top] (\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y}) + (\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y})^\\top \\text{d}(\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y})\\}=tr{[d(Xw−y)⊤](Xw−y)+(Xw−y)⊤d(Xw−y)} =tr{(Xdw)⊤(Xw−y)+(Xw−y)⊤(Xdw)}= \\text{tr}\\{(\\boldsymbol{X}\\text{d}\\boldsymbol{w})^\\top(\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y}) + (\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y})^\\top(\\boldsymbol{X}\\text{d}\\boldsymbol{w})\\}=tr{(Xdw)⊤(Xw−y)+(Xw−y)⊤(Xdw)} =tr[(Xdw)⊤(Xw−y)+(Xw−y)⊤(Xdw)]= \\text{tr}[(\\boldsymbol{X}\\text{d}\\boldsymbol{w})^\\top(\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y}) + (\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y})^\\top(\\boldsymbol{X}\\text{d}\\boldsymbol{w})]=tr[(Xdw)⊤(Xw−y)+(Xw−y)⊤(Xdw)] =tr[(Xw−y)⊤(Xdw)+(Xw−y)⊤(Xdw)]= \\text{tr}[(\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y})^\\top(\\boldsymbol{X}\\text{d}\\boldsymbol{w}) + (\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y})^\\top(\\boldsymbol{X}\\text{d}\\boldsymbol{w})]=tr[(Xw−y)⊤(Xdw)+(Xw−y)⊤(Xdw)] =tr[2(Xw−y)⊤Xdw]= \\text{tr}[2(\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y})^\\top\\boldsymbol{X}\\text{d}\\boldsymbol{w}]=tr[2(Xw−y)⊤Xdw] =tr{2[X⊤(Xw−y)]⊤dw}= \\text{tr}\\{2[\\boldsymbol{X}^\\top(\\boldsymbol{X}\\boldsymbol{w} - \\boldsymbol{y})]^\\top\\text{d}\\boldsymbol{w}\\}=tr{2[X⊤(Xw−y)]⊤dw} Answer: ∂ℓ∂w=2X⊤Xw−2X⊤y→w=(X⊤X)−1X⊤y\\frac{\\partial \\ell}{\\partial \\boldsymbol{w}} = 2\\boldsymbol{X}^\\top\\boldsymbol{X}\\boldsymbol{w} - 2\\boldsymbol{X}^\\top\\boldsymbol{y} \\rightarrow \\boldsymbol{w} = (\\boldsymbol{X}^\\top\\boldsymbol{X})^{-1}\\boldsymbol{X}^\\top\\boldsymbol{y}∂w∂ℓ​=2X⊤Xw−2X⊤y→w=(X⊤X)−1X⊤y 例 5. Maximum Likelihood Estimation (MLE) for the Multivariate Normal Distribution x1,⋯ ,xN∼N(μ,Σ),ℓ=MLE(Σ)=log⁡∣Σ∣+1N∑i=1N(xi−x‾)⊤Σ−1(xi−x‾),x‾=1N∑i=1Nxi,Σ∈Rm×m\\boldsymbol{x}_1, \\cdots, \\boldsymbol{x}_N \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma}), \\ell = MLE(\\boldsymbol{\\Sigma}) = \\log |\\boldsymbol{\\Sigma}| + \\frac{1}{N}\\sum_{i=1}^N{(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})}^\\top\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}}), \\overline{\\boldsymbol{x}} = \\frac{1}{N}\\sum_{i=1}^N\\boldsymbol{x}_i, \\boldsymbol{\\Sigma}\\in\\mathbb{R}^{m\\times m}x1​,⋯,xN​∼N(μ,Σ),ℓ=MLE(Σ)=log∣Σ∣+N1​∑i=1N​(xi​−x)⊤Σ−1(xi​−x),x=N1​∑i=1N​xi​,Σ∈Rm×m. Process: $\\text{d} \\ell $ =tr[d(log⁡∣Σ∣)+1N∑i=1N(xi−x‾)⊤(dΣ−1)(xi−x‾)]= \\text{tr} [\\text{d} (\\log|\\boldsymbol{\\Sigma}|) + \\frac{1}{N}\\sum_{i=1}^N(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})^\\top(\\text{d}\\boldsymbol{\\Sigma}^{-1})(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})]=tr[d(log∣Σ∣)+N1​∑i=1N​(xi​−x)⊤(dΣ−1)(xi​−x)] =tr(1∣Σ∣⊙d∣Σ∣)+1N∑i=1Ntr[(xi−x‾)⊤(dΣ−1)(xi−x‾)]= \\text{tr} (\\frac{1}{|\\boldsymbol{\\Sigma}|}\\odot\\text{d}|\\boldsymbol{\\Sigma}|) + \\frac{1}{N}\\sum_{i=1}^N\\text{tr}[(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})^\\top(\\text{d}\\boldsymbol{\\Sigma}^{-1})(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})]=tr(∣Σ∣1​⊙d∣Σ∣)+N1​∑i=1N​tr[(xi​−x)⊤(dΣ−1)(xi​−x)] =tr{1∣Σ∣⋅∣Σ∣tr(Σ−1dΣ)}+1N∑i=1Ntr[(xi−x‾)(xi−x‾)⊤(dΣ−1)]= \\text{tr} \\{\\frac{1}{|\\boldsymbol{\\Sigma}|}\\cdot|\\boldsymbol{\\Sigma}|\\text{tr}(\\boldsymbol{\\Sigma}^{-1}\\text{d}\\boldsymbol{\\Sigma})\\} + \\frac{1}{N}\\sum_{i=1}^N\\text{tr}[(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})^\\top(\\text{d}\\boldsymbol{\\Sigma}^{-1})]=tr{∣Σ∣1​⋅∣Σ∣tr(Σ−1dΣ)}+N1​∑i=1N​tr[(xi​−x)(xi​−x)⊤(dΣ−1)] =tr(Σ−1dΣ)−1N∑i=1Ntr{(xi−x‾)(xi−x‾)⊤[Σ−1(dΣ)Σ−1]}= \\text{tr}(\\boldsymbol{\\Sigma}^{-1}\\text{d}\\boldsymbol{\\Sigma}) - \\frac{1}{N}\\sum_{i=1}^N\\text{tr}\\{(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})^\\top[\\boldsymbol{\\Sigma}^{-1}(\\text{d}\\boldsymbol{\\Sigma})\\boldsymbol{\\Sigma}^{-1}]\\}=tr(Σ−1dΣ)−N1​∑i=1N​tr{(xi​−x)(xi​−x)⊤[Σ−1(dΣ)Σ−1]} =tr(Σ−1dΣ)−1N∑i=1Ntr[Σ−1(xi−x‾)(xi−x‾)⊤Σ−1dΣ]= \\text{tr}(\\boldsymbol{\\Sigma}^{-1}\\text{d}\\boldsymbol{\\Sigma}) - \\frac{1}{N}\\sum_{i=1}^N\\text{tr}[\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})^\\top\\boldsymbol{\\Sigma}^{-1}\\text{d}\\boldsymbol{\\Sigma}]=tr(Σ−1dΣ)−N1​∑i=1N​tr[Σ−1(xi​−x)(xi​−x)⊤Σ−1dΣ] =tr{[Σ−1−1N∑i=1NΣ−1(xi−x‾)(xi−x‾)⊤Σ−1]dΣ}= \\text{tr}\\left\\{[\\boldsymbol{\\Sigma}^{-1} - \\frac{1}{N}\\sum_{i=1}^N \\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})^\\top\\boldsymbol{\\Sigma}^{-1}]\\text{d}\\boldsymbol{\\Sigma}\\right\\}=tr{[Σ−1−N1​∑i=1N​Σ−1(xi​−x)(xi​−x)⊤Σ−1]dΣ} Answer: ∂ℓ∂Σ={Σ−1−1N∑i=1NΣ−1[(xi−x‾)(xi−x‾)⊤]Σ−1}⊤\\frac{\\partial \\ell}{\\partial \\boldsymbol{\\Sigma}} = {\\{\\boldsymbol{\\Sigma}^{-1} - \\frac{1}{N}\\sum_{i=1}^N\\boldsymbol{\\Sigma}^{-1}[(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}}){(\\boldsymbol{x}_i - \\overline{\\boldsymbol{x}})}^\\top]\\boldsymbol{\\Sigma}^{-1}\\}}^\\top∂Σ∂ℓ​={Σ−1−N1​∑i=1N​Σ−1[(xi​−x)(xi​−x)⊤]Σ−1}⊤ 例 6. Multinomial Logistic Regression. ℓ=−y⊤log⁡softmax(Wx),y is a one-hot encoding vector with size m,W∈Rm×n,x∈Rn×1,y∈Rm×1,softmax(a)=ea1⊤ea\\ell = -\\boldsymbol{y}^\\top \\log softmax(\\boldsymbol{W}\\boldsymbol{x}), \\boldsymbol{y} \\text{ is a one-hot encoding vector with size } m, \\boldsymbol{W}\\in\\mathbb{R}^{m\\times n}, \\boldsymbol{x}\\in\\mathbb{R}^{n\\times 1}, \\boldsymbol{y}\\in\\mathbb{R}^{m\\times 1}, softmax(\\boldsymbol{a}) = \\frac{e^{\\boldsymbol{a}}}{\\boldsymbol{1}^\\top e^{\\boldsymbol{a}}}ℓ=−y⊤logsoftmax(Wx),y is a one-hot encoding vector with size m,W∈Rm×n,x∈Rn×1,y∈Rm×1,softmax(a)=1⊤eaea​. Process: $\\ell $ =−y⊤log⁡softmax(Wx)= -\\boldsymbol{y}^\\top\\log \\text{softmax}(\\boldsymbol{W}\\boldsymbol{x})=−y⊤logsoftmax(Wx) =−y⊤log⁡eWx1⊤eWx= -\\boldsymbol{y}^\\top\\log \\frac{\\text{e}^{\\boldsymbol{W}\\boldsymbol{x}}}{\\boldsymbol{1}^\\top\\text{e}^{\\boldsymbol{W}\\boldsymbol{x}}}=−y⊤log1⊤eWxeWx​ =−y⊤(Wx)+y⊤log⁡[1⋅(1⊤eWx)]= -\\boldsymbol{y}^\\top (\\boldsymbol{W}\\boldsymbol{x}) + \\boldsymbol{y}^\\top\\log [\\boldsymbol{1}\\cdot(\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}})]=−y⊤(Wx)+y⊤log[1⋅(1⊤eWx)] =−y⊤(Wx)+(y⊤1)log⁡(1⊤eWx)= -\\boldsymbol{y}^\\top (\\boldsymbol{W}\\boldsymbol{x}) + (\\boldsymbol{y}^\\top\\boldsymbol{1})\\log (\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}})=−y⊤(Wx)+(y⊤1)log(1⊤eWx) =−y⊤(Wx)+log⁡(1⊤eWx)= -\\boldsymbol{y}^\\top (\\boldsymbol{W}\\boldsymbol{x}) + \\log (\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}})=−y⊤(Wx)+log(1⊤eWx) $\\text{d} \\ell $ =tr[−y⊤(dW)x+11⊤eWxd(1⊤eWx)]= \\text{tr} [-\\boldsymbol{y}^\\top(\\text{d}\\boldsymbol{W})\\boldsymbol{x} + \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}}\\text{d}(\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}})]=tr[−y⊤(dW)x+1⊤eWx1​d(1⊤eWx)] =tr[−y⊤(dW)x+11⊤eWx⋅1⊤deWx]= \\text{tr} [-\\boldsymbol{y}^\\top(\\text{d}\\boldsymbol{W})\\boldsymbol{x} + \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}}\\cdot\\boldsymbol{1}^\\top\\text{d}e^{\\boldsymbol{W}\\boldsymbol{x}}]=tr[−y⊤(dW)x+1⊤eWx1​⋅1⊤deWx] =tr{−y⊤(dW)x+11⊤eWx⋅1⊤[eWx⊙d(Wx)]}= \\text{tr} \\{-\\boldsymbol{y}^\\top(\\text{d}\\boldsymbol{W})\\boldsymbol{x} + \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}}\\cdot \\boldsymbol{1}^\\top [e^{\\boldsymbol{W}\\boldsymbol{x}}\\odot\\text{d}(\\boldsymbol{W}\\boldsymbol{x})]\\}=tr{−y⊤(dW)x+1⊤eWx1​⋅1⊤[eWx⊙d(Wx)]} =tr[−y⊤(dW)x]+11⊤eWxtr{1⊤[eWx⊙d(Wx)]}= \\text{tr} [-\\boldsymbol{y}^\\top(\\text{d}\\boldsymbol{W})\\boldsymbol{x}] + \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}}\\text{tr} \\{\\boldsymbol{1}^\\top [e^{\\boldsymbol{W}\\boldsymbol{x}}\\odot\\text{d}(\\boldsymbol{W}\\boldsymbol{x})]\\}=tr[−y⊤(dW)x]+1⊤eWx1​tr{1⊤[eWx⊙d(Wx)]} =tr[−y⊤(dW)x]+11⊤eWxtr[(1⊙eWx)⊤d(Wx)]= \\text{tr} [-\\boldsymbol{y}^\\top(\\text{d}\\boldsymbol{W})\\boldsymbol{x}] + \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}}\\text{tr} [(\\boldsymbol{1}\\odot e^{\\boldsymbol{W}\\boldsymbol{x}})^\\top\\text{d}(\\boldsymbol{W}\\boldsymbol{x})]=tr[−y⊤(dW)x]+1⊤eWx1​tr[(1⊙eWx)⊤d(Wx)] =tr(−xy⊤dW)+11⊤eWxtr[(1⊙eWx)⊤(dW)x]= \\text{tr} (-\\boldsymbol{x}\\boldsymbol{y}^\\top\\text{d}\\boldsymbol{W}) + \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}}\\text{tr} [(\\boldsymbol{1}\\odot e^{\\boldsymbol{W}\\boldsymbol{x}})^\\top(\\text{d}\\boldsymbol{W})\\boldsymbol{x}]=tr(−xy⊤dW)+1⊤eWx1​tr[(1⊙eWx)⊤(dW)x] =tr{[−xy⊤+x(eWx)⊤1⊤eWx]dW}= \\text{tr} \\{[-\\boldsymbol{x}\\boldsymbol{y}^\\top + \\boldsymbol{x}\\frac{(e^{\\boldsymbol{W}\\boldsymbol{x}})^\\top}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}}]\\text{d}\\boldsymbol{W}\\}=tr{[−xy⊤+x1⊤eWx(eWx)⊤​]dW} =tr{[(eWx1⊤eWx−y)x⊤]⊤dW}= \\text{tr} \\left\\{[(\\frac{e^{\\boldsymbol{W}\\boldsymbol{x}}}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}} - \\boldsymbol{y})\\boldsymbol{x}^\\top]^\\top\\text{d}\\boldsymbol{W}\\right\\}=tr{[(1⊤eWxeWx​−y)x⊤]⊤dW} Answer: ∂ℓ∂W=[softmax(Wx)−y]x⊤\\frac{\\partial \\ell}{\\partial \\boldsymbol{W}} = [softmax(\\boldsymbol{W}\\boldsymbol{x}) - \\boldsymbol{y}]\\boldsymbol{x}^\\top∂W∂ℓ​=[softmax(Wx)−y]x⊤ 例 7. Back Propagation (BP) for Multi-Layer Perceptron (MLP) ℓ=−∑i=1Nyi⊤log⁡softmax[W2σ(W1xi+b1)+b2],xi∈Rn×1,yi is a one-hot encoding vector with size m,\\ell = - \\sum_{i=1}^N \\boldsymbol{y}_i^\\top\\log softmax[\\boldsymbol{W}_2 \\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2], \\boldsymbol{x}_i \\in \\mathbb{R}^{n\\times 1}, \\boldsymbol{y}_i \\text{ is a one-hot encoding vector with size } m,ℓ=−∑i=1N​yi⊤​logsoftmax[W2​σ(W1​xi​+b1​)+b2​],xi​∈Rn×1,yi​ is a one-hot encoding vector with size m, W1∈Rp×n,b1∈Rp×1,W2∈Rm×p,b2∈Rm×1\\boldsymbol{W}_1 \\in \\mathbb{R}^{p\\times n}, \\boldsymbol{b}_1 \\in \\mathbb{R}^{p\\times 1}, \\boldsymbol{W}_2 \\in \\mathbb{R}^{m\\times p}, \\boldsymbol{b}_2 \\in \\mathbb{R}^{m\\times 1}W1​∈Rp×n,b1​∈Rp×1,W2​∈Rm×p,b2​∈Rm×1. Process: $\\ell $ =−∑i=1Nyi⊤log⁡softmax[W2σ(W1xi+b1)+b2]= -\\sum_{i=1}^N\\boldsymbol{y}_i^{\\top}\\log\\text{softmax}[\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2]=−∑i=1N​yi⊤​logsoftmax[W2​σ(W1​xi​+b1​)+b2​] =−∑i=1Nyi⊤log⁡eW2σ(W1xi+b1)+b21⊤eW2σ(W1xi+b1)+b2= -\\sum_{i=1}^N \\boldsymbol{y}_i^\\top \\log\\frac{e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}}=−∑i=1N​yi⊤​log1⊤eW2​σ(W1​xi​+b1​)+b2​eW2​σ(W1​xi​+b1​)+b2​​ =−∑i=1Nyi⊤[W2σ(W1xi+b1)+b2−log⁡(1⋅1⊤eW2σ(W1xi+b1)+b2)]= -\\sum_{i=1}^N \\boldsymbol{y}_i^\\top[\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2 - \\log(\\boldsymbol{1}\\cdot\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2})]=−∑i=1N​yi⊤​[W2​σ(W1​xi​+b1​)+b2​−log(1⋅1⊤eW2​σ(W1​xi​+b1​)+b2​)] =−∑i=1N{yi⊤[W2σ(W1xi+b1)+b2]−(yi⊤1)log⁡(1⊤eW2σ(W1xi+b1)+b2)}= -\\sum_{i=1}^N\\left\\{\\boldsymbol{y}_i^\\top[\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2] - (\\boldsymbol{y}_i^\\top\\boldsymbol{1})\\log(\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2})\\right\\}=−∑i=1N​{yi⊤​[W2​σ(W1​xi​+b1​)+b2​]−(yi⊤​1)log(1⊤eW2​σ(W1​xi​+b1​)+b2​)} =−∑i=1N{yi⊤[W2σ(W1xi+b1)+b2]−log⁡(1⊤eW2σ(W1xi+b1)+b2)}= -\\sum_{i=1}^N\\left\\{\\boldsymbol{y}_i^\\top[\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2] - \\log(\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2})\\right\\}=−∑i=1N​{yi⊤​[W2​σ(W1​xi​+b1​)+b2​]−log(1⊤eW2​σ(W1​xi​+b1​)+b2​)} dℓ\\text{d} \\elldℓ $ = -\\sum_{i=1}^N \\text{tr}\\left{\\boldsymbol{y}_i^\\top\\text{d} [\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2] - \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} \\text{d} [\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}]\\right}$ =====w.r.t. W2−∑i=1Ntr{yi⊤(dW2)σ(W1xi+b1)−11⊤eW2σ(W1xi+b1)+b2[1⊤deW2σ(W1xi+b1)+b2]}\\overset{\\text{w.r.t.}~\\boldsymbol{W}_2}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\boldsymbol{y}_i^\\top(\\text{d}\\boldsymbol{W}_2)\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) - \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} [\\boldsymbol{1}^\\top \\text{d} e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}]\\right\\}=====w.r.t. W2​−∑i=1N​tr{yi⊤​(dW2​)σ(W1​xi​+b1​)−1⊤eW2​σ(W1​xi​+b1​)+b2​1​[1⊤deW2​σ(W1​xi​+b1​)+b2​]} =====w.r.t. W2−∑i=1Ntr{yi⊤(dW2)σ(W1xi+b1)−1⊤{eW2σ(W1xi+b1)+b2⊙d[W2σ(W1xi+b1)]}1⊤eW2σ(W1xi+b1)+b2}\\overset{\\text{w.r.t.}~\\boldsymbol{W}_2}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\boldsymbol{y}_i^\\top(\\text{d}\\boldsymbol{W}_2)\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) - \\frac{\\boldsymbol{1}^\\top \\{e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2} \\odot \\text{d}[\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1)]\\}}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} \\right\\}=====w.r.t. W2​−∑i=1N​tr{yi⊤​(dW2​)σ(W1​xi​+b1​)−1⊤eW2​σ(W1​xi​+b1​)+b2​1⊤{eW2​σ(W1​xi​+b1​)+b2​⊙d[W2​σ(W1​xi​+b1​)]}​} =====w.r.t. W2−∑i=1Ntr{yi⊤(dW2)σ(W1xi+b1)−(eW2σ(W1xi+b1)+b2)⊤⋅d[W2σ(W1xi+b1)]1⊤eW2σ(W1xi+b1)+b2}\\overset{\\text{w.r.t.}~\\boldsymbol{W}_2}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\boldsymbol{y}_i^\\top(\\text{d}\\boldsymbol{W}_2)\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) - \\frac{(e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2})^\\top \\cdot \\text{d}[\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1)]}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} \\right\\}=====w.r.t. W2​−∑i=1N​tr{yi⊤​(dW2​)σ(W1​xi​+b1​)−1⊤eW2​σ(W1​xi​+b1​)+b2​(eW2​σ(W1​xi​+b1​)+b2​)⊤⋅d[W2​σ(W1​xi​+b1​)]​} =====w.r.t. W2−∑i=1Ntr{yi⊤(dW2)σ(W1xi+b1)−(eW2σ(W1xi+b1)+b2)⊤(dW2)σ(W1xi+b1)1⊤eW2σ(W1xi+b1)+b2}\\overset{\\text{w.r.t.}~\\boldsymbol{W}_2}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\boldsymbol{y}_i^\\top(\\text{d}\\boldsymbol{W}_2)\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) - \\frac{(e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2})^\\top (\\text{d}\\boldsymbol{W}_2)\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1)}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} \\right\\}=====w.r.t. W2​−∑i=1N​tr{yi⊤​(dW2​)σ(W1​xi​+b1​)−1⊤eW2​σ(W1​xi​+b1​)+b2​(eW2​σ(W1​xi​+b1​)+b2​)⊤(dW2​)σ(W1​xi​+b1​)​} =====w.r.t. W2−∑i=1Ntr{σ(W1xi+b1)yi⊤dW2−σ(W1xi+b1)(eW2σ(W1xi+b1)+b2)⊤dW21⊤eW2σ(W1xi+b1)+b2}\\overset{\\text{w.r.t.}~\\boldsymbol{W}_2}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1)\\boldsymbol{y}_i^\\top\\text{d}\\boldsymbol{W}_2 - \\frac{\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1)(e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2})^\\top \\text{d}\\boldsymbol{W}_2}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} \\right\\}=====w.r.t. W2​−∑i=1N​tr{σ(W1​xi​+b1​)yi⊤​dW2​−1⊤eW2​σ(W1​xi​+b1​)+b2​σ(W1​xi​+b1​)(eW2​σ(W1​xi​+b1​)+b2​)⊤dW2​​} =====w.r.t. W2∑i=1Ntr{σ(W1xi+b1)[(eW2σ(W1xi+b1)+b2)⊤1⊤eW2σ(W1xi+b1)+b2−yi⊤]dW2}\\overset{\\text{w.r.t.}~\\boldsymbol{W}_2}{=====} \\sum_{i=1}^N \\text{tr}\\left\\{\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1)[\\frac{(e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2})^\\top}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} - \\boldsymbol{y}_i^\\top]\\text{d}\\boldsymbol{W}_2 \\right\\}=====w.r.t. W2​∑i=1N​tr{σ(W1​xi​+b1​)[1⊤eW2​σ(W1​xi​+b1​)+b2​(eW2​σ(W1​xi​+b1​)+b2​)⊤​−yi⊤​]dW2​} =====w.r.t. W2∑i=1Ntr{{[softmax(W2σ(W1xi+b1)+b2)−yi]σ⊤(W1xi+b1)}⊤dW2}\\overset{\\text{w.r.t.}~\\boldsymbol{W}_2}{=====} \\sum_{i=1}^N \\text{tr}\\left\\{\\{[\\text{softmax} (\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2) - \\boldsymbol{y}_i]\\sigma^\\top(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1)\\}^\\top\\text{d}\\boldsymbol{W}_2 \\right\\}=====w.r.t. W2​∑i=1N​tr{{[softmax(W2​σ(W1​xi​+b1​)+b2​)−yi​]σ⊤(W1​xi​+b1​)}⊤dW2​} dℓ=−∑i=1Ntr{yi⊤d[W2σ(W1xi+b1)+b2]−11⊤eW2σ(W1xi+b1)+b2d[1⊤eW2σ(W1xi+b1)+b2]}\\text{d} \\ell = -\\sum_{i=1}^N \\text{tr}\\left\\{\\boldsymbol{y}_i^\\top\\text{d} [\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2] - \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} \\text{d} [\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}]\\right\\}dℓ=−∑i=1N​tr{yi⊤​d[W2​σ(W1​xi​+b1​)+b2​]−1⊤eW2​σ(W1​xi​+b1​)+b2​1​d[1⊤eW2​σ(W1​xi​+b1​)+b2​]} =====w.r.t. b2−∑i=1Ntr{yi⊤db2−11⊤eW2σ(W1xi+b1)+b2[1⊤deW2σ(W1xi+b1)+b2]}\\overset{\\text{w.r.t.}~\\boldsymbol{b}_2}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\boldsymbol{y}_i^\\top\\text{d}\\boldsymbol{b}_2 - \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} [\\boldsymbol{1}^\\top \\text{d} e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}]\\right\\}=====w.r.t. b2​−∑i=1N​tr{yi⊤​db2​−1⊤eW2​σ(W1​xi​+b1​)+b2​1​[1⊤deW2​σ(W1​xi​+b1​)+b2​]} =====w.r.t. b2−∑i=1Ntr{yi⊤db2−1⊤{eW2σ(W1xi+b1)+b2⊙d[W2σ(W1xi+b1)+b2]}1⊤eW2σ(W1xi+b1)+b2}\\overset{\\text{w.r.t.}~\\boldsymbol{b}_2}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\boldsymbol{y}_i^\\top\\text{d}\\boldsymbol{b}_2 - \\frac{\\boldsymbol{1}^\\top \\{e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2} \\odot \\text{d} [\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2]\\}}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}}\\right\\}=====w.r.t. b2​−∑i=1N​tr{yi⊤​db2​−1⊤eW2​σ(W1​xi​+b1​)+b2​1⊤{eW2​σ(W1​xi​+b1​)+b2​⊙d[W2​σ(W1​xi​+b1​)+b2​]}​} =====w.r.t. b2−∑i=1Ntr{yi⊤db2−[eW2σ(W1xi+b1)+b2]⊤d[W2σ(W1xi+b1)+b2]1⊤eW2σ(W1xi+b1)+b2}\\overset{\\text{w.r.t.}~\\boldsymbol{b}_2}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\boldsymbol{y}_i^\\top\\text{d}\\boldsymbol{b}_2 - \\frac{[e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}]^\\top \\text{d} [\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2]}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}}\\right\\}=====w.r.t. b2​−∑i=1N​tr{yi⊤​db2​−1⊤eW2​σ(W1​xi​+b1​)+b2​[eW2​σ(W1​xi​+b1​)+b2​]⊤d[W2​σ(W1​xi​+b1​)+b2​]​} =====w.r.t. b2−∑i=1Ntr{yi⊤db2−[eW2σ(W1xi+b1)+b2]⊤db21⊤eW2σ(W1xi+b1)+b2}\\overset{\\text{w.r.t.}~\\boldsymbol{b}_2}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\boldsymbol{y}_i^\\top\\text{d}\\boldsymbol{b}_2 - \\frac{[e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}]^\\top \\text{d} \\boldsymbol{b}_2}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}}\\right\\}=====w.r.t. b2​−∑i=1N​tr{yi⊤​db2​−1⊤eW2​σ(W1​xi​+b1​)+b2​[eW2​σ(W1​xi​+b1​)+b2​]⊤db2​​} =====w.r.t. b2∑i=1Ntr{(eW2σ(W1xi+b1)+b21⊤eW2σ(W1xi+b1)+b2−yi)⊤db2}\\overset{\\text{w.r.t.}~\\boldsymbol{b}_2}{=====} \\sum_{i=1}^N \\text{tr}\\left\\{ (\\frac{e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} - \\boldsymbol{y}_i)^\\top\\text{d}\\boldsymbol{b}_2 \\right\\}=====w.r.t. b2​∑i=1N​tr{(1⊤eW2​σ(W1​xi​+b1​)+b2​eW2​σ(W1​xi​+b1​)+b2​​−yi​)⊤db2​} =====w.r.t. b2∑i=1Ntr{(softmax(W2σ(W1xi+b1)+b2)−yi)⊤db2}\\overset{\\text{w.r.t.}~\\boldsymbol{b}_2}{=====} \\sum_{i=1}^N \\text{tr}\\left\\{ (\\text{softmax}(\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2) - \\boldsymbol{y}_i)^\\top\\text{d}\\boldsymbol{b}_2 \\right\\}=====w.r.t. b2​∑i=1N​tr{(softmax(W2​σ(W1​xi​+b1​)+b2​)−yi​)⊤db2​} dℓ=−∑i=1Ntr{yi⊤d[W2σ(W1xi+b1)+b2]−11⊤eW2σ(W1xi+b1)+b2d[1⊤eW2σ(W1xi+b1)+b2]}\\text{d} \\ell = -\\sum_{i=1}^N \\text{tr}\\left\\{\\boldsymbol{y}_i^\\top\\text{d} [\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2] - \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} \\text{d} [\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}]\\right\\}dℓ=−∑i=1N​tr{yi⊤​d[W2​σ(W1​xi​+b1​)+b2​]−1⊤eW2​σ(W1​xi​+b1​)+b2​1​d[1⊤eW2​σ(W1​xi​+b1​)+b2​]} =====w.r.t. W1−∑i=1Ntr{yi⊤W2dσ(W1xi+b1)−11⊤eW2σ(W1xi+b1)+b2[1⊤deW2σ(W1xi+b1)+b2]}\\overset{\\text{w.r.t.}~\\boldsymbol{W}_1}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\boldsymbol{y}_i^\\top\\boldsymbol{W}_2\\text{d}\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) - \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} [\\boldsymbol{1}^\\top \\text{d} e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}]\\right\\}=====w.r.t. W1​−∑i=1N​tr{yi⊤​W2​dσ(W1​xi​+b1​)−1⊤eW2​σ(W1​xi​+b1​)+b2​1​[1⊤deW2​σ(W1​xi​+b1​)+b2​]} =====w.r.t. W1−∑i=1Ntr{{yi⊤−[eW2σ(W1xi+b1)+b2]⊤1⊤eW2σ(W1xi+b1)+b2}W2[σ′(W1xi+b1)⊙d(W1xi)]}\\overset{\\text{w.r.t.}~\\boldsymbol{W}_1}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\{\\boldsymbol{y}_i^\\top - \\frac{[e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}]^\\top}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}}\\}\\boldsymbol{W}_2[\\sigma^{\\prime}(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) \\odot\\text{d}(\\boldsymbol{W}_1\\boldsymbol{x}_i)]\\right\\}=====w.r.t. W1​−∑i=1N​tr{{yi⊤​−1⊤eW2​σ(W1​xi​+b1​)+b2​[eW2​σ(W1​xi​+b1​)+b2​]⊤​}W2​[σ′(W1​xi​+b1​)⊙d(W1​xi​)]} =====w.r.t. W1−∑i=1Ntr{{W2⊤[yi−eW2σ(W1xi+b1)+b21⊤eW2σ(W1xi+b1)+b2]}⊤[σ′(W1xi+b1)⊙d(W1xi)]}\\overset{\\text{w.r.t.}~\\boldsymbol{W}_1}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\{ {\\boldsymbol{W}_2}^\\top[\\boldsymbol{y}_i - \\frac{e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}}]\\}^\\top[\\sigma^{\\prime}(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) \\odot\\text{d}(\\boldsymbol{W}_1\\boldsymbol{x}_i)]\\right\\}=====w.r.t. W1​−∑i=1N​tr{{W2​⊤[yi​−1⊤eW2​σ(W1​xi​+b1​)+b2​eW2​σ(W1​xi​+b1​)+b2​​]}⊤[σ′(W1​xi​+b1​)⊙d(W1​xi​)]} =====w.r.t. W1−∑i=1Ntr{{{W2⊤[yi−softmax(W2σ(W1xi+b1)+b2)]}⊙σ′(W1xi+b1)}⊤d(W1xi)}\\overset{\\text{w.r.t.}~\\boldsymbol{W}_1}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\left\\{\\{ {\\boldsymbol{W}_2}^\\top[\\boldsymbol{y}_i - \\text{softmax}(\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2)]\\}\\odot\\sigma^{\\prime}(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1)\\right\\}^\\top\\text{d}(\\boldsymbol{W}_1\\boldsymbol{x}_i)\\right\\}=====w.r.t. W1​−∑i=1N​tr{{{W2​⊤[yi​−softmax(W2​σ(W1​xi​+b1​)+b2​)]}⊙σ′(W1​xi​+b1​)}⊤d(W1​xi​)} =====w.r.t. W1∑i=1Ntr{{{W2⊤[softmax(W2σ(W1xi+b1)+b2)−yi]}⊙σ′(W1xi+b1)⋅xi⊤}⊤dW1}\\overset{\\text{w.r.t.}~\\boldsymbol{W}_1}{=====} \\sum_{i=1}^N \\text{tr}\\left\\{\\left\\{\\{ {\\boldsymbol{W}_2}^\\top[\\text{softmax}(\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2) - \\boldsymbol{y}_i]\\}\\odot\\sigma^{\\prime}(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1)\\cdot\\boldsymbol{x}_i^\\top\\right\\}^\\top\\text{d}\\boldsymbol{W}_1\\right\\}=====w.r.t. W1​∑i=1N​tr{{{W2​⊤[softmax(W2​σ(W1​xi​+b1​)+b2​)−yi​]}⊙σ′(W1​xi​+b1​)⋅xi⊤​}⊤dW1​} dℓ=−∑i=1Ntr{yi⊤d[W2σ(W1xi+b1)+b2]−11⊤eW2σ(W1xi+b1)+b2d[1⊤eW2σ(W1xi+b1)+b2]}\\text{d} \\ell = -\\sum_{i=1}^N \\text{tr}\\left\\{\\boldsymbol{y}_i^\\top\\text{d} [\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2] - \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} \\text{d} [\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}]\\right\\}dℓ=−∑i=1N​tr{yi⊤​d[W2​σ(W1​xi​+b1​)+b2​]−1⊤eW2​σ(W1​xi​+b1​)+b2​1​d[1⊤eW2​σ(W1​xi​+b1​)+b2​]} =====w.r.t. b1−∑i=1Ntr{yi⊤W2dσ(W1xi+b1)−11⊤eW2σ(W1xi+b1)+b2[1⊤deW2σ(W1xi+b1)+b2]}\\overset{\\text{w.r.t.}~\\boldsymbol{b}_1}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\boldsymbol{y}_i^\\top\\boldsymbol{W}_2\\text{d}\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) - \\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}} [\\boldsymbol{1}^\\top \\text{d} e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}]\\right\\}=====w.r.t. b1​−∑i=1N​tr{yi⊤​W2​dσ(W1​xi​+b1​)−1⊤eW2​σ(W1​xi​+b1​)+b2​1​[1⊤deW2​σ(W1​xi​+b1​)+b2​]} =====w.r.t. b1−∑i=1Ntr{{yi⊤−[eW2σ(W1xi+b1)+b2]⊤1⊤eW2σ(W1xi+b1)+b2}W2[σ′(W1xi+b1)⊙db1]}\\overset{\\text{w.r.t.}~\\boldsymbol{b}_1}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\{\\boldsymbol{y}_i^\\top - \\frac{[e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}]^\\top}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}}\\}\\boldsymbol{W}_2[\\sigma^{\\prime}(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) \\odot\\text{d}\\boldsymbol{b}_1]\\right\\}=====w.r.t. b1​−∑i=1N​tr{{yi⊤​−1⊤eW2​σ(W1​xi​+b1​)+b2​[eW2​σ(W1​xi​+b1​)+b2​]⊤​}W2​[σ′(W1​xi​+b1​)⊙db1​]} =====w.r.t. b1−∑i=1Ntr{{W2⊤[yi−eW2σ(W1xi+b1)+b21⊤eW2σ(W1xi+b1)+b2]}⊤[σ′(W1xi+b1)⊙db1]}\\overset{\\text{w.r.t.}~\\boldsymbol{b}_1}{=====} -\\sum_{i=1}^N \\text{tr}\\left\\{\\{ {\\boldsymbol{W}_2}^\\top[\\boldsymbol{y}_i - \\frac{e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2}}]\\}^\\top[\\sigma^{\\prime}(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) \\odot\\text{d}\\boldsymbol{b}_1]\\right\\}=====w.r.t. b1​−∑i=1N​tr{{W2​⊤[yi​−1⊤eW2​σ(W1​xi​+b1​)+b2​eW2​σ(W1​xi​+b1​)+b2​​]}⊤[σ′(W1​xi​+b1​)⊙db1​]} =====w.r.t. b1∑i=1Ntr{{{W2⊤[softmax(W2σ(W1xi+b1)+b2)−yi]}⊙σ′(W1xi+b1)}⊤db1}\\overset{\\text{w.r.t.}~\\boldsymbol{b}_1}{=====} \\sum_{i=1}^N \\text{tr}\\left\\{\\left\\{\\{ {\\boldsymbol{W}_2}^\\top[\\text{softmax}(\\boldsymbol{W}_2\\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2) - \\boldsymbol{y}_i]\\}\\odot\\sigma^{\\prime}(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1)\\right\\}^\\top\\text{d}\\boldsymbol{b}_1\\right\\}=====w.r.t. b1​∑i=1N​tr{{{W2​⊤[softmax(W2​σ(W1​xi​+b1​)+b2​)−yi​]}⊙σ′(W1​xi​+b1​)}⊤db1​} Answer: ∂ℓ∂W2=∑i=1N{softmax[W2σ(W1xi+b1)+b2]−yi}σ⊤(W1xi+b1)\\frac{\\partial \\ell}{\\partial \\boldsymbol{W}_2} = \\sum_{i=1}^N \\{softmax[\\boldsymbol{W}_2 \\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2] - \\boldsymbol{y}_i\\} \\sigma^\\top(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1)∂W2​∂ℓ​=∑i=1N​{softmax[W2​σ(W1​xi​+b1​)+b2​]−yi​}σ⊤(W1​xi​+b1​) ∂ℓ∂b2=∑i=1Nsoftmax[W2σ(W1xi+b1)+b2]−yi\\frac{\\partial \\ell}{\\partial \\boldsymbol{b}_2} = \\sum_{i=1}^N softmax[\\boldsymbol{W}_2 \\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2] - \\boldsymbol{y}_i∂b2​∂ℓ​=∑i=1N​softmax[W2​σ(W1​xi​+b1​)+b2​]−yi​ ∂ℓ∂W1=∑i=1N{{W2⊤{softmax[W2σ(W1xi+b1)+b2]−yi}}⊙σ′(W1xi+b1)}xi⊤\\frac{\\partial \\ell}{\\partial \\boldsymbol{W}_1} = \\sum_{i=1}^N \\{\\{\\boldsymbol{W}_2^\\top\\{softmax[\\boldsymbol{W}_2 \\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2] - \\boldsymbol{y}_i\\}\\} \\odot \\sigma^{\\prime}(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) \\} \\boldsymbol{x}_i^\\top∂W1​∂ℓ​=∑i=1N​{{W2⊤​{softmax[W2​σ(W1​xi​+b1​)+b2​]−yi​}}⊙σ′(W1​xi​+b1​)}xi⊤​ ∂ℓ∂b1=∑i=1N{W2⊤{softmax[W2σ(W1xi+b1)+b2]−yi}}⊙σ′(W1xi+b1)\\frac{\\partial \\ell}{\\partial \\boldsymbol{b}_1} = \\sum_{i=1}^N \\{\\boldsymbol{W}_2^\\top\\{softmax[\\boldsymbol{W}_2 \\sigma(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1) + \\boldsymbol{b}_2] - \\boldsymbol{y}_i\\}\\} \\odot \\sigma^{\\prime}(\\boldsymbol{W}_1\\boldsymbol{x}_i + \\boldsymbol{b}_1)∂b1​∂ℓ​=∑i=1N​{W2⊤​{softmax[W2​σ(W1​xi​+b1​)+b2​]−yi​}}⊙σ′(W1​xi​+b1​) Derivative of the Matrix to Matrix 假设f(x)∈Rp×1\\boldsymbol{f}(\\boldsymbol{x})\\in\\mathbb{R}^{p\\times 1}f(x)∈Rp×1是关于向量x∈Rn×1\\boldsymbol{x}\\in\\mathbb{R}^{n\\times 1}x∈Rn×1的函数。不失优雅地（不考虑矩阵布局），我们由向量微分与偏导的关联（df=∂f∂x⊤dxd\\boldsymbol{f}=\\frac{\\partial\\boldsymbol{f}}{\\partial\\boldsymbol{x}}^\\top d\\boldsymbol{x}df=∂x∂f​⊤dx），反推给出列向量对列向量的偏导定义如下： ∂f∂x=[∂f1∂x1⋯∂f1∂xn⋮⋱⋮∂fp∂x1⋯∂fp∂xn]∈Rp×n\\frac{\\partial \\boldsymbol{f}}{\\partial \\boldsymbol{x}} = \\begin{bmatrix} \\frac{\\partial f_1}{\\partial x_{1}} &amp; \\cdots &amp; \\frac{\\partial f_1}{\\partial x_n} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\frac{\\partial f_p}{\\partial x_{1}} &amp; \\cdots &amp; \\frac{\\partial f_p}{\\partial x_n} \\end{bmatrix} \\in \\mathbb{R}^{p\\times n}∂x∂f​=⎣⎢⎢⎢⎡​∂x1​∂f1​​⋮∂x1​∂fp​​​⋯⋱⋯​∂xn​∂f1​​⋮∂xn​∂fp​​​⎦⎥⎥⎥⎤​∈Rp×n 该布局默认为分母布局。在分子布局下， ∂f∂x=[∂f1∂x1⋯∂fp∂x1⋮⋱⋮∂f1∂xn⋯∂fp∂xn]∈Rn×p\\frac{\\partial \\boldsymbol{f}}{\\partial \\boldsymbol{x}} = \\begin{bmatrix} \\frac{\\partial f_1}{\\partial x_{1}} &amp; \\cdots &amp; \\frac{\\partial f_p}{\\partial x_1} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\frac{\\partial f_1}{\\partial x_{n}} &amp; \\cdots &amp; \\frac{\\partial f_p}{\\partial x_n} \\end{bmatrix} \\in \\mathbb{R}^{n\\times p}∂x∂f​=⎣⎢⎢⎢⎡​∂x1​∂f1​​⋮∂xn​∂f1​​​⋯⋱⋯​∂x1​∂fp​​⋮∂xn​∂fp​​​⎦⎥⎥⎥⎤​∈Rn×p 在给出矩阵对矩阵的导数定义前，我们先定义矩阵X∈Rm×n\\boldsymbol{X}\\in\\mathbb{R}^{m\\times n}X∈Rm×n的向量化为Vec(X)=[x1,1,x2,1,⋯ ,xm,1,x1,2,⋯ ,xm,n]⊤\\text{Vec}(\\boldsymbol{X})=[x_{1,1},x_{2,1},\\cdots,x_{m,1},x_{1,2},\\cdots,x_{m,n}]^\\topVec(X)=[x1,1​,x2,1​,⋯,xm,1​,x1,2​,⋯,xm,n​]⊤。从而进一步地我们定义矩阵F∈Rp×q\\boldsymbol{F}\\in\\mathbb{R}^{p\\times q}F∈Rp×q对矩阵X∈Rm×n\\boldsymbol{X}\\in\\mathbb{R}^{m\\times n}X∈Rm×n的导数如下： ∂F∂X=∂Vec(F)∂Vec(X)∈Rmn×pq\\frac{\\partial \\boldsymbol{F}}{\\partial \\boldsymbol{X}} = \\frac{\\partial \\text{Vec}(\\boldsymbol{F})}{\\partial \\text{Vec}(\\boldsymbol{X})}\\in\\mathbb{R}^{mn\\times pq}∂X∂F​=∂Vec(X)∂Vec(F)​∈Rmn×pq 同时，导数与微分的联系可以不失一般地表示为： Vec(dF)=(∂Vec(F)∂Vec(X))⊤Vec(dX)=(∂F∂X)⊤Vec(dX)\\text{Vec}(d\\boldsymbol{F}) = (\\frac{\\partial \\text{Vec}(\\boldsymbol{F})}{\\partial \\text{Vec}(\\boldsymbol{X})})^\\top\\text{Vec}(d\\boldsymbol{X}) = (\\frac{\\partial \\boldsymbol{F}}{\\partial \\boldsymbol{X}})^\\top\\text{Vec}(d\\boldsymbol{X})Vec(dF)=(∂Vec(X)∂Vec(F)​)⊤Vec(dX)=(∂X∂F​)⊤Vec(dX). 若FFF降级为标量fff时，为了统一表示，我们记∂f∂X=Vec(∇Xf)\\frac{\\partial f}{\\partial \\boldsymbol{X}} = \\text{Vec}(\\nabla_{\\boldsymbol{X}}f)∂X∂f​=Vec(∇X​f)。在此基础上求二阶导，得到机器学习中常见的 Hessian matrix: ∇X2f=∂2f∂X2=∂(∇Xf)∂X∈Rmn×mn\\nabla^2_{\\boldsymbol{X}}f = \\frac{\\partial^2 f}{\\partial\\boldsymbol{X}^2} = \\frac{\\partial (\\nabla_{\\boldsymbol{X}}f)}{\\partial \\boldsymbol{X}}\\in\\mathbb{R}^{mn\\times mn}∇X2​f=∂X2∂2f​=∂X∂(∇X​f)​∈Rmn×mn. Notice 1: 若从分子布局和分母布局的角度出发，与微分相关联且不失一般性的布局为分母布局，机器学习和优化理论常用此布局。 Notice 2: 矩阵对矩阵求导定义除了分子布局与分母布局外，还可以有其它定义，例如: ∂F∂X=[∂f1,1∂X⋯∂f1,q∂X⋮⋱⋮∂fp,1∂X⋯∂fp,q∂X]=[∂F∂x1,1⋯∂F∂x1,n⋮⋱⋮∂F∂xm,1⋯∂F∂xm,n]\\frac{\\partial \\boldsymbol{F}}{\\partial \\boldsymbol{X}} = \\begin{bmatrix} \\frac{\\partial f_{1,1}}{\\partial \\boldsymbol{X}} &amp; \\cdots &amp; \\frac{\\partial f_{1,q}}{\\partial \\boldsymbol{X}} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\frac{\\partial f_{p,1}}{\\partial \\boldsymbol{X}} &amp; \\cdots &amp; \\frac{\\partial f_{p,q}}{\\partial \\boldsymbol{X}} \\end{bmatrix} = \\begin{bmatrix} \\frac{\\partial \\boldsymbol{F}}{\\partial x_{1,1}} &amp; \\cdots &amp; \\frac{\\partial \\boldsymbol{F}}{\\partial x_{1,n}} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\frac{\\partial \\boldsymbol{F}}{\\partial x_{m,1}} &amp; \\cdots &amp; \\frac{\\partial \\boldsymbol{F}}{\\partial x_{m,n}} \\end{bmatrix}∂X∂F​=⎣⎢⎢⎡​∂X∂f1,1​​⋮∂X∂fp,1​​​⋯⋱⋯​∂X∂f1,q​​⋮∂X∂fp,q​​​⎦⎥⎥⎤​=⎣⎢⎢⎢⎡​∂x1,1​∂F​⋮∂xm,1​∂F​​⋯⋱⋯​∂x1,n​∂F​⋮∂xm,n​∂F​​⎦⎥⎥⎥⎤​ 然而，该定义只可兼容标量对矩阵的求导，无法配合微分进行运算，因此不是&quot;好&quot;的定义。 假设纯在复合函数Y⋅F\\boldsymbol{Y}\\cdot\\boldsymbol{F}Y⋅F，则 Vec(dF)=(∂F∂Y)⊤Vec(dY)=(∂F∂Y)⊤((∂Y∂X)⊤Vec(dX))=(∂Y∂X∂F∂Y)⊤Vec(dX)\\text{Vec}(\\text{d} \\boldsymbol{F}) = {(\\frac{\\partial \\boldsymbol{F}}{\\partial \\boldsymbol{Y}})}^\\top \\text{Vec}(\\text{d} \\boldsymbol{Y}) = {(\\frac{\\partial \\boldsymbol{F}}{\\partial \\boldsymbol{Y}})}^\\top \\left( {(\\frac{\\partial \\boldsymbol{Y}}{\\partial \\boldsymbol{X}})}^\\top \\text{Vec}(\\text{d} \\boldsymbol{X})\\right) = {\\left(\\frac{\\partial \\boldsymbol{Y}}{\\partial \\boldsymbol{X}} \\frac{\\partial \\boldsymbol{F}}{\\partial \\boldsymbol{Y}}\\right)} ^\\top \\text{Vec}(\\text{d} \\boldsymbol{X})Vec(dF)=(∂Y∂F​)⊤Vec(dY)=(∂Y∂F​)⊤((∂X∂Y​)⊤Vec(dX))=(∂X∂Y​∂Y∂F​)⊤Vec(dX). 因此，dFdX=∂Y∂X∂F∂Y\\frac{\\text{d} \\boldsymbol{F}}{\\text{d} \\boldsymbol{X}} = \\frac{\\partial \\boldsymbol{Y}}{\\partial \\boldsymbol{X}} \\frac{\\partial \\boldsymbol{F}}{\\partial \\boldsymbol{Y}}dXdF​=∂X∂Y​∂Y∂F​. Vectorization Trick Vec(A+B)=Vec(A)+Vec(B)\\color{green}\\text{Vec}(\\boldsymbol{A} + \\boldsymbol{B}) = \\text{Vec}(\\boldsymbol{A}) + \\text{Vec}(\\boldsymbol{B})Vec(A+B)=Vec(A)+Vec(B) Vec(AXB)=(B⊤⊗A)Vec(X)，其中 ⊗ 表示 Kronecker Product:\\color{green}\\text{Vec}(\\boldsymbol{A}\\boldsymbol{X}\\boldsymbol{B}) = (\\boldsymbol{B}^\\top\\otimes \\boldsymbol{A})\\text{Vec}(\\boldsymbol{X})，其中~\\otimes~表示~\\text{Kronecker Product}:Vec(AXB)=(B⊤⊗A)Vec(X)，其中 ⊗ 表示 Kronecker Product: A⊗B(A∈Rm×n,B∈Rp×q)=[a1,1B⋯a1,nB⋮⋱⋮am,1B⋯am,nB]\\color{green} \\boldsymbol{A}\\otimes\\boldsymbol{B}(\\boldsymbol{A}\\in\\mathbb{R}^{m\\times n}, \\boldsymbol{B}\\in\\mathbb{R}^{p\\times q}) = \\begin{bmatrix} a_{1,1}\\boldsymbol{B} &amp; \\cdots &amp; a_{1,n}\\boldsymbol{B}\\\\ \\vdots &amp; \\ddots &amp; \\vdots\\\\ a_{m,1}\\boldsymbol{B} &amp; \\cdots &amp; a_{m,n}\\boldsymbol{B} \\end{bmatrix}A⊗B(A∈Rm×n,B∈Rp×q)=⎣⎢⎢⎡​a1,1​B⋮am,1​B​⋯⋱⋯​a1,n​B⋮am,n​B​⎦⎥⎥⎤​ Vec(ab⊤)=b⊗a\\color{green}\\text{Vec}(\\boldsymbol{a}\\boldsymbol{b}^\\top) = \\boldsymbol{b}\\otimes\\boldsymbol{a}Vec(ab⊤)=b⊗a Vec(AT)=KmnVec(A),其中 Kmn 为交换矩阵 (∑iki,j=∑jki,j=1,Kmn=Knm⊤,KmnKnm=I)\\color{green}\\text{Vec}(\\boldsymbol{A}^T)=\\boldsymbol{K}_{mn}\\text{Vec}(\\boldsymbol{A}), 其中~ \\boldsymbol{K}_{mn}~为交换矩阵~(\\sum_i k_{i,j} = \\sum_j k_{i,j} = 1, \\boldsymbol{K}_{mn} = {\\boldsymbol{K}_{nm}}^\\top, \\boldsymbol{K}_{mn}\\boldsymbol{K}_{nm} = \\boldsymbol{I})Vec(AT)=Kmn​Vec(A),其中 Kmn​ 为交换矩阵 (∑i​ki,j​=∑j​ki,j​=1,Kmn​=Knm​⊤,Kmn​Knm​=I) Kp,m(A⊗B)Knq=B⊗A(A∈Rm×n,B∈Rp×q)\\color{green} \\boldsymbol{K}_{p,m}(\\boldsymbol{A}\\otimes\\boldsymbol{B})\\boldsymbol{K}_{nq}=\\boldsymbol{B}\\otimes\\boldsymbol{A}(\\boldsymbol{A}\\in\\mathbb{R}^{m\\times n}, \\boldsymbol{B}\\in\\mathbb{R}^{p\\times q})Kp,m​(A⊗B)Knq​=B⊗A(A∈Rm×n,B∈Rp×q) Proof: Vec(AXB⊤)=B⊗AVec(X),A∈Rm×n,X∈Rn×q,B∈Rp×q\\text{Vec}(\\boldsymbol{A}\\boldsymbol{X}\\boldsymbol{B}^\\top)=\\boldsymbol{B}\\otimes\\boldsymbol{A}\\text{Vec}(X), \\boldsymbol{A}\\in\\mathbb{R}^{m\\times n}, \\boldsymbol{X}\\in\\mathbb{R}^{n\\times q}, \\boldsymbol{B}\\in\\mathbb{R}^{p\\times q}Vec(AXB⊤)=B⊗AVec(X),A∈Rm×n,X∈Rn×q,B∈Rp×q Vec(BX⊤A⊤)=(A⊗B)Vec(X⊤)=(A⊗B)Kn,qVec(X)\\text{Vec}(\\boldsymbol{B}\\boldsymbol{X}^\\top\\boldsymbol{A}^\\top)=(\\boldsymbol{A}\\otimes\\boldsymbol{B})\\text{Vec}(\\boldsymbol{X}^\\top)=(\\boldsymbol{A}\\otimes\\boldsymbol{B})\\boldsymbol{K}_{n,q}\\text{Vec}(\\boldsymbol{X})Vec(BX⊤A⊤)=(A⊗B)Vec(X⊤)=(A⊗B)Kn,q​Vec(X) Vec[(AXB⊤)⊤]=Km,pVec(AXB⊤)=Km,pB⊗AVec(X)\\text{Vec}\\left[(\\boldsymbol{A}\\boldsymbol{X}\\boldsymbol{B}^\\top)^\\top\\right]=\\boldsymbol{K}_{m,p}\\text{Vec}(\\boldsymbol{A}\\boldsymbol{X}\\boldsymbol{B}^\\top)=\\boldsymbol{K}_{m,p}\\boldsymbol{B}\\otimes\\boldsymbol{A}\\text{Vec}(\\boldsymbol{X})Vec[(AXB⊤)⊤]=Km,p​Vec(AXB⊤)=Km,p​B⊗AVec(X) Thus, Kp,m(A⊗B)Kn,qVec(X)=Kp,mKm,pB⊗AVec(X)=B⊗AVec(X)\\boldsymbol{K}_{p,m}(\\boldsymbol{A}\\otimes\\boldsymbol{B})\\boldsymbol{K}_{n,q}\\text{Vec}(\\boldsymbol{X})=\\boldsymbol{K}_{p,m}\\boldsymbol{K}_{m,p}\\boldsymbol{B}\\otimes\\boldsymbol{A}\\text{Vec}(\\boldsymbol{X})=\\boldsymbol{B}\\otimes\\boldsymbol{A}\\text{Vec}(\\boldsymbol{X})Kp,m​(A⊗B)Kn,q​Vec(X)=Kp,m​Km,p​B⊗AVec(X)=B⊗AVec(X) Vec(A⊙B)=Diag(A)Vec(B)，其中 Diag(A) 为对角化操作，即把 Vec(A) 中所有元素排成对角阵(除对角线外其余元素全为零)\\color{green}\\text{Vec}(\\boldsymbol{A}\\odot\\boldsymbol{B}) = \\text{Diag}(\\boldsymbol{A})\\text{Vec}(\\boldsymbol{B})，其中~\\text{Diag}(\\boldsymbol{A})~为对角化操作，即把~\\text{Vec}(\\boldsymbol{A})~中所有元素排成对角阵(除对角线外其余元素全为零)Vec(A⊙B)=Diag(A)Vec(B)，其中 Diag(A) 为对角化操作，即把 Vec(A) 中所有元素排成对角阵(除对角线外其余元素全为零) a⊙b=Vec(a⊙b)=Diag(a)b\\color{green}\\boldsymbol{a}\\odot\\boldsymbol{b}=\\text{Vec}(\\boldsymbol{a}\\odot\\boldsymbol{b})=\\text{Diag}(\\boldsymbol{a})\\boldsymbol{b}a⊙b=Vec(a⊙b)=Diag(a)b (A⊗B)⊤=A⊤⊗B⊤\\color{green}(\\boldsymbol{A}\\otimes\\boldsymbol{B})^\\top = \\boldsymbol{A}^\\top\\otimes\\boldsymbol{B}^\\top(A⊗B)⊤=A⊤⊗B⊤ (A⊗B)(C⊗D)=AC⊗BD\\color{green}(\\boldsymbol{A}\\otimes\\boldsymbol{B})(\\boldsymbol{C}\\otimes\\boldsymbol{D}) = \\boldsymbol{AC}\\otimes\\boldsymbol{BD}(A⊗B)(C⊗D)=AC⊗BD Proof: 构造函数 F=D⊤B⊤XAC=D⊤(B⊤XA)C\\boldsymbol{F}=\\boldsymbol{D}^\\top\\boldsymbol{B}^\\top\\boldsymbol{X}\\boldsymbol{A}\\boldsymbol{C}=\\boldsymbol{D}^\\top(\\boldsymbol{B}^\\top\\boldsymbol{X}\\boldsymbol{A})\\boldsymbol{C}F=D⊤B⊤XAC=D⊤(B⊤XA)C For F=D⊤B⊤XAC,Vec(dF)=Vec(D⊤B⊤dXAC)=[(AC)⊤⊗(D⊤B⊤)]Vec(dX)=[(AC)⊗(BD)]⊤Vec(dX)\\text{For~} \\boldsymbol{F}=\\boldsymbol{D}^\\top\\boldsymbol{B}^\\top\\boldsymbol{X}\\boldsymbol{A}\\boldsymbol{C}, \\text{Vec}(\\text{d}\\boldsymbol{F})=\\text{Vec}(\\boldsymbol{D}^\\top\\boldsymbol{B}^\\top\\text{d}\\boldsymbol{X}\\boldsymbol{A}\\boldsymbol{C})=\\left[(\\boldsymbol{AC})^\\top\\otimes(\\boldsymbol{D}^\\top\\boldsymbol{B}^\\top)\\right]\\text{Vec}(\\text{d}\\boldsymbol{X})=\\left[(\\boldsymbol{A}\\boldsymbol{C})\\otimes(\\boldsymbol{B}\\boldsymbol{D})\\right]^\\top\\text{Vec}(\\text{d}\\boldsymbol{X})For F=D⊤B⊤XAC,Vec(dF)=Vec(D⊤B⊤dXAC)=[(AC)⊤⊗(D⊤B⊤)]Vec(dX)=[(AC)⊗(BD)]⊤Vec(dX) For F=D⊤(B⊤XA)C,Vec(dF)=Vec[D⊤d(B⊤XA)C]=(C⊤⊗D⊤)Vec[d(B⊤XA)]=(C⊤⊗D⊤)Vec[B⊤dXA]\\text{For~} \\boldsymbol{F}=\\boldsymbol{D}^\\top(\\boldsymbol{B}^\\top\\boldsymbol{X}\\boldsymbol{A})\\boldsymbol{C}, \\text{Vec}(\\text{d}\\boldsymbol{F})=\\text{Vec}\\left[\\boldsymbol{D}^\\top\\text{d}(\\boldsymbol{B}^\\top\\boldsymbol{X}\\boldsymbol{A})\\boldsymbol{C}\\right]=(\\boldsymbol{C}^\\top\\otimes\\boldsymbol{D}^\\top)\\text{Vec}\\left[\\text{d}(\\boldsymbol{B}^\\top\\boldsymbol{X}\\boldsymbol{A})\\right]=(\\boldsymbol{C}^\\top\\otimes\\boldsymbol{D}^\\top)\\text{Vec}\\left[\\boldsymbol{B}^\\top\\text{d}\\boldsymbol{X}\\boldsymbol{A}\\right]For F=D⊤(B⊤XA)C,Vec(dF)=Vec[D⊤d(B⊤XA)C]=(C⊤⊗D⊤)Vec[d(B⊤XA)]=(C⊤⊗D⊤)Vec[B⊤dXA] =(C⊤⊗D⊤)(A⊤⊗B⊤)Vec(dX)=[(A⊗B)(C⊗D)]⊤Vec(dX)=(\\boldsymbol{C}^\\top\\otimes\\boldsymbol{D}^\\top)(\\boldsymbol{A}^\\top\\otimes\\boldsymbol{B}^\\top)\\text{Vec}(\\text{d}\\boldsymbol{X})=\\left[(\\boldsymbol{A}\\otimes\\boldsymbol{B})(\\boldsymbol{C}\\otimes\\boldsymbol{D})\\right]^\\top\\text{Vec}(\\text{d}\\boldsymbol{X})=(C⊤⊗D⊤)(A⊤⊗B⊤)Vec(dX)=[(A⊗B)(C⊗D)]⊤Vec(dX) Thus, dFdX=(AC)⊗(BD)=(A⊗B)(C⊗D)\\text{Thus,~}\\frac{\\text{d}\\boldsymbol{F}}{\\text{d}\\boldsymbol{X}}=(\\boldsymbol{A}\\boldsymbol{C})\\otimes(\\boldsymbol{B}\\boldsymbol{D})=(\\boldsymbol{A}\\otimes\\boldsymbol{B})(\\boldsymbol{C}\\otimes\\boldsymbol{D})Thus, dXdF​=(AC)⊗(BD)=(A⊗B)(C⊗D) 例 8. 构造函数 F=AX,X∈Rm×n\\boldsymbol{F} = \\boldsymbol{A}\\boldsymbol{X}, \\boldsymbol{X}\\in\\mathbb{R}^{m\\times n}F=AX,X∈Rm×n Process: Vec(dF)\\text{Vec}(\\text{d}\\boldsymbol{F})Vec(dF) =Vec(AdX)=\\text{Vec}(\\boldsymbol{A}\\text{d}\\boldsymbol{X})=Vec(AdX) =In⊗AVec(dX)=\\boldsymbol{I}_n\\otimes\\boldsymbol{A}\\text{Vec}(\\text{d}\\boldsymbol{X})=In​⊗AVec(dX) Answer: dFdX=In⊗A⊤\\frac{\\text{d}\\boldsymbol{F}}{\\text{d}\\boldsymbol{X}}=\\boldsymbol{I}_n\\otimes\\boldsymbol{A}^\\topdXdF​=In​⊗A⊤ 例 9. 构造函数 f=log∣X∣,X∈Rn×nf = \\text{log} |\\boldsymbol{X}|, \\boldsymbol{X}\\in\\mathbb{R}^{n\\times n}f=log∣X∣,X∈Rn×n，求二阶导（Hessian Matrix）. Process: df\\text{d} fdf $ = \\text{d}\\log|\\boldsymbol{X}|$ =1∣X∣d∣X∣=\\frac{1}{|\\boldsymbol{X}|}\\text{d}|\\boldsymbol{X}|=∣X∣1​d∣X∣ =1∣X∣∣X∣tr(X−1dX)=\\frac{1}{|\\boldsymbol{X}|}|\\boldsymbol{X}|\\text{tr}(\\boldsymbol{X}^{-1}\\text{d}\\boldsymbol{X})=∣X∣1​∣X∣tr(X−1dX) =tr(X−1dX)=\\text{tr}(\\boldsymbol{X}^{-1}\\text{d}\\boldsymbol{X})=tr(X−1dX) Hence, dfdX=Vec[(X−1)⊤], ∇Xf=(X−1)⊤=(X⊤)−1\\frac{\\text{d}f}{\\text{d}\\boldsymbol{X}}=\\text{Vec}\\left[(\\boldsymbol{X}^{-1})^\\top\\right],~\\nabla_{\\boldsymbol{X}} f = (\\boldsymbol{X}^{-1})^\\top=(\\boldsymbol{X}^\\top)^{-1}dXdf​=Vec[(X−1)⊤], ∇X​f=(X−1)⊤=(X⊤)−1 Vec(d∇Xf)\\text{Vec}(\\text{d}\\nabla_{\\boldsymbol{X}}f)Vec(d∇X​f) =−Vec[(X⊤)−1dX⊤(X⊤)−1]=-\\text{Vec}\\left[(\\boldsymbol{X}^\\top)^{-1}\\text{d}\\boldsymbol{X}^\\top(\\boldsymbol{X}^\\top)^{-1}\\right]=−Vec[(X⊤)−1dX⊤(X⊤)−1] =−X−1⊗(X−1)⊤Vec(dX⊤)= -\\boldsymbol{X}^{-1}\\otimes(\\boldsymbol{X}^{-1})^\\top\\text{Vec}(\\text{d}\\boldsymbol{X}^\\top)=−X−1⊗(X−1)⊤Vec(dX⊤) =−X−1⊗(X−1)⊤Kn,nVec(dX)= -\\boldsymbol{X}^{-1}\\otimes(\\boldsymbol{X}^{-1})^\\top\\boldsymbol{K}_{n,n}\\text{Vec}(\\text{d}\\boldsymbol{X})=−X−1⊗(X−1)⊤Kn,n​Vec(dX) Answer: ∇Xf=X−1⊤\\nabla_{\\boldsymbol{X}} f = {\\boldsymbol{X}^{-1}}^\\top∇X​f=X−1⊤ ∇X2f=−Kn,n(X−1)⊤⊗X−1\\nabla^2_{\\boldsymbol{X}} f = -\\boldsymbol{K}_{n,n}(\\boldsymbol{X}^{-1})^\\top\\otimes\\boldsymbol{X}^{-1}∇X2​f=−Kn,n​(X−1)⊤⊗X−1 例 10. 构造函数 F=AeXB,A∈Rl×m,X∈Rm×n,B∈Rn×p.\\boldsymbol{F} = \\boldsymbol{A}e^{\\boldsymbol{X}\\boldsymbol{B}}, \\boldsymbol{A}\\in\\mathbb{R}^{l\\times m}, \\boldsymbol{X}\\in\\mathbb{R}^{m\\times n}, \\boldsymbol{B}\\in\\mathbb{R}^{n\\times p}.F=AeXB,A∈Rl×m,X∈Rm×n,B∈Rn×p. Process: Vec(dF)\\text{Vec}(\\text{d}\\boldsymbol{F})Vec(dF) =Vec{A[eXB⊙(dXB)]}=\\text{Vec}\\left\\{\\boldsymbol{A}\\left[e^{\\boldsymbol{X}\\boldsymbol{B}}\\odot(\\text{d}\\boldsymbol{X}\\boldsymbol{B})\\right]\\right\\}=Vec{A[eXB⊙(dXB)]} =(Ip⊤⊗A)Vec[eXB⊙(dXB)]=(\\boldsymbol{I}_p^\\top\\otimes\\boldsymbol{A})\\text{Vec}\\left[e^{\\boldsymbol{X}\\boldsymbol{B}}\\odot(\\text{d}\\boldsymbol{X}\\boldsymbol{B})\\right]=(Ip⊤​⊗A)Vec[eXB⊙(dXB)] =(Ip⊗A)Diag(eXB)Vec(dXB)=(\\boldsymbol{I}_p\\otimes\\boldsymbol{A})\\text{Diag}(e^{\\boldsymbol{X}\\boldsymbol{B}})\\text{Vec}(\\text{d}\\boldsymbol{X}\\boldsymbol{B})=(Ip​⊗A)Diag(eXB)Vec(dXB) =(Ip⊗A)Diag(eXB)(B⊤⊗Im)Vec(dX)=(\\boldsymbol{I}_p\\otimes\\boldsymbol{A})\\text{Diag}(e^{\\boldsymbol{X}\\boldsymbol{B}})(\\boldsymbol{B}^\\top\\otimes\\boldsymbol{I}_m)\\text{Vec}(\\text{d}\\boldsymbol{X})=(Ip​⊗A)Diag(eXB)(B⊤⊗Im​)Vec(dX) Answer: dFdX=(B⊗Im)Diag(eXB)(Ip⊗A)\\frac{\\text{d}\\boldsymbol{F}}{\\text{d}\\boldsymbol{X}}=(\\boldsymbol{B}\\otimes\\boldsymbol{I}_m)\\text{Diag}(e^{\\boldsymbol{X}\\boldsymbol{B}})(\\boldsymbol{I}_p\\otimes\\boldsymbol{A})dXdF​=(B⊗Im​)Diag(eXB)(Ip​⊗A) 例 11. 一元 logistic 回归 ℓ=−yx⊤w+log⁡(1+ex⊤w)\\ell = -y\\boldsymbol{x}^\\top\\boldsymbol{w} + \\log(1 + e^{\\boldsymbol{x}^\\top\\boldsymbol{w}})ℓ=−yx⊤w+log(1+ex⊤w)，求∇wℓ\\nabla_{\\boldsymbol{w}}\\ell∇w​ℓ和∇w2ℓ\\nabla^2_{\\boldsymbol{w}}\\ell∇w2​ℓ，其中y∈0,1,x,w∈Rn×1y\\in{0,1}, \\boldsymbol{x},\\boldsymbol{w}\\in\\mathbb{R}^{n\\times 1}y∈0,1,x,w∈Rn×1. Process: $\\text{d} \\ell $ =−yx⊤dw+11+ex⊤w[ex⊤w⊙(x⊤dw)]= -y\\boldsymbol{x}^\\top\\text{d}\\boldsymbol{w}+\\frac{1}{1+e^{\\boldsymbol{x}^\\top\\boldsymbol{w}}}\\left[e^{\\boldsymbol{x}^\\top\\boldsymbol{w}}\\odot(\\boldsymbol{x}^\\top\\text{d}\\boldsymbol{w})\\right]=−yx⊤dw+1+ex⊤w1​[ex⊤w⊙(x⊤dw)] =−yx⊤dw+ex⊤w1+ex⊤w(x⊤dw)= -y\\boldsymbol{x}^\\top\\text{d}\\boldsymbol{w}+\\frac{e^{\\boldsymbol{x}^\\top\\boldsymbol{w}}}{1+e^{\\boldsymbol{x}^\\top\\boldsymbol{w}}}(\\boldsymbol{x}^\\top\\text{d}\\boldsymbol{w})=−yx⊤dw+1+ex⊤wex⊤w​(x⊤dw) =(ex⊤w1+ex⊤w−y)x⊤dw= (\\frac{e^{\\boldsymbol{x}^\\top\\boldsymbol{w}}}{1+e^{\\boldsymbol{x}^\\top\\boldsymbol{w}}}-y)\\boldsymbol{x}^\\top\\text{d}\\boldsymbol{w}=(1+ex⊤wex⊤w​−y)x⊤dw d∇wℓ\\text{d}\\nabla_{\\boldsymbol{w}}\\elld∇w​ℓ =xdex⊤w1+ex⊤w={\\color{red}\\boldsymbol{x}} \\text{d}\\frac{e^{\\boldsymbol{x}^\\top\\boldsymbol{w}}}{1+e^{\\boldsymbol{x}^\\top\\boldsymbol{w}}}=xd1+ex⊤wex⊤w​ =xex⊤w(1+ex⊤w)−e2x⊤w(1+ex⊤w)2x⊤dw=\\boldsymbol{x}\\frac{e^{\\boldsymbol{x}^\\top\\boldsymbol{w}}(1+e^{\\boldsymbol{x}^\\top\\boldsymbol{w}})-e^{2\\boldsymbol{x}^\\top\\boldsymbol{w}}}{(1+e^{\\boldsymbol{x}^\\top\\boldsymbol{w}})^2}\\boldsymbol{x}^\\top\\text{d}\\boldsymbol{w}=x(1+ex⊤w)2ex⊤w(1+ex⊤w)−e2x⊤w​x⊤dw =xex⊤w(1+ex⊤w)2x⊤dw=\\boldsymbol{x}\\frac{e^{\\boldsymbol{x}^\\top\\boldsymbol{w}}}{(1+e^{\\boldsymbol{x}^\\top\\boldsymbol{w}})^2}\\boldsymbol{x}^\\top\\text{d}\\boldsymbol{w}=x(1+ex⊤w)2ex⊤w​x⊤dw Answer: dℓdw=∇wℓ=(ex⊤w1+ex⊤w−y)x\\frac{\\text{d}\\ell}{\\text{d}\\boldsymbol{w}} = \\nabla_{\\boldsymbol{w}}\\ell = (\\frac{e^{\\boldsymbol{x}^\\top\\boldsymbol{w}}}{1+e^{\\boldsymbol{x}^\\top\\boldsymbol{w}}}-y)\\boldsymbol{x}dwdℓ​=∇w​ℓ=(1+ex⊤wex⊤w​−y)x ∇w2ℓ=xex⊤w(1+ex⊤w)2x⊤\\nabla^2_{\\boldsymbol{w}}\\ell=\\boldsymbol{x}\\frac{e^{\\boldsymbol{x}^\\top\\boldsymbol{w}}}{(1+e^{\\boldsymbol{x}^\\top\\boldsymbol{w}})^2}\\boldsymbol{x}^\\top∇w2​ℓ=x(1+ex⊤w)2ex⊤w​x⊤ 例 12. 带多重样本的一元 logistic 回归 针对包含多重样本的数据集 {(x1,y1),⋯ ,(xN,yN)}\\{(\\boldsymbol{x}_1, y_1),\\cdots,(\\boldsymbol{x}_N, y_N)\\}{(x1​,y1​),⋯,(xN​,yN​)}，ℓ=∑i=1N[−yixi⊤w+log⁡(1+exi⊤w)]\\ell = \\sum_{i=1}^N\\left[-y_i\\boldsymbol{x}_i^\\top\\boldsymbol{w}+\\log(1+e^{\\boldsymbol{x}_i^\\top\\boldsymbol{w}})\\right]ℓ=∑i=1N​[−yi​xi⊤​w+log(1+exi⊤​w)] Process No.1: The process of 例 11 Answer No.1: dℓdw=∇wℓ=∑i=1N(exi⊤w1+exi⊤w−yi)xi\\frac{\\text{d}\\ell}{\\text{d}\\boldsymbol{w}} = \\nabla_{\\boldsymbol{w}}\\ell = \\sum_{i=1}^N(\\frac{e^{\\boldsymbol{x}_i^\\top\\boldsymbol{w}}}{1+e^{\\boldsymbol{x}_i^\\top\\boldsymbol{w}}}-y_i)\\boldsymbol{x}_idwdℓ​=∇w​ℓ=∑i=1N​(1+exi⊤​wexi⊤​w​−yi​)xi​ ∇w2ℓ=∑i=1Nxiexi⊤w(1+exi⊤w)2xi⊤\\nabla^2_{\\boldsymbol{w}}\\ell=\\sum_{i=1}^N\\boldsymbol{x}_i\\frac{e^{\\boldsymbol{x}_i^\\top\\boldsymbol{w}}}{(1+e^{\\boldsymbol{x}_i^\\top\\boldsymbol{w}})^2}\\boldsymbol{x}_i^\\top∇w2​ℓ=∑i=1N​xi​(1+exi⊤​w)2exi⊤​w​xi⊤​ Process No. 2: X=[x1⊤⋮xN⊤],y=[y1⋮yN],ℓ=−y⊤Xw+1⊤log⁡(1+eXw)\\boldsymbol{X}=\\begin{bmatrix}\\boldsymbol{x}_1^\\top\\\\\\vdots\\\\\\boldsymbol{x}_N^\\top\\end{bmatrix}, \\boldsymbol{y}=\\begin{bmatrix}y_1\\\\\\vdots\\\\y_N\\end{bmatrix},\\ell=-\\boldsymbol{y}^\\top\\boldsymbol{X}\\boldsymbol{w}+\\boldsymbol{1}^\\top\\log(\\boldsymbol{1}+e^{\\boldsymbol{X}\\boldsymbol{w}})X=⎣⎢⎢⎡​x1⊤​⋮xN⊤​​⎦⎥⎥⎤​,y=⎣⎢⎢⎡​y1​⋮yN​​⎦⎥⎥⎤​,ℓ=−y⊤Xw+1⊤log(1+eXw) dℓ\\text{d}\\elldℓ =−y⊤Xdw+1⊤[eXx1+eX⊤w⊙(Xdw)]=-\\boldsymbol{y}^\\top\\boldsymbol{X}\\text{d}\\boldsymbol{w}+\\boldsymbol{1}^\\top\\left[\\frac{e^{\\boldsymbol{X}\\boldsymbol{x}}}{\\boldsymbol{1}+e^{\\boldsymbol{X}^\\top\\boldsymbol{w}}}\\odot(\\boldsymbol{X}\\text{d}\\boldsymbol{w})\\right]=−y⊤Xdw+1⊤[1+eX⊤weXx​⊙(Xdw)] =−y⊤Xdw+(1⊙eXx1+eX⊤w)⊤(Xdw)=-\\boldsymbol{y}^\\top\\boldsymbol{X}\\text{d}\\boldsymbol{w}+(\\boldsymbol{1}\\odot\\frac{e^{\\boldsymbol{X}\\boldsymbol{x}}}{\\boldsymbol{1}+e^{\\boldsymbol{X}^\\top\\boldsymbol{w}}})^\\top(\\boldsymbol{X}\\text{d}\\boldsymbol{w})=−y⊤Xdw+(1⊙1+eX⊤weXx​)⊤(Xdw) =(eXw1+eXw−y)⊤Xdw=\\left(\\frac{e^{\\boldsymbol{X}\\boldsymbol{w}}}{\\boldsymbol{1}+e^{\\boldsymbol{X}\\boldsymbol{w}}}-\\boldsymbol{y}\\right)^\\top\\boldsymbol{X}\\text{d}\\boldsymbol{w}=(1+eXweXw​−y)⊤Xdw d∇wℓ\\text{d}\\nabla_{\\boldsymbol{w}}\\elld∇w​ℓ =X⊤[eXw(1+eXw)2⊙(Xdw)]=\\boldsymbol{X}^\\top\\left[\\frac{e^{\\boldsymbol{X}\\boldsymbol{w}}}{(\\boldsymbol{1}+e^{\\boldsymbol{X}\\boldsymbol{w}})^2}\\odot(\\boldsymbol{X}\\text{d}\\boldsymbol{w})\\right]=X⊤[(1+eXw)2eXw​⊙(Xdw)] =X⊤Diag[eXw(1+eXw)2]Xdw=\\boldsymbol{X}^\\top\\text{Diag}\\left[\\frac{e^{\\boldsymbol{X}\\boldsymbol{w}}}{(\\boldsymbol{1}+e^{\\boldsymbol{X}\\boldsymbol{w}})^2}\\right]\\boldsymbol{X}\\text{d}\\boldsymbol{w}=X⊤Diag[(1+eXw)2eXw​]Xdw Answer No.2: ∇wℓ=X⊤(eXw1+eXw−y)\\nabla_{\\boldsymbol{w}}\\ell = \\boldsymbol{X}^\\top(\\frac{e^{\\boldsymbol{X}\\boldsymbol{w}}}{\\boldsymbol{1}+e^{\\boldsymbol{X}\\boldsymbol{w}}}-\\boldsymbol{y})∇w​ℓ=X⊤(1+eXweXw​−y) ∇w2ℓ=X⊤Diag[eXw(1+eXw)2]X\\nabla_{\\boldsymbol{w}}^2\\ell=\\boldsymbol{X}^\\top\\text{Diag}\\left[\\frac{e^{\\boldsymbol{X}\\boldsymbol{w}}}{(\\boldsymbol{1}+e^{\\boldsymbol{X}\\boldsymbol{w}})^2}\\right]\\boldsymbol{X}∇w2​ℓ=X⊤Diag[(1+eXw)2eXw​]X 例 13. 多元 logistic 回归 ℓ=−y⊤log softmax(Wx)=−y⊤Wx+log(1⊤eWx)\\ell = -\\boldsymbol{y}^\\top\\text{log~softmax}(\\boldsymbol{W}\\boldsymbol{x}) = -\\boldsymbol{y}^\\top\\boldsymbol{W}\\boldsymbol{x} + \\text{log}(\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}})ℓ=−y⊤log softmax(Wx)=−y⊤Wx+log(1⊤eWx)，求∇wl\\nabla_{\\boldsymbol{w}}l∇w​l和∇w2l\\nabla^2_{\\boldsymbol{w}}l∇w2​l，其中y∈Rmy\\in\\mathbb{R}^{m}y∈Rm且为 one-hot 编码, x∈Rn,W∈Rm×n\\boldsymbol{x}\\in\\mathbb{R}^{n}, \\boldsymbol{W}\\in\\mathbb{R}^{m\\times n}x∈Rn,W∈Rm×n. Process: dℓ\\text{d}\\elldℓ =−tr(y⊤dWx)+11⊤eWx⊙d(1⊤eWx)=-\\text{tr}(\\boldsymbol{y}^\\top\\text{d}\\boldsymbol{W}\\boldsymbol{x})+\\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}}\\odot\\text{d}(\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}})=−tr(y⊤dWx)+1⊤eWx1​⊙d(1⊤eWx) =−tr(y⊤dWx)+11⊤eWx1⊤[eWx⊙(dWx)]=-\\text{tr}(\\boldsymbol{y}^\\top\\text{d}\\boldsymbol{W}\\boldsymbol{x})+\\frac{1}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}}\\boldsymbol{1}^\\top\\left[e^{\\boldsymbol{W}\\boldsymbol{x}}\\odot(\\text{d} \\boldsymbol{W}\\boldsymbol{x})\\right]=−tr(y⊤dWx)+1⊤eWx1​1⊤[eWx⊙(dWx)] =−tr(y⊤dWx)+tr[(eWx1⊤eWx)⊤(dWx)]=-\\text{tr}(\\boldsymbol{y}^\\top\\text{d}\\boldsymbol{W}\\boldsymbol{x})+\\text{tr}\\left[(\\frac{e^{\\boldsymbol{W}\\boldsymbol{x}}}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}})^\\top(\\text{d} \\boldsymbol{W}\\boldsymbol{x})\\right]=−tr(y⊤dWx)+tr[(1⊤eWxeWx​)⊤(dWx)] =tr[[x(eWx1⊤eWx)⊤−xy⊤]dW]=\\text{tr}\\left[[\\boldsymbol{x}(\\frac{e^{\\boldsymbol{W}\\boldsymbol{x}}}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}})^\\top - \\boldsymbol{x}\\boldsymbol{y}^\\top]\\text{d} \\boldsymbol{W}\\right]=tr[[x(1⊤eWxeWx​)⊤−xy⊤]dW] d∇Wℓ\\text{d}\\nabla_{\\boldsymbol{W}}\\elld∇W​ℓ =deWx1⊤eWxx⊤=\\text{d} \\frac{e^{\\boldsymbol{W}\\boldsymbol{x}}}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}} \\boldsymbol{x}^\\top=d1⊤eWxeWx​x⊤ =[d(eWx)1⊤eWx−eWx1⊤d(eWx)(1⊤eWx)2]x⊤=\\left[\\frac{\\text{d}(e^{\\boldsymbol{W}\\boldsymbol{x}})}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}} - \\frac{ {\\color{red}e^{\\boldsymbol{W}\\boldsymbol{x}}}\\boldsymbol{1}^\\top\\text{d}(e^{\\boldsymbol{W}\\boldsymbol{x}})}{(\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}})^2}\\right]\\boldsymbol{x}^\\top=[1⊤eWxd(eWx)​−(1⊤eWx)2eWx1⊤d(eWx)​]x⊤ =[eWx⊙(dWx)1⊤eWx−eWx1⊤[eWx⊙(dWx)](1⊤eWx)2]x⊤=\\left[\\frac{e^{\\boldsymbol{W}\\boldsymbol{x}}\\odot(\\text{d}\\boldsymbol{W}\\boldsymbol{x})}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}} - \\frac{e^{\\boldsymbol{W}\\boldsymbol{x}}\\boldsymbol{1}^\\top[e^{\\boldsymbol{W}\\boldsymbol{x}}\\odot(\\text{d}\\boldsymbol{W}\\boldsymbol{x})]}{(\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}})^2}\\right]\\boldsymbol{x}^\\top=[1⊤eWxeWx⊙(dWx)​−(1⊤eWx)2eWx1⊤[eWx⊙(dWx)]​]x⊤ =[Diag(eWx)(dWx)1⊤eWx−eWx1⊤Diag(eWx)(dWx)(1⊤eWx)2]x⊤=\\left[\\frac{\\text{Diag}(e^{\\boldsymbol{W}\\boldsymbol{x}})(\\text{d}\\boldsymbol{W}\\boldsymbol{x})}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}}-\\frac{e^{\\boldsymbol{W}\\boldsymbol{x}}\\boldsymbol{1}^\\top\\text{Diag}(e^{\\boldsymbol{W}\\boldsymbol{x}})(\\text{d}\\boldsymbol{W}\\boldsymbol{x})}{(\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}})^2}\\right]\\boldsymbol{x}^\\top=[1⊤eWxDiag(eWx)(dWx)​−(1⊤eWx)2eWx1⊤Diag(eWx)(dWx)​]x⊤ =[Diag(eWx)(dWx)1⊤eWx−eWx(eWx)⊤(dWx)(1⊤eWx)2]x⊤=\\left[\\frac{\\text{Diag}(e^{\\boldsymbol{W}\\boldsymbol{x}})(\\text{d}\\boldsymbol{W}\\boldsymbol{x})}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}} - \\frac{e^{\\boldsymbol{W}\\boldsymbol{x}}(e^{\\boldsymbol{W}\\boldsymbol{x}})^\\top(\\text{d}\\boldsymbol{W}\\boldsymbol{x})}{(\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}})^2}\\right]\\boldsymbol{x}^\\top=[1⊤eWxDiag(eWx)(dWx)​−(1⊤eWx)2eWx(eWx)⊤(dWx)​]x⊤ =Diag(eWx)(dW)xx⊤1⊤eWx−eWx(eWx)⊤(dW)xx⊤(1⊤eWx)2=\\frac{\\text{Diag}(e^{\\boldsymbol{W}\\boldsymbol{x}})(\\text{d}\\boldsymbol{W})\\boldsymbol{x}\\boldsymbol{x}^\\top}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}} - \\frac{e^{\\boldsymbol{W}\\boldsymbol{x}}(e^{\\boldsymbol{W}\\boldsymbol{x}})^\\top(\\text{d}\\boldsymbol{W})\\boldsymbol{x}\\boldsymbol{x}^\\top}{(\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}})^2}=1⊤eWxDiag(eWx)(dW)xx⊤​−(1⊤eWx)2eWx(eWx)⊤(dW)xx⊤​ Vec(d∇Wℓ)\\text{Vec}(\\text{d}\\nabla_{\\boldsymbol{W}}\\ell)Vec(d∇W​ℓ) =xx⊤⊗[Diag[softmax(Wx)]−softmax(Wx)softmax(Wx)⊤]Vec(dW)=\\boldsymbol{x}\\boldsymbol{x}^\\top\\otimes\\left[\\text{Diag}[\\text{softmax}(\\boldsymbol{W}\\boldsymbol{x})]-\\text{softmax}(\\boldsymbol{W}\\boldsymbol{x})\\text{softmax}(\\boldsymbol{W}\\boldsymbol{x})^\\top\\right]\\text{Vec}(\\text{d}\\boldsymbol{W})=xx⊤⊗[Diag[softmax(Wx)]−softmax(Wx)softmax(Wx)⊤]Vec(dW) Answer: ∇Wℓ=[eWx1⊤eWx−y]x⊤\\nabla_{\\boldsymbol{W}}\\ell=\\left[\\frac{e^{\\boldsymbol{W}\\boldsymbol{x}}}{\\boldsymbol{1}^\\top e^{\\boldsymbol{W}\\boldsymbol{x}}} - \\boldsymbol{y}\\right]\\boldsymbol{x}^\\top∇W​ℓ=[1⊤eWxeWx​−y]x⊤ ∇W2ℓ=xx⊤⊗[Diag[softmax(Wx)]−softmax(Wx)softmax(Wx)⊤]\\nabla_{\\boldsymbol{W}}^2\\ell=\\boldsymbol{x}\\boldsymbol{x}^\\top\\otimes\\left[\\text{Diag}[\\text{softmax}(\\boldsymbol{W}\\boldsymbol{x})]-\\text{softmax}(\\boldsymbol{W}\\boldsymbol{x})\\text{softmax}(\\boldsymbol{W}\\boldsymbol{x})^\\top\\right]∇W2​ℓ=xx⊤⊗[Diag[softmax(Wx)]−softmax(Wx)softmax(Wx)⊤] 写在最后： 注意例 4 和 5 中红色标注部分，不含微分对象的变量尽量左移可以给微分求解过程去除不必要的麻烦。 本文为参考文献所涉及的两篇博客的吸收消化理解精炼，仅供学习参考使用。 Reference [1] 矩阵求导术（上） - 长躯鬼侠的文章 - 知乎 https://zhuanlan.zhihu.com/p/24709748 [2] 矩阵求导术（下） - 长躯鬼侠的文章 - 知乎 https://zhuanlan.zhihu.com/p/24863977","categories":[{"name":"MachineLearning","slug":"MachineLearning","permalink":"https://junfish.github.io/categories/MachineLearning/"}],"tags":[{"name":"Matrix","slug":"Matrix","permalink":"https://junfish.github.io/tags/Matrix/"},{"name":"Calculus","slug":"Calculus","permalink":"https://junfish.github.io/tags/Calculus/"},{"name":"derivative","slug":"derivative","permalink":"https://junfish.github.io/tags/derivative/"}]},{"title":"Markdown Grammer Cheat Sheet","slug":"common-markdown-commands","date":"2022-08-04T03:58:37.000Z","updated":"2022-08-04T06:57:14.000Z","comments":true,"path":"2022/08/03/common-markdown-commands/","link":"","permalink":"https://junfish.github.io/2022/08/03/common-markdown-commands/","excerpt":"","text":"Description syntax Result H1 Title # H1 Title H1 Title H2 Title ## H2 Title H2 Title ... ... ... H5 Title ##### H5 Title H5 Title H6 Title ###### H6 Title H6 Title Bold Text **Bold Text** Bold Text Italic Text *Italic Text* Italic Text Bold and Italic Text **_Bold and Italic Text_** Italic Text Strike-Through Text ~~Strike-Through Text~~ Strike-Through Text Ordered List 1. First point2. Second point3. Third point First point Second point Third point Bullet Point - Bullet Point 1 &ensp; - Indented Point 1.1 &ensp; - Indented Point 1.2 &ensp;&ensp; - Indented Point 1.2.1 &ensp;&ensp;&ensp; - Indented Point 1.2.1.1 &ensp;&ensp;&ensp; - ... - Bullet Point 2 - Bullet Point 3 Bullet Point 1 Indented Point 1.1 Indented Point 1.2 Indented Point 1.2.1 Indented Point 1.2.1.1 … Bullet Point 2 Bullet Point 3 Inline Code `Inline Code` Inline Code Horizontal Rules --- or *** Link [junfish](https://junfish.github.io/) junfish Picture ![example](https://junfish.github.io/photos/images/DSCF0611.jpg) Continuing…","categories":[],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"https://junfish.github.io/tags/Markdown/"},{"name":"Cheatsheet","slug":"Cheatsheet","permalink":"https://junfish.github.io/tags/Cheatsheet/"}]},{"title":"Cheat Sheet of Counting Files or Folders","slug":"counting-files-or-folders","date":"2022-06-18T20:30:55.000Z","updated":"2022-06-18T23:09:55.000Z","comments":true,"path":"2022/06/18/counting-files-or-folders/","link":"","permalink":"https://junfish.github.io/2022/06/18/counting-files-or-folders/","excerpt":"","text":"显示当前文件夹下所有文件 1ls -l | grep &quot;^-&quot; 统计当前文件夹下文件个数 1ls -l ./|grep &quot;^-&quot;|wc -l 统计当前文件夹下文件夹个数 1ls -l ./|grep &quot;^d&quot;|wc -l 递归统计当前文件夹下所有文件个数 1ls -lR | grep &quot;^-&quot;| wc -l 递归统计当前文件夹下所有文件夹个数 1ls -lR | grep &quot;^d&quot;| wc -l","categories":[{"name":"Cheatsheet","slug":"Cheatsheet","permalink":"https://junfish.github.io/categories/Cheatsheet/"}],"tags":[{"name":"commands","slug":"commands","permalink":"https://junfish.github.io/tags/commands/"},{"name":"linux","slug":"linux","permalink":"https://junfish.github.io/tags/linux/"}]},{"title":"Conda Cheat Sheet","slug":"common-conda-commands","date":"2022-05-25T06:17:45.000Z","updated":"2022-06-09T20:47:42.000Z","comments":true,"path":"2022/05/25/common-conda-commands/","link":"","permalink":"https://junfish.github.io/2022/05/25/common-conda-commands/","excerpt":"","text":"新建虚拟环境 12conda create --name my_env_name [python=3.9] # Create the environment from scratchconda env create -f environment.yml # Create the environment from the environment.yml file 列出所有虚拟环境 1conda env list 激活虚拟环境 1conda activate my_env_name 查看虚拟环境内安装包 12conda list -n my_env_name # deactivatedconda list # activated 导出虚拟环境 1conda env export &gt; environment.yml 重建虚拟环境 1conda env create -f environment.yml","categories":[{"name":"Cheatsheet","slug":"Cheatsheet","permalink":"https://junfish.github.io/categories/Cheatsheet/"}],"tags":[{"name":"conda","slug":"conda","permalink":"https://junfish.github.io/tags/conda/"},{"name":"python","slug":"python","permalink":"https://junfish.github.io/tags/python/"},{"name":"virtual environment","slug":"virtual-environment","permalink":"https://junfish.github.io/tags/virtual-environment/"},{"name":"commands","slug":"commands","permalink":"https://junfish.github.io/tags/commands/"}]},{"title":"Tmux Cheat Sheet","slug":"common-tmux-commands","date":"2022-05-24T23:31:35.000Z","updated":"2022-09-28T19:07:58.000Z","comments":true,"path":"2022/05/24/common-tmux-commands/","link":"","permalink":"https://junfish.github.io/2022/05/24/common-tmux-commands/","excerpt":"","text":"Structure Command Start a new session 12tmux new -s &lt;session_name&gt;tmux # 按照 0, 1, 2, ··· 编号 Rename a session 1tmux rename-session -t &lt;target_session_name&gt; &lt;session_new_name&gt; Detach the current session 1tmux detach Show all current sessions 1tmux ls Attach a session 1tmux attach -t &lt;session_name&gt; Kill a session 123tmux kill-session -t &lt;session_name&gt; # kill the specific sessiontmux kill-session -a # kill all sessions but the currenttmux kill-session -a -t &lt;session_name&gt; # kill all sessions but the &lt;session_name&gt; Switch between two sessions 1tmux switch -t &lt;session_name&gt; # switch to the &lt;session_name&gt; Create a new window 1tmux new-window -n &lt;window_name&gt; # create a new window named window_name Select a window 1tmux select-window -t &lt;window_name/window_number&gt; # swap to a specific window Rename a window 1tmux rename-window &lt;new_name&gt; # rename the current window Split a window into two panes 12tmux split-window # divide the window into two top and bottom panestmux split-window -h # divide the window into two left and right panes Move cursor 1tmux select-pane -U/-D/-L/-R # move the cursor to the top/bottom/left/right pane Swap two panes 1tmux swap-pane -U/-D # move the current pane to the top/bottom Reference [1] Tmux 快捷键 &amp; 速查表 &amp; 简明教程 [2] Tmux Cheat Sheet &amp; Quick Reference .markmap-container{display:flex;justify-content:center;margin:0 auto;width:90%;height:500px}.markmap-container svg{width:100%;height:100%}@media(max-width:768px){.markmap-container{height:400px}} document.querySelectorAll('.markmap-container>svg').forEach(mindmap => markmap.Markmap.create(mindmap, null, JSON.parse(mindmap.getAttribute('data'))))","categories":[{"name":"Cheatsheet","slug":"Cheatsheet","permalink":"https://junfish.github.io/categories/Cheatsheet/"}],"tags":[{"name":"Tmux","slug":"Tmux","permalink":"https://junfish.github.io/tags/Tmux/"},{"name":"Linux","slug":"Linux","permalink":"https://junfish.github.io/tags/Linux/"},{"name":"SSH","slug":"SSH","permalink":"https://junfish.github.io/tags/SSH/"}]},{"title":"hexo 中常见错误及其解决方案","slug":"regular-errors-happened-in-hexo","date":"2022-03-27T04:57:40.000Z","updated":"2023-10-27T01:24:16.174Z","comments":true,"path":"2022/03/27/regular-errors-happened-in-hexo/","link":"","permalink":"https://junfish.github.io/2022/03/27/regular-errors-happened-in-hexo/","excerpt":"","text":"menu.Page_Name 问题 众所周知，hexo new page &quot;Page_Name&quot; 可以方便快捷地在 hexo 中创建新页面，但是当我们通过如下方法将新页面添加到主页面的 menu 中时， 123打开 ./MyBlog/themes/pure/_config.yml添加 menu: Page_Name: Page_Name 然而，主页的新增页面却会出现 menu.Page_Name 的情况，这时候我们只需要找到 ./MyBlog/_config.yml 配置文件，检查 language: 字段所指向的文件。例如，我是用默认的英文语言，language: 字段指向的文件为空。这时，我们去到 ./MyBlog/themes/pure/languages/* 文件夹下找到所指向的language 配置文件 default.yml，然后按照其他案例对比添加新增页面的指向即可。 自定义 icon-font 利用网站 https://www.iconfont.cn/ 新建自己的 icon 图标项目（方便后续添加新的 icon），然后在网站中添加自己喜欢的图标到项目中（每个图标在添加项目后仍可编辑）。例如我新建的 hexo 项目如下左图所示： 接着，单击页面顶部右 2 的项目设置按钮，做出如上右图所示的项目设置（需要勾选 Base64 ）。 最后，我们 download 项目至 ./MyBlog/themes/pure/source/fonts/，打开 iconfont.css 并 copy 其中代码覆盖 ./MyBlog/themes/pure/source/css/style.css 中对应部分代码。同时，覆盖 ./MyBlog/themes/pure/source/fonts/ 下四个文件名为 iconfont 的文件。 这时，我们测试修改 ./MyBlog/themes/pure/_config.yml 中关键字如下： 12345678910111213menu_icons: enable: true # 是否启用导航菜单图标 home: icon-home archives: icon-archives categories: icon-folder tags: icon-tags publications: icon-papers repository: icon-code_lib books: icon-books movies: icon-movies travels: icon-plane_departure links: icon-links about: icon-aboutme 可以发现，小破站的 menu 图标均已变成我们自己项目中的内容了： git commit 无法回滚问题 删除 .deploy_git 文件并尝试重新提交（hexo g -d）","categories":[{"name":"站点建设","slug":"站点建设","permalink":"https://junfish.github.io/categories/%E7%AB%99%E7%82%B9%E5%BB%BA%E8%AE%BE/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://junfish.github.io/tags/hexo/"}]},{"title":"Hello World","slug":"hello-world","date":"2022-03-25T21:48:51.000Z","updated":"2022-03-25T21:48:51.000Z","comments":true,"path":"2022/03/25/hello-world/","link":"","permalink":"https://junfish.github.io/2022/03/25/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post 1$ hexo new &quot;My New Post&quot; More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment // 基于准备好的dom，初始化echarts实例 var myChart = echarts.init(document.getElementById('echarts9882')); // 指定图表的配置项和数据 var option = { title: { text: 'Stacked Line' }, tooltip: { trigger: 'axis' }, legend: { data: ['Email', 'Union Ads', 'Video Ads', 'Direct', 'Search Engine'] }, grid: { left: '3%', right: '4%', bottom: '3%', containLabel: true }, toolbox: { feature: { saveAsImage: {} } }, xAxis: { type: 'category', boundaryGap: false, data: ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'] }, yAxis: { type: 'value' }, series: [ { name: 'Email', type: 'line', stack: 'Total', data: [120, 132, 101, 134, 90, 230, 210] }, { name: 'Union Ads', type: 'line', stack: 'Total', data: [220, 182, 191, 234, 290, 330, 310] }, { name: 'Video Ads', type: 'line', stack: 'Total', data: [150, 232, 201, 154, 190, 330, 410] }, { name: 'Direct', type: 'line', stack: 'Total', data: [320, 332, 301, 334, 390, 330, 320] }, { name: 'Search Engine', type: 'line', stack: 'Total', data: [820, 932, 901, 934, 1290, 1330, 1320] } ] }; // 使用刚指定的配置项和数据显示图表。 myChart.setOption(option);","categories":[],"tags":[]},{"title":"Terminology in Billiards","slug":"terminology-in-billiards","date":"2021-10-02T23:11:56.000Z","updated":"2022-04-23T18:22:17.000Z","comments":true,"path":"2021/10/02/terminology-in-billiards/","link":"","permalink":"https://junfish.github.io/2021/10/02/terminology-in-billiards/","excerpt":"","text":"写在前面 这周末和朋友约了场台球，因为台球桌是在 apartment 住处自带的 club 里面，所以并不是每次去都是空闲的。我们这次去的时候运气非常不好的成了替补球员。难受啊马飞~！几个 Indian guys 已经在玩了，怎么办呢？我们就看着他们打，只要我不尴尬，尴尬的就是他们，就等你们邀请我们加入，哈哈。果不其然，他们来了句：Do you wanna join us? 正中心机 boy 下怀，嘿嘿。 但是这种 social activity 很难免的需要交流，我就发现在台球运动上的术语储备太匮乏了，只能尬吹 “great shot”, 所以回来赶紧整理了一下台球相关的术语，有备无患。 鉴于斯诺克的国际赛事每年都很多，相关的术语永远可以找到相应的资料和解说视频可以学习，我们就聚焦于更大众化的十六彩（黑八）。 Terminology 最开始的当然是开球咯，经常看球赛的朋友脑海里一定开始环绕 “Ding Junhui to break.” 没错，就是 break，当然使用 start 或者 begin 之类的也是可以达意的，无伤大雅。 黑八的玩法无论规则如何，无法避免谈及的就是花色与全色。全色球是 solid ball，花色球是 stripe ball。 器具类： billiards: 台球（总称）。但其实我发现老美不太喜欢复杂的术语，你说 billiards 不一定有人懂，但是你说 pool 他们基本都知道。如何在酒吧优雅的回答 “Do you wanna play some pool?” “Sry, I can’t swim.” 化身全场最闪亮的仔。 table: 球台 cushion: 库边，也是我们常说的“颗星”的音译 chalk: 巧克 powder: 滑石粉。为什么这种严重影响手感的玩意会有人用。简直和拿 magic mouse 玩游戏差不多体验。 cue ball: 母球 object ball: 目标球 rest: 架杆 extension: 加长杆 cue (stick): 球杆 tip: 杆头 joint: 非通杆的连接处 triangle: 摆球的三角架 pocket: 球袋 top pocket middle pocket bottom pocket lampshade: 灯罩。至于为啥需要这个词，因为你永远会遇到用球杆捅灯的女孩，画面感是不是有了？ 状态类： ball in hand: 自由球。根据我查的资料其实不是 free ball，free ball 似乎已经成了斯诺克的一个专有名词。 foul: 犯规 snooker: 被遮挡，障碍球。动词化用法也是挺常见的，snookered touching ball: 贴球 frozen: 贴库或咬死的状态 lawed ball: 袋口挤住的球 nominated ball/called ball: 指定球 called pocket: 指定袋 tie: 平局。耳边回荡起马龙的灵魂质问“ tie 什么 tie?” forced off the table: 击球出界。像我这种猛男， dictionary 里必须常备这种短语 杆法类： combination: 传球 bank shot: 翻袋。因为 bank 也可以用来表示库边。 draw shot: 低杆。新手装逼必备杆法。 back spin: 下旋 stop shot: 定杆 stun: 斯登。高手最朴实无华的杆法，却尽显深厚内功，懂的自然懂，好吧。重剑无锋。 follow shot: 高杆 top spin: 上旋 side spin: 加塞旋转 push stroke: 推杆 double hit: 连击。touching ball 处理不当极易由 push stroke 导致这种犯规。 double kiss: 双击。处理库边的 frozen ball 经常出现的情况，不是犯规，而是击球分离角度计算失误造成的。 english/side spin: 弧线球。其实打大球想要出弧线的效果基本只能是扎杆（prick stroke）了。 fluke: 运气球 kick shot: 勾球。和 snooker 是黄金搭档哦😯 jump shot: 跳球。个人认为最应该从规则里剔除的杆法，伤台伤球，又有失优雅。正经人谁跳球啊，你跳球么？我反正不跳。跳起来的球能叫台球么？下贱！ scratch: 摔袋。黑八的噩梦。。。 positioning: 走位 miscue: 滑杆。什么？你说滑杆不是杆法，丁主任比赛看全了吗？ thick cut: 厚切 thin cut 薄切 feather shot: 薄球 ​","categories":[{"name":"Recreation","slug":"Recreation","permalink":"https://junfish.github.io/categories/Recreation/"}],"tags":[{"name":"billiards","slug":"billiards","permalink":"https://junfish.github.io/tags/billiards/"},{"name":"terminology","slug":"terminology","permalink":"https://junfish.github.io/tags/terminology/"}]},{"title":"Practice in Professional Email Writing","slug":"practice-in-email-writing","date":"2021-09-15T22:53:54.000Z","updated":"2022-05-25T17:52:18.000Z","comments":true,"path":"2021/09/15/practice-in-email-writing/","link":"","permalink":"https://junfish.github.io/2021/09/15/practice-in-email-writing/","excerpt":"","text":"Ending &amp; beginning of an email The safe expression in order of formality: Nothing →\\rightarrow→ Thanks →\\rightarrow→ Thank you →\\rightarrow→ Many Thanks →\\rightarrow→ Kind regards →\\rightarrow→ Best regards →\\rightarrow→ Sincerely →\\rightarrow→ Yours SIncerely. “sincerely” can be only used when you know the name of the specific person. The safest expression in any situation to anyone is “Best”. The safe expression of the beginning: Dear __ or Hi __. Don’t use “Dear” if the recipient responds you starting with a “Hi”. Otherwise, it seems a little bit weird and even cold. “Dear” is more formal than “Hi”. Body of the text Start positive and friendly with some basic background information and the reason why you’re writing. Get to the point directly, in the first paragraph or the first sentence, if possible. Give extra details if the recipients are not familiar with the topic. Use bullet points to organize your thoughts and logistics. Keep sentences relatively short: 505050 ≤\\le≤ Total Word Number ≤\\le≤ 150150150; Sentence ≤20\\le20≤20 words; Paragragh ≤7\\le7≤7 sentences (444 or 555 lines). Keep the total length could be viewed entirely under the popular screen size. Don’t be too direct with the British person. It may not be a massive problem, but it’s still important to be polite to anyone in a senior position to you. More hedging expressions can avoid a rude impression about yourself: I was wondering if + modal verb + please + reason: I was just wondering if you might be able to (be possible for you to do ···) ··· so that I can start working on the next step ···. Could you please help me to ···？ Please can you not make me do ···？ I was thinking of doing ···. What do you think? Avoide using “I’ve decided to ···” especially you’re lower down in your working place. Will →change to\\xrightarrow{change\\ to}change to​ Would. (Not always work) Do you think it would be okay to ···? Tell the recipients what they should do after this email. Please let me know if you have any questions. Looking forward to hearing from you soon. Please feel free to contact me. Attachment Be sure to mention clearly and explicitly any attached files. Give more details for the name of your attached files, such as Lehigh_Jun_Yu_Resume.pdf. Psychology-backed tactics Start strong for the subject line and keep it short, using clear and descriptive words. Length: Keep it short, roughly 141414 words. Consider the key point. Clarity: don’t be too vague of the chosen keywords. Consider the better experience of searching and filtering. If you want to convince someone, state the benefits they will get. Give reasons when ask someone to do something. The magic of the word “because” is resulting in more compliance. Recall the action you are requesting again in the last sentence of the first introduction paragraph. Use positive words, but do not over do it. Actually, for the tendency of response, a neutral tone ≤\\le≤ a slightly positive tone ≤\\le≤ a slightly positive tone. Positive words: yes, possible, together, please, ··· Negative words: never, impossible, without, stuck, ··· Use memory tricks in your information statements. Limit lists to 333 items maximum to avoid the difficulties of recalling. Use Familiar-New information flow to make reader absorb information more easily. Always say “Thank you”. Showing appreciation triggers more helpful behavior. More you, less me. In addition, more us, less me. The reason behind it is that we all care more about ourselves. Humans are social animals. They are more likely to provide help if they feel in the same situation with you. Use the recipient’s name and show some emotion and visual language. Emotional words: glad, appreciate, understand, happy, discover, ··· Visual language: see, clear, looks good, visualize, realize, bright, pattern, thin, ··· Tip: Read your writing email loud out before hit the “send” button. Express, not impress. Be concise and clear. Informal, plain English is totally fine; it’s better than poetry language. Use familiar words nad avoid complicated words. More verbs than nouns. Avoid reduntant words. Don’t oversimplify. Avoid too much abbreviations. Use transition words to organize your ideas. Use active voice instead of passive voice. Show authority and confidence and remove weak statements. Balance between being friendly and lacking confidence. Don’t Never use more than one exclamation mark unless you’re writing to a friend. Avoid use exclamation mark in general. Avoid text messaging and misspellings. Don’t write the email with anger, distress or some other negative emotion. Avoid voilating any policies, laws, rules or folkways in the receipient’s culture. Before Sending Check misspellings &amp; typos (Use grammer tools like “Grammarly”). Make sure that Email is better than a phone call or face-to-face communication. Make sure it’s polite to say this email out face to face before your receipient. Read this email to feel if the information flow is logical and it’s easy to get the point. Tips for the email to VIP Let it rest in the drafts and read it many times. Use reviewers’ suggestions. Reference [1] 【撰写英文邮件的技巧规则】 - Susie 戴舒萱的视频 - 知乎 https://www.zhihu.com/zvideo/1382430931886739456 [2] https://www.craftofscientificwriting.com/badge_emails.html [3] How to Write Professional Emails in English, written by Paola Pascual.","categories":[{"name":"WritingSkills","slug":"WritingSkills","permalink":"https://junfish.github.io/categories/WritingSkills/"}],"tags":[{"name":"writing","slug":"writing","permalink":"https://junfish.github.io/tags/writing/"},{"name":"E-mail","slug":"E-mail","permalink":"https://junfish.github.io/tags/E-mail/"}]},{"title":"Definition of Different Multi-X Learning","slug":"difference-between-multi-X-learning","date":"2021-09-10T20:15:11.000Z","updated":"2022-05-25T17:52:04.000Z","comments":true,"path":"2021/09/10/difference-between-multi-X-learning/","link":"","permalink":"https://junfish.github.io/2021/09/10/difference-between-multi-X-learning/","excerpt":"","text":"0. Introduction We discuss Multi-X Learning in two main categories: Multi-input learning and multi-output learning. Their relationships are shown in an imperfect venn diagram as follows. The dotted line implies some special cases would make itself cross the boundaries among these multi-X learning paradigms. 1. Multi-output Level Multi-class classification[1] Label of data is defined as multiple (3+3+3+) classes, but any sample in the dataset is specified into only one of these multiple classes. If we use a one-hot encoding to represent different classes, then all labels in the dataset contain the only 111 and leave the left values as 000. Multi-label classification[2][3][4] It can be understood as a generalization of the multi-class classification problem;there is more than one class assigned to a sample in multi-label problem . Thus, if its label is represented by a one-hot encoding, there is no constraint on the number of 111s or 000s on the entries of the binary vector. Multi-target Regression[5] Multi-target regression aims to simultaneously learn multiple regression responses attached to any instance, in which each response has its own distribution but shares same instance set. Multi-task Learning[6][7] MTL aims to learn mmm related tasks simultaneously to improve the performance of a model by sharing the information among these different tasks. These tasks could be represented by datasets from related but different sources. 2. Multi-input Level Multi-instance Learning[8] Different from multi-label learning with multiple labels per instance, multi-instance learning has just one label per several instances. Multi-instance learning is a special supervised learning paradigm that targets the bags of the instances. If any instance in a bag of instances is labeled as positive, then this bag is labeled as positive, otherwise it’s labeled as negative if all the instances are labeled as negative. However, there is no any label attached to the individual instances. Multi-view Learning[9] Multi-view learning has different sets of features for the single-source data in a single-task learning, such as different color features and texture features extracted from the images; these views may also be obtained from different sources, such as urls and words contained in a web page. Multi-modality learning is a special case of multi-view learning, in which different sets of features are represented by data in different modalities. 3. Transfer Learning[10] Learn representations on a target domain with the help of source domain, which alleviates the dependence on labeled data in target domain and achieves matching results compared with leaning from large-scale annotated dataset. 4. Comparison and Connection[7] Multi-label Learning &amp; Multi-target Regression[5] If all targets in a multi-target regression problem are binary variates (predicted by using logistic regression), we can understand it as a special case of multi-label learning. Multi-label Learning &amp; Multi-task Learning Multi-label learning takes advantage of dataset in which multiple labels are associated with identical data point. However, multi-task learning always targets several datasets from related but different data sources. If each of the multiple labels is separately treated as a task, but learning a sharing machine to predict all labels, then we can also resort to multi-task learning model to solve multi-label problem. Multi-view Learning &amp; Multi-task Learning Multi-view learning is a single task learning with many different sets of features where multi-task learning aims to learn different tasks together. The intersection between them is ∅\\emptyset∅. Transfer Learning &amp; Multi-task Learning Transfer learning aims to improve target task by using source task, but all tasks are equally treated and mutually learn representations from each other in Multi-task learning. On the other hand, target task is learned after source task in transfer learning but all tasks are shared and learned together in multi-task learning. From my point view, transfer learning is a special case of multi-task learning (mutually transfer learning). Reference [1] https://en.wikipedia.org/wiki/Multiclass_classification [2] https://en.wikipedia.org/wiki/Multi-label_classification [3] Zhang, Min-Ling, and Zhi-Hua Zhou. “A review on multi-label learning algorithms.” IEEE transactions on knowledge and data engineering 26.8 (2013): 1819-1837. [4] Zhou, Zhi-Hua, and Min-Ling Zhang. “Multi-label Learning.” (2017): 875-881. [5] Xu, Donna, Yaxin Shi, Ivor W. Tsang, Yew-Soon Ong, Chen Gong, and Xiaobo Shen. “Survey on multi-output learning.” IEEE transactions on neural networks and learning systems 31, no. 7 (2019): 2409-2429. [6] Caruana, Rich. “Multitask learning.” Machine learning 28.1 (1997): 41-75. [7] Zhang, Yu, and Qiang Yang. “A survey on multi-task learning.” arXiv preprint arXiv:1707.08114 (2017). [8] https://www.cs.cmu.edu/~juny/MILL/review.htm [9] Xu, Chang, Dacheng Tao, and Chao Xu. “A survey on multi-view learning.” arXiv preprint arXiv:1304.5634 (2013). [10] Zhuang, Fuzhen, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu Zhu, Hui Xiong, and Qing He. “A comprehensive survey on transfer learning.” Proceedings of the IEEE 109, no. 1 (2020): 43-76.","categories":[{"name":"MachineLearning","slug":"MachineLearning","permalink":"https://junfish.github.io/categories/MachineLearning/"}],"tags":[{"name":"Multi-X Learning","slug":"Multi-X-Learning","permalink":"https://junfish.github.io/tags/Multi-X-Learning/"},{"name":"Multi-class","slug":"Multi-class","permalink":"https://junfish.github.io/tags/Multi-class/"},{"name":"Multi-label","slug":"Multi-label","permalink":"https://junfish.github.io/tags/Multi-label/"},{"name":"Multi-instance","slug":"Multi-instance","permalink":"https://junfish.github.io/tags/Multi-instance/"},{"name":"Multi-view","slug":"Multi-view","permalink":"https://junfish.github.io/tags/Multi-view/"},{"name":"Multi-source","slug":"Multi-source","permalink":"https://junfish.github.io/tags/Multi-source/"},{"name":"Multi-task","slug":"Multi-task","permalink":"https://junfish.github.io/tags/Multi-task/"}]},{"title":"ImageNet 从下载到喂入模型训练","slug":"preprocess-imagenet-ILSVRC2012","date":"2021-07-26T16:03:03.000Z","updated":"2022-10-04T18:43:22.000Z","comments":true,"path":"2021/07/26/preprocess-imagenet-ILSVRC2012/","link":"","permalink":"https://junfish.github.io/2021/07/26/preprocess-imagenet-ILSVRC2012/","excerpt":"","text":"本文目的 鉴于目前网络上并无相关从 imagenet 官网下载竞赛数据到训练的相关教程，本文提供从获取数据到训练的全步骤讲解。 下载并解压数据 进入官网下载页面 https://image-net.org/challenges/LSVRC/2012/2012-downloads.php 获取下载链接。 利用 wget命令下载数据（一共四个数据文件）。 1234wget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_train.tarwget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tarwget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_train_t3.tarwget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_test_v10102019.tar 利用tar命令解压缩数据包放入指定文件夹 首先尝试解压缩部分文件探索数据文件目录结构：tar -xvf ./ILSVRC2012_img_train_t3.tar -C test。然后，通过bash命令批处理删除生成的文件：find ./test -name '*.JPEG' -type f -print -exec rm -rf &#123;&#125; \\;。 经探索发现文件结构如下： 12345678910111213141516171819202122| - - ILSVRC2012_img_train.tar | - - n01440764.tar | - - n01440764_2708.JPEG | - - n01440764_7173.JPEG ··· ···| - - ILSVRC2012_img_val.tar | - - ILSVRC2012_val_00010062.JPEG | - - ILSVRC2012_val_00009546.JPEG ...| - - ILSVRC2012_img_train_t3.tar | - - n02085620.tar | - - n02085620_10074.JPEG | - - n02085620_10131.JPEG ··· ···| - - ILSVRC2012_img_test_v10102019.tar | - - test | - - ILSVRC2012_test_00013640.JPEG | - - ILSVRC2012_test_00020698.JPEG ··· ... 编写python脚本文件批处理解压并删除中间tar文件： 123456789101112131415161718192021222324252627282930313233import tarfileimport osfrom tqdm import tqdmdef get_tar(path): tar_files = [] for name in os.listdir(path): # 遍历当前目录下所有文件和文件夹 if &#x27;.tar&#x27; in name: # 筛选出当前文件夹下需要解压的 .tar 文件 tar_files.append(name) return tar_filesdef untar(ori_file): print(&quot;Untar the file: &quot; + ori_file) new_dir_name = os.path.splitext(ori_file)[0] tar = tarfile.open(ori_file) names = tar.getnames() for name in tqdm(names): tar.extract(name, new_dir_name) if &#x27;.tar&#x27; in name: new_ori_file = os.path.join(new_dir_name, name) # 获取 tar 包内的 tar 包文件 untar(new_ori_file) # 解压 tar 包 os.remove(new_ori_file) # 解压完成后删除 tar 包 tar.close()def main(): abs_path = os.getcwd() # 获取当前文件所在目录绝对路径 tar_files = get_tar(abs_path) # 获取待解压的所有 tar 包 for tar_file in tar_files: ori_file = os.path.join(abs_path, tar_file) untar(ori_file)if __name__ == &quot;__main__&quot;: main() 上述代码保证了解压缩完的数据文件与原始的tar包文件结构一致（去除.tar后缀直接做文件夹名称）。 获取标签 从官网下载 Development Kit，获取1000个分类类别标签。 两个压缩包解压后的目录结构如下所示： 123456789| - - ILSVRC2012_devkit_t12 | - - COPYING | - - data | - - ILSVRC2012_validation_ground_truth.txt | - - meta.mat | - - evaluation | - - *.txt | - - *.m | - - readme.txt 其中，true label 的 value 存储于ILSVRC2012_devkit_t12/data/文件夹下。其中.txt文件包含 50,000 验证集的 class index values，每一行为对应图片（images 按序编号）的 class index label。 另外，其余训练集信息包含于meta.mat文件中，用 matlab 打开该文件，其中大小为1860×11860\\times11860×1的 synsets 结构体包含的数据详情如下截图所示： 其中关键信息为 ILSVRC2012_ID 和 WNID 两列，分别对应 class true label 和训练集文件夹名称。 数据集与标签匹配关系（借用 Cheat Sheet of Counting Files or Folders 探索解压后文件夹结构） 训练集ILSVRC2012_img_train下一级目录名（#1000）均可在 synsets 结构体 WNID 列（#1860）内找到对应，从而可以锁定以 WNID 为目录名下所有图片标签。 验证集ILSVRC2012_img_val下直接存储验证集所有图片（#50000），其文件名为ILSVRC2012_val_00000001到ILSVRC2012_val_00050000。这时我们需要借助ILSVRC2012_devkit_t12/data/ILSVRC2012_validation_ground_truth.txt文件来匹配文件名所对应的 ILSVRC2012_ID，从而在 synsets 结构体中与 WNID 关联。 测试集（#100000）同验证集 综上所述，训练集通过目录名称 -&gt; synsets -&gt; WNID -&gt; ILSVRC2012_ID匹配上标签，验证集和测试集通过文件名 -&gt; ILSVRC2012_validation_ground_truth.txt -&gt; synsets -&gt; ILSVRC2012_ID -&gt; WNID匹配上标签。 数据集整理 训练集目录结构刚好符合 torchvision.datasets.ImageFolder 的目录结构安排。 以此为标准，我做了如下的整理： 训练集结构不变，次级目录名称由 WNID 改为 ILSVRC2012_ID 验证集与测试集按照训练集标准安排结构，类别序号（ILSVRC2012_ID）做目录名称，包含该类别所有图片 编写python脚本按照上述思路整理数据集: 1234567891011121314151617181920212223242526272829303132333435363738import osimport shutilimport scipy.io as siodef rename_train(meta_data, img_root): dir_names = os.listdir(img_root) for dir_name in dir_names: for item in meta_data: if dir_name == item[0][1][0]: os.rename(os.path.join(img_root, dir_name), os.path.join(img_root, str(item[0][0][0][0]))) breakdef group_val(ground_truth, img_dir): with open(ground_truth) as f: lines = f.readlines() labels = [int(line.strip()) for line in lines] filenames = os.listdir(img_dir) for filename in filenames: img_idx = int(filename.split(&#x27;_&#x27;)[-1].split(&#x27;.&#x27;)[0]) ILSVRC_ID = labels[img_idx - 1] output_dir = os.path.join(img_dir, str(ILSVRC_ID)) if not os.path.isdir(output_dir): os.mkdir(output_dir) shutil.move(os.path.join(img_dir, filename), os.path.join(output_dir, filename)) passif __name__ == &quot;__main__&quot;: synsets = &#x27;/data/Datasets/ImageNet2012/ILSVRC2012_devkit_t12/ILSVRC2012_devkit_t12/data/meta.mat&#x27; ground_truth = &#x27;/data/Datasets/ImageNet2012/ILSVRC2012_devkit_t12/ILSVRC2012_devkit_t12/data/ILSVRC2012_validation_ground_truth.txt&#x27; val_dir = &#x27;/data/Datasets/ImageNet2012/ILSVRC2012_img_val&#x27; train_dir = &#x27;/data/Datasets/ImageNet2012/ILSVRC2012_img_train&#x27; meta_data = sio.loadmat(synsets)[&quot;synsets&quot;] a = meta_data[0, 0][1][0] rename_train(meta_data, train_dir) group_val(ground_truth, val_dir) 其中rename_val用于训练集分类别目录重命名，group_val用于验证集图片整理。 整理完的训练集与验证集目录结构如下（同 torchvision.datasets.ImageFolder）： 12345678910111213141516171819| - - ImageNet2012 | - - ILSVRC2012_img_train | - - 1 | - - n02119789_10007.JPEG | - - n02119789_10584.JPEG | - - n02119789_11491.JPEG ... | - - 2 ... ... | - - ILSVRC2012_img_val | - - 1 | - - ILSVRC2012_val_00000756.JPEG | - - ILSVRC2012_val_00006145.JPEG | - - ILSVRC2012_val_00009128.JPEG ... | - - 2 ... ... 根据统计，训练集共有 1,281,167 张图片+标签，验证集有 50,000 张图片+标签，测试集有 100,000 张图片，和官方标准一样。 写在最后 本文目的在于探索一个未知数据集的具体解决思路，从python脚本语言入手简洁明了。为了更加高效，可直接移步pytorch官方bash处理方法 Reference [1] Official pytorch example [2] ILSVRC2012 Official Website [2] ImageNet数据集到底长什么样子？ - 七个太阳的回答 - 知乎 [3] ImageNet使用方法？ - 薰风初入弦的回答 - 知乎 可视化 .markmap-container{display:flex;justify-content:center;margin:0 auto;width:90%;height:500px}.markmap-container svg{width:100%;height:100%}@media(max-width:768px){.markmap-container{height:400px}} document.querySelectorAll('.markmap-container>svg').forEach(mindmap => markmap.Markmap.create(mindmap, null, JSON.parse(mindmap.getAttribute('data'))))","categories":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"https://junfish.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"ImageNet","slug":"ImageNet","permalink":"https://junfish.github.io/tags/ImageNet/"},{"name":"Preprocess","slug":"Preprocess","permalink":"https://junfish.github.io/tags/Preprocess/"},{"name":"预处理","slug":"预处理","permalink":"https://junfish.github.io/tags/%E9%A2%84%E5%A4%84%E7%90%86/"}]},{"title":"Popular Datasets in SSL of CV","slug":"popular-CV-dataset-intro","date":"2021-07-07T17:49:38.000Z","updated":"2022-08-25T02:09:34.000Z","comments":true,"path":"2021/07/07/popular-CV-dataset-intro/","link":"","permalink":"https://junfish.github.io/2021/07/07/popular-CV-dataset-intro/","excerpt":"","text":"Introduction This blog is an excerpt from my own paper 《A survey on pre-trained models in text, image and graph: powerful self-supervised deep learning via big data》 that targets introducing the powerful pre-trained model (PTM) in Self-Supervised Learning (SSL) era. This blog serves as a synopsis of benchmark datasets in SSL in computer vision (CV). Classification The MNIST[1] is a database of handwritten digits containing 60,00060,00060,000 training examples and 10,00010,00010,000 testing examples. The images are fixed-size with 28×2828\\times2828×28 pixels. The pixel values are from 000 to 255.0255.0255.0 in which pixel values smaller than 255.0255.0255.0 can be understood as background (white) and 255 means foreground (black). The labels are from 0 to 9 and only one of these digits exists in an image. Both traditional and deep learning methods are based on this most popular dataset despite advanced methods showing perfect results. Thus, Geoffrey Hinton has described it as “the drosophila of machine learning”. Also in the domain of digit number, The Street View House Numbers (SVHN)[2] dataset collects real-world digit numbers from house numbers in Google Street View images. There are 73,25773,25773,257 digits for training, 26,03226,03226,032 digits for testing, and 531,131531,131531,131 additional, and all of them are 32×3232\\times3232×32 color images with both class labels and character level bounding boxes. As more advanced methods show perfect results on simple dataset, more sophisticated dataset such as CIFAR-10/CIFAR-100[3] are conducted. These two datasets are more close to the real-world object. The CIFAR-10 consists of 50,00050,00050,000 training images and 10,00010,00010,000 testing images, with 6,0006,0006,000 images per class and 32×3232\\times3232×32 pixels in each RGB colour image. The CIFAR-100 is similar to the CIFAR-10 but with more detailed label information. There are 100100100 classes containing 500500500 training images and 100100100 testing images in each class. In addition, these 100100100 “fine” classes are grouped equally into 202020 “coarse” classes. Researchers can adapt it to suitable learning methods. Inspired by the CIFAR-10 dataset, **STL-10[4] is another 96×9696\\times9696×96 color image dataset containing similar 101010 real-world classes. Each class has 500500500 training images and 800800800 test images. The biggest difference is that STL-10 has 100,000100,000100,000 unlabeled images for unsupervised learning. More construction information can be seen in [5]. Caltech-101[6] collects roughly 300×200300\\times200300×200 color images of objects belonging to 101101101 categories, with 404040 to 800800800 images per category and 505050 on average. The outlines of the objects in the pictures are annotated for the convenience of different learning methods. ImageNet[7] is one of the most popular and large-scale dataset on computer vision. It is built according to the hierarchical structure of WordNet[8]. The full ImageNet dataset contains 14,197,12214,197,12214,197,122 images and 21,84121,84121,841 synsets indexed, attaching on average 1,0001,0001,000 images to illustrate each synset. The most frequently-used subset of ImageNet is the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) dataset from 2010 to 2017, containing tasks of classification, localization, and detection. The number of samples in training and testing datasets and the labels of images is determined by the specific task, more details are seen in [9]. In addition to the popular MNIST, there still exist many domain datasets used for the downstream tasks in the classification problem. HMDB51[10][11] is an action video database for a total of 7,0007,0007,000 clips in 515151 action classes. It contains five types of facial actions and body movements. UCF101[12] is another action video data set designed for the more realistic action recognition. It is an extension of UCF50[13] data set containing only 50 action categories with 101101101 action categories, collected from YouTube. What makes it a famous recognition dataset is the workshop in ICCV13 with UCF101 as its main competition benchmark. Food-101[14] is a real-world food dataset of 101101101 food categories, with 750750750 and 250250250 images per class in training and testing dataset respectively. Birdsnap[15] is a large-scale fine-grained visual categorization of birds, with bounding boxes and the locations/annotations of 171717 parts in the object. It contains 49,82949,82949,829 images of 500500500 most common species in North American, with each species containing 696969 to 100100100 images and most species having 100100100. In addition, some images are also labeled as male or female, immature or adult, and breeding or non-breeding plumage. To target the scene categorization, the extensive Scene UNderstanding (SUN)[16][17] database fills the gap of the existing dataset with the limited scope of categories. This database contains 899899899 categories and 130,519130,519130,519 images, and only images with more than 200×200200\\times200200×200 pixels were kept. SUN397 is a more well-sampled subset that maintains 397397397 categories with at least 100100100 images per category, in which other categories containing relatively few unique photographs are discarded. Places205[18] dataset is another large scale scene dataset consists of 2,448,8732,448,8732,448,873 images from 205205205 scene categories. Cars[19] dataset in the domain of cars contains 16,18516,18516,185 color images of 196196196 classes (at the level of Make, Model, Year) of cars. For convenience, this dataset is split into training and test set in roughly equal quantities. Aircraft[20] is another fine-grained visual classification designed for aircraft (also known as FGVC-Aircraft). A popular form of this dataset is the fine-grained recognition challenge 2013 (FGComp2013)[21] ran in parallel with the ILSVRC2013. There exist four-level hierarchy: Model, Variant, Family, Manufacturer, from finer to coarser to organize this database. The more detailed information is shown in [22]. Pets[23] represents The Oxford-IIIT Pet Dataset that collects 373737 pet categories with roughly 200200200 images per category. All images have an associated ground truth annotation of breed for classification, head ROI for detection, and pixel-level trimap for segmentation. Similarly, Flowers[24] is another domain dataset in flowers also collected by Oxford; it contains Oxford-17 Flowers of 171717 categories and Oxford-102 Flowers of 102102102 categories. The Describable Textures Dataset (DTD)[25] is an evolving collection of textural images in the wild, which consists of 5,6405,6405,640 images of 474747 categories, with 120120120 images per category. iNaturallist2018[26] is a large-scale species classification competition conducted on the FGVC5 workshop at CVPR2018. This dataset contains over 8,0008,0008,000 species categories, with more than 450,000450,000450,000 images in the training and validation dataset collected from iNaturalist[27]. Detection COCO[28] is a large-scale data set for object detection, segmentation, and caption; it contains 330,000330,000330,000 rgb images, with more than 200,000200,000200,000 labelled. There are 1.51.51.5 million​ object instances of 808080 object categories involved. Thus, it is one of the most popular benchmark data set in detection and segmentation in parallel with the following PASCAL VOC. The PASCAL VOC project[29] provides standardized image datasets for object class recognition and also has run challenges evaluating performance on object class recognition from 2005 to 2012. The main datasets used in self-supervised learning are VOC07, VOC11, and VOC12. Main competitions in VOC07[30] contains classification and detection tasks; both of them consist of 202020 objects and contain at least one object in each image. Thus, it is common to use VOC07 serving as the downstream task for the detection. Segmentation Both VOC11[31] and VOC12[32] contains classification, detection, and segmentation tasks in the main competition, thus leading to the common use of down stream task for the segmentation. ADE20K[33][34] collects 27,57427,57427,574 images from both the SUN and Places205 databases, in which 25,57425,57425,574 for training and 2,0002,0002,000 for testing. All 707,868707,868707,868 objects from 3,6883,6883,688 categories existing in images are annotated. Especially, this dataset contains 193,238193,238193,238 annotated object parts and parts of parts, and additional attributes, annotation time, depth ordering for the benefit of research community. The NYU-Depth V2[35] is a dataset consists of images and video sequences from 464464464 indoor scenes that are recorded by both the RGB and Depth cameras from 333 cities. It contains 1,4491,4491,449 images with the ground truth of depth, and the original RGB values are also provided. In addition, there are 407,024407,024407,024 new unlabeled frames and additional class labels for the objects in images. Cityscapes[36][37] is a dataset of urban street scenes from 505050 cities with the ground truth of semantic segmentation. The main instances are vehicles, people, and construction. The high-quality dense pixel annotations contain a volume of 5,0005,0005,000 images. In addition to the fine annotations, coarser polygonal annotations are provided for a set of 20,00020,00020,000 images. Moreover, the videos consist of not consistent images with high-quality annotations, and these annotated images with consistent changing views are provided for researchers. LVIS[38] is dataset for large vocabulary instance segmentation. It features that 1) a category or word in one image is related to the only segmentation object; 2) more than 1,2001,2001,200 categories are extracted from roughly 160,000160,000160,000 images; 3) long tails phenomenon exist in these categories; and 4) more than 2,000,0002,000,0002,000,000 high-quality instance segmentation masks. Densely Annotated VIdeo Segmentation (DAVIS)[39] is a video dataset designed for the in-depth analysis of the SOTA in video object segmentation, in which DAVIS 2017[40] contains both semi-supervised (human-guided at test time) and unsupervised (human non-guided at test time) video sequences with multiple annotated instances. Others Paris StreetView dataset[41] is designed for image inpainting task, which contains 14,90014,90014,900 training images and 100 test images collected from street views of Paris. This dataset is collected from Google Street View and mainly focuses on the buildings in the city. Based on MNIST, Moving-MNIST[42] is a video dataset designed for evaluating sequence prediction or reconstruction, which contains 10,00010,00010,000 sequences. Each video is long of 202020 frames and consisted of two digits (possibly overlapped) moving inside a 64×6464\\times6464×64 patch. The first benchmark is reported on [43] by the method of LSTMs. Yahoo Flickr Creative Commons 100100100 Million (YFCC100M) dataset[44][45] is the largest public multimedia collection that is allowed to search by users for their own targets; this dataset can browse both images and videos. It is free and for researchers to explore and investigate subsets of the YFCC100M in real-time. Subsets of the complete dataset can be retrieved by any keyword searching and reviewed directly. In addition, the text information attached to any image or video is abundant, such as containing location information and user tags. Briefly，it is more a multimedia library than a domain dataset. More generalized dataset concept in self-supervised learning era is composed of multimedia website, APP, or search engine such as \\textbf{Instagram}, Flickr, Google Images, etc. I think pictures in the wild will play a major role in the future study in CV because of the quantity of data, the computation source, and the learning power of PTM. Reference [1] http://yann.lecun.com/exdb/mnist/. [2] http://ufldl.stanford.edu/housenumbers/. [3] https://www.cs.toronto.edu/~kriz/index.html. [4] A. Coates, A. Ng, and H. Lee, “An analysis of single-layer networks in unsupervised feature learning,” in Proceedings of the fourteenth international conference on artificial intelligence and statistics, pp. 215–223, JMLR Workshop and Conference Proceedings, 2011. [5] https://cs.stanford.edu/~acoates/stl10/. [6] http://www.vision.caltech.edu/Image_Datasets/Caltech101/. [7] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, “Imagenet: A large-scale hierarchical image database,” in 2009 IEEE conference on computer vision and pattern recognition, pp. 248–255, Ieee, 2009. [8] G. A. Miller, WordNet: An electronic lexical database. MIT press, 1998. [9] https://image-net.org/. [10] H. Kuehne, H. Jhuang, E. Garrote, T. Poggio, and T. Serre, “HMDB: a large video database for human motion recognition,” in Proceedings of the International Conference on Computer Vision (ICCV), 2011. [11] https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/. [12] https://www.crcv.ucf.edu/data/UCF101.php. [13] https://www.crcv.ucf.edu/data/UCF50.php. [14] L. Bossard, M. Guillaumin, and L. Van Gool, “Food-101–mining discriminative components with random forests,” in European conference on computer vision, pp. 446–461, Springer, 2014. [15] T. Berg, J. Liu, S. Woo Lee, M. L. Alexander, D. W. Jacobs, and P. N. Belhumeur, “Birdsnap: Large-scale fine-grained visual categorization of birds,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2014. [16] J. Xiao, J. Hays, K. A. Ehinger, A. Oliva, and A. Torralba, “Sun database: Large-scale scene recognition from abbey to zoo,” in 2010 IEEE computer society conference on computer vision and pattern recognition, pp. 3485–3492, IEEE, 2010. [17] J. Xiao, K. A. Ehinger, J. Hays, A. Torralba, and A. Oliva, “Sun database: Exploring a large collection of scene c International Journal of Computer Vision, vol. 119, no. 1, pp. 3–22, 2016. [18] http://places.csail.mit.edu/downloadData.html. [19] http://ai.stanford.edu/~jkrause/cars/car_dataset.html. [20] S. Maji, J. Kannala, E. Rahtu, M. Blaschko, and A. Vedaldi, “Fine-grained visual classification of aircraft,” tech. rep., 2013. [21] https://sites.google.com/site/fgcomp2013/. [22] https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/. [23] https://www.robots.ox.ac.uk/~vgg/data/pets/. [24] https://www.robots.ox.ac.uk/~vgg/data/flowers/. [25] https://www.robots.ox.ac.uk/~vgg/data/dtd/. [26] https://sites.google.com/view/fgvc5/competitions/inaturalist. [27] https://www.inaturalist.org/. [28] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollár, and C. L. Zitnick, “Microsoft coco: Common objects in context,” in European conference on computer vision, pp. 740–755, Springer, 2014. [29] http://host.robots.ox.ac.uk/pascal/VOC/. [30] http://host.robots.ox.ac.uk/pascal/VOC/voc2007/index.html. [31] http://host.robots.ox.ac.uk/pascal/VOC/voc2011/index.html. [32] http://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html. [33] B. Zhou, H. Zhao, X. Puig, S. Fidler, A. Barriuso, and A. Torralba, “Scene parsing through ade20k dataset,” in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 633–641, 2017. [34] B. Zhou, H. Zhao, X. Puig, T. Xiao, S. Fidler, A. Barriuso, and A. Torralba, “Semantic understanding of scenes through the ade20k dataset,” International Journal of Computer Vision, vol. 127, no. 3, pp. 302–321, 2019. [35] https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html. [36] M. Cordts, M. Omran, S. Ramos, T. Scharwächter, M. Enzweiler, R. Benenson, U. Franke, S. Roth, and B. Schiele, “The cityscapes dataset,” in CVPR Workshop on The Future of Datasets in Vision, 2015. [37] M. Cordts, M. Omran, S. Ramos, T. Rehfeld, M. Enzweiler, R. Benenson, U. Franke, S. Roth, and B. Schiele, “The cityscapes dataset for semantic urban scene understanding,” in Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016. [38] A. Gupta, P. Dollar, and R. Girshick, “LVIS: A dataset for large vocabulary instance segmentation,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2019. [39] https://davischallenge.org/. [40] https://davischallenge.org/davis2017/code.html. [41] C. Doersch, “Data analysis project: What makes paris look like paris?”. [42] http://www.cs.toronto.edu/~nitish/unsupervised_video/. [43] N. Srivastava, E. Mansimov, and R. Salakhudinov, “Unsupervised learning of video representations using lstms,” in International conference on machine learning, pp. 843–852, PMLR, 2015. [44] B. Thomee, D. A. Shamma, G. Friedland, B. Elizalde, K. Ni, D. Poland, D. Borth, and L.-J. Li, “Yfcc100m: The new data in multimedia research,” Communications of the ACM, vol. 59, no. 2, pp. 64–73, 2016. [45] http://projects.dfki.uni-kl.de/yfcc100m/.","categories":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"https://junfish.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"PTM","slug":"PTM","permalink":"https://junfish.github.io/tags/PTM/"},{"name":"SSL","slug":"SSL","permalink":"https://junfish.github.io/tags/SSL/"},{"name":"benchmark datasets","slug":"benchmark-datasets","permalink":"https://junfish.github.io/tags/benchmark-datasets/"},{"name":"CV","slug":"CV","permalink":"https://junfish.github.io/tags/CV/"}]},{"title":"How to import data from Douban API?","slug":"import-douban-data-from-douban-api","date":"2021-07-05T07:24:50.000Z","updated":"2022-03-25T21:49:07.000Z","comments":true,"path":"2021/07/05/import-douban-data-from-douban-api/","link":"","permalink":"https://junfish.github.io/2021/07/05/import-douban-data-from-douban-api/","excerpt":"","text":"写在前面 Hexo 为我们提供了大量的 Plugins 以供需要使用，这些包通过npm install命令可以一键便捷地集成到我们的网站中。大家可以根据个人胃口食用之。因此，本文只是作为一个引子展示 Hexo 有广泛的个性化定制支撑。毕竟，博客作为一个记录功能的存在，我们希望它的建设更加丰富多样的同时不要占据我们太多的工作和学习时间。Time is Money。 安装组件并配置 直接通过官方命令npm install hexo-douban --save安装。 站点根目录下的/_config.yml配置文件末尾加上如下代码： 12345678910111213douban: user: 214963638 # 你的豆瓣ID builtin: true # 将生成页面的功能嵌入hexo s和hexo g中 book: title: &#x27;读后感&#x27; quote: &#x27;This is my book quote&#x27; movie: title: &#x27;观后感&#x27; quote: &#x27;This is my movie quote&#x27; #game: #title: &#x27;This is my game title&#x27; #quote: &#x27;This is my game quote&#x27; timeout: 10000 # 爬取数据的超时时间，也即超时报错（ETIMEOUT）等待时间 通过命令hexo clean &amp;&amp; hexo douban -bgm &amp;&amp; hexo g -d &amp;&amp; hexo s开启豆瓣的数据导入，其中-bgm代表的是 books、games、movies 三个参数，根据需要酌情食用。 ps: builtin参数设置为true将hexo douban -bgm内嵌入hexo g -d或hexo s中，方便网页的下次生成和部署。 在主题配置文件/themes/pure/_config.yml中添加 menu 按钮及其图标代码。 12345678910111213141516171819202122232425menu: Home: / Archives: archives # 归档 Categories: categories # 分类 Tags: tags # 标签 Publications: /publications Repository: repository # github repositories Books: books # 豆瓣书单 Movies: movies # 豆瓣电影 Links: links # 友链 About: about # 关于# Enable/Disable menu iconsmenu_icons: enable: true # 是否启用导航菜单图标 home: icon-home-fill archives: icon-archives-fill categories: icon-folder tags: icon-tags publications: icon-list repository: icon-project books: icon-book-fill movies: icon-douban links: icon-friendship about: icon-cup-fill 常规 Bug 的解决方案 数据导入（hexo douban -bgm）可能出现的常规报错[1]如下所示： 12INFO 0 books have been loaded in 2177 ms, because you are offline or your network is badINFO 0 movies have been loaded in 2351 ms, because you are offline or your network is bad 首先利用node --version检查当前版本，然后通过sudo npm install n -g安装 node 的管理模块，最后通过命令sudo n 12.18.1安装 v12.18.1 版本的node.js 解决上述网络问题导致的 bug。 参考资料 [1] Hexo博客加入豆瓣 [2] 在Hexo博客中加入豆瓣读书页面 [3] node版本降级（mac下）","categories":[{"name":"站点建设","slug":"站点建设","permalink":"https://junfish.github.io/categories/%E7%AB%99%E7%82%B9%E5%BB%BA%E8%AE%BE/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://junfish.github.io/tags/hexo/"},{"name":"plugins","slug":"plugins","permalink":"https://junfish.github.io/tags/plugins/"}]},{"title":"How to import comment system into my blog website?","slug":"import-comment-system","date":"2021-07-04T04:13:38.000Z","updated":"2022-03-25T21:49:02.000Z","comments":true,"path":"2021/07/04/import-comment-system/","link":"","permalink":"https://junfish.github.io/2021/07/04/import-comment-system/","excerpt":"","text":"名词介绍 评论系统（comment system）是指一个为用户提供交互的平台，并且一般还具有对所有评论进行相应的云端存储或管理功能。LeanCloud 是一家为软件开发提供后端的云服务供应商。Valine 是一款快速、简洁且评论者无需注册的便捷评价系统，非常适合博客等访问量不高的网站，可以有效避免博主维护注册用户等的额外开销。 他们之间的逻辑关系为 Valine 是一款评论系统，LeanCloud 作为一个服务商帮助我们一键运维博客内嵌的 Valine 系统。 准备工作 注册 LeanCloud 账号，推荐国际版账号。 创建应用，然后选择自己创建的应用。 按照：设置（Settings）–&gt; 应用 Key（App Keys）–&gt;AppID 和 AppKey。 为了数据安全，可在安全中心中添加自己的博客域名。 插入 Valine Valine 本身可通过导入js包Valine.min.js而在 html 页面中直接插入，代码例子[1]如下： 123456789101112131415161718192021222324&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Valine - A simple comment system based on Leancloud.&lt;/title&gt; &lt;!--Leancloud 操作库:--&gt; &lt;script src=&quot;//cdn1.lncld.net/static/js/3.0.4/av-min.js&quot;&gt;&lt;/script&gt; &lt;!--Valine 的核心代码库:--&gt; &lt;script src=&quot;./dist/Valine.min.js&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div class=&quot;comment&quot;&gt;&lt;/div&gt; &lt;script&gt; new Valine(&#123; // AV 对象来自上面引入av-min.js(老司机们不要开车➳♡゛扎心了老铁) av: AV, el: &#x27;.comment&#x27;, // app_id: &#x27;Your APP ID&#x27;, // 这里填写上面得到的APP ID app_key: &#x27;Your APP KEY&#x27;, // 这里填写上面得到的APP KEY placeholder: &#x27;ヾﾉ≧∀≦)o来啊，快活啊!&#x27; // [v1.0.7 new]留言框占位提示文字 &#125;); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 然而，在我们使用的 hexo 主题模板中，只需要通过./themes/pure/_config.yml文件即可激活我们的 Valine 系统。找到comment项如下所示： 123456789101112131415161718192021222324252627282930comment: type: valine # 启用哪种评论系统 disqus: youyan: uid: livere: uid: gitment: githubID: repo: ClientID: ClientSecret: lazy: false gitalk: owner: admin: repo: ClientID: ClientSecret: valine: appid: # your leancloud application appid appkey: # your leancloud application appkey notify: false # mail notifier , https://github.com/xCss/Valine/wiki verify: true # Verification code placeholder: Please comment here! This box has full support for Markdown. 请评论！支持 Markdown 语法。 # comment box placeholder avatar: mm # gravatar style meta: nick,mail,link # custom comment header pageSize: 10 # pagination size visitor: true # Article reading statistic https://valine.js.org/visitor.html recordIP: true # 记录评论者IP 需要配置的项已经在上面的yaml文件中注释。 测试与玩转 通过 hexo clean &amp;&amp; hexo g -d来更新并部署添加了评论系统的博客。然后进行评论，并登录 leancloud 进行后台数据的管理。截图如下所示： 参考文献 [1] Valine – 一款极简的评论系统 [2] Hexo 部署 valine 评论的 leancloud 设置","categories":[{"name":"站点建设","slug":"站点建设","permalink":"https://junfish.github.io/categories/%E7%AB%99%E7%82%B9%E5%BB%BA%E8%AE%BE/"}],"tags":[{"name":"comment system","slug":"comment-system","permalink":"https://junfish.github.io/tags/comment-system/"},{"name":"LeanCloud","slug":"LeanCloud","permalink":"https://junfish.github.io/tags/LeanCloud/"},{"name":"Valine","slug":"Valine","permalink":"https://junfish.github.io/tags/Valine/"},{"name":"评论系统","slug":"评论系统","permalink":"https://junfish.github.io/tags/%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F/"}]},{"title":"How to create your own blog on github by hexo?","slug":"how-to-create-blog-md","date":"2021-07-03T05:28:21.000Z","updated":"2023-02-11T00:26:02.000Z","comments":true,"path":"2021/07/03/how-to-create-blog-md/","link":"","permalink":"https://junfish.github.io/2021/07/03/how-to-create-blog-md/","excerpt":"","text":"名词说明 github 网站是一个代码托管平台，经常用于与他人分享自己的项目与成果。github 利用 git 来逻辑化项目的版本控制和团队间的合作交流。github pages 则是 github 推出的一项用于搭建并托管个人网站的服务。hexo 是一个快捷开发个人博客的强大工具，它支持 Makedown 语法写作和很多功能强大的插件。 简而言之，我们将利用 github 来作为服务器托管我们的博客，用 github pages 来初始化存放我们博客的仓库，用 hexo 来创建、调试、发布我们的博客，并关联到我们创建的 github pages 仓库。因此，关键在于 hexo 与 github 服务器上仓库的连接。 准备工作 注册 github 账号 了解并安装 git 安装 brew (mac上强大的软件管理工具) 环境配置 1. 通过 brew 安装 node.js 1brew install node node.js 会包含 npm 的安装，安装完成后检查是否安装成功。 1node -v 1npm -v 输出为版本号，我的输出如下： 1v16.4.1 17.18.1 2. 利用 npm 安装 hexo 1npm install -g hexo-cli 3. 利用 hexo 初始化博客网站 新建一个文件夹（blog）作为本地博客项目管理地址。 1mkdir blog &amp;&amp; cd blog 本地博客的初始化操作： 1hexo init 初始化完成之后我们执行 ls 将会展示全部生成的文件如下： 1234_config.landscape.yml package-lock.json source_config.yml package.json themesdb.json publicnode_modules scaffolds 此时我们执行命令 hexo s 就可以预览我们的博客网站，命令行界面输出如下表示一切正常。 123INFO Validating configINFO Start processingINFO Hexo is running at http://localhost:4000 . Press Ctrl+C to stop. 在浏览器地址栏输入 http://localhost:4000 就会打开我们的博客。此时，我们的电脑即为博客的服务器端，其他设备可通过将字符串 “localhost” 替换为本机 ip 地址的方式来访问我们的博客。 4. 通过 Github Pages 建立远程仓库 官方教程 5. 生成 git 客户端 SSH key 通过 Terminal 配置用户名和邮箱: 12git config --global user.name &quot;username&quot;git config --global user.email &quot;email@gmail.com&quot; 然后通过下面的命令生成 SSH key: 1ssh-keygen -t rsa -C &quot;email@gmail.com&quot; 接着输入如下命令获取 key: 1cat ~/.ssh/id_rsa.pub 6. 与 github 仓库建立远程链接 Github 账户 --&gt; Settings --&gt; SSH and GPG keys --&gt; New SSH key 7. 管理个人博客常用命令与技巧 发布博客：hexo n newblog 清除已生成的静态文件：hexo clean 生成博客：hexo g 部署博客：hexo d 避免重复输入 passphrase：ssh-add -K ~/.ssh/id_rsa。该命令可用于在当前 session 中记住私钥，重启 Terminal 会要求再次输入 passphrase。 一键生成博客并部署：hexo g -d 参考文献 [1] Mac下使用GitHub+Hexo搭建个人博客 [2] git命令行如何设置passphrase for key来避免每次push都需要输入pass for key? [3] GitHub Pages + Hexo免费搭建个人博客_Mac","categories":[{"name":"站点建设","slug":"站点建设","permalink":"https://junfish.github.io/categories/%E7%AB%99%E7%82%B9%E5%BB%BA%E8%AE%BE/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://junfish.github.io/tags/hexo/"},{"name":"github","slug":"github","permalink":"https://junfish.github.io/tags/github/"},{"name":"macintosh","slug":"macintosh","permalink":"https://junfish.github.io/tags/macintosh/"}]},{"title":"Golden Words in Academic Writing","slug":"practice-in-paper-writing","date":"2021-07-03T05:28:21.000Z","updated":"2023-02-16T20:36:13.000Z","comments":true,"path":"2021/07/03/practice-in-paper-writing/","link":"","permalink":"https://junfish.github.io/2021/07/03/practice-in-paper-writing/","excerpt":"","text":"Abstract Commend your own model simple yet effective Introduction Inspired by other works the proposed method follows the spirit of XXX inspired by XXX Similar but different our algorithm/method is similar to xxx with two differences: (1) we … instead of …, and (2) we use xxx as … Judging other works making XXX prohibitive in practice methods","categories":[{"name":"WritingSkills","slug":"WritingSkills","permalink":"https://junfish.github.io/categories/WritingSkills/"}],"tags":[{"name":"writing","slug":"writing","permalink":"https://junfish.github.io/tags/writing/"}]}],"categories":[{"name":"小作文","slug":"小作文","permalink":"https://junfish.github.io/categories/%E5%B0%8F%E4%BD%9C%E6%96%87/"},{"name":"Debugging","slug":"Debugging","permalink":"https://junfish.github.io/categories/Debugging/"},{"name":"MachineLearning","slug":"MachineLearning","permalink":"https://junfish.github.io/categories/MachineLearning/"},{"name":"Cheatsheet","slug":"Cheatsheet","permalink":"https://junfish.github.io/categories/Cheatsheet/"},{"name":"站点建设","slug":"站点建设","permalink":"https://junfish.github.io/categories/%E7%AB%99%E7%82%B9%E5%BB%BA%E8%AE%BE/"},{"name":"Recreation","slug":"Recreation","permalink":"https://junfish.github.io/categories/Recreation/"},{"name":"WritingSkills","slug":"WritingSkills","permalink":"https://junfish.github.io/categories/WritingSkills/"},{"name":"计算机视觉","slug":"计算机视觉","permalink":"https://junfish.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"个人感悟","slug":"个人感悟","permalink":"https://junfish.github.io/tags/%E4%B8%AA%E4%BA%BA%E6%84%9F%E6%82%9F/"},{"name":"Nvidia","slug":"Nvidia","permalink":"https://junfish.github.io/tags/Nvidia/"},{"name":"GPU","slug":"GPU","permalink":"https://junfish.github.io/tags/GPU/"},{"name":"driver","slug":"driver","permalink":"https://junfish.github.io/tags/driver/"},{"name":"Matrix","slug":"Matrix","permalink":"https://junfish.github.io/tags/Matrix/"},{"name":"Calculus","slug":"Calculus","permalink":"https://junfish.github.io/tags/Calculus/"},{"name":"derivative","slug":"derivative","permalink":"https://junfish.github.io/tags/derivative/"},{"name":"Markdown","slug":"Markdown","permalink":"https://junfish.github.io/tags/Markdown/"},{"name":"Cheatsheet","slug":"Cheatsheet","permalink":"https://junfish.github.io/tags/Cheatsheet/"},{"name":"commands","slug":"commands","permalink":"https://junfish.github.io/tags/commands/"},{"name":"linux","slug":"linux","permalink":"https://junfish.github.io/tags/linux/"},{"name":"conda","slug":"conda","permalink":"https://junfish.github.io/tags/conda/"},{"name":"python","slug":"python","permalink":"https://junfish.github.io/tags/python/"},{"name":"virtual environment","slug":"virtual-environment","permalink":"https://junfish.github.io/tags/virtual-environment/"},{"name":"Tmux","slug":"Tmux","permalink":"https://junfish.github.io/tags/Tmux/"},{"name":"Linux","slug":"Linux","permalink":"https://junfish.github.io/tags/Linux/"},{"name":"SSH","slug":"SSH","permalink":"https://junfish.github.io/tags/SSH/"},{"name":"hexo","slug":"hexo","permalink":"https://junfish.github.io/tags/hexo/"},{"name":"billiards","slug":"billiards","permalink":"https://junfish.github.io/tags/billiards/"},{"name":"terminology","slug":"terminology","permalink":"https://junfish.github.io/tags/terminology/"},{"name":"writing","slug":"writing","permalink":"https://junfish.github.io/tags/writing/"},{"name":"E-mail","slug":"E-mail","permalink":"https://junfish.github.io/tags/E-mail/"},{"name":"Multi-X Learning","slug":"Multi-X-Learning","permalink":"https://junfish.github.io/tags/Multi-X-Learning/"},{"name":"Multi-class","slug":"Multi-class","permalink":"https://junfish.github.io/tags/Multi-class/"},{"name":"Multi-label","slug":"Multi-label","permalink":"https://junfish.github.io/tags/Multi-label/"},{"name":"Multi-instance","slug":"Multi-instance","permalink":"https://junfish.github.io/tags/Multi-instance/"},{"name":"Multi-view","slug":"Multi-view","permalink":"https://junfish.github.io/tags/Multi-view/"},{"name":"Multi-source","slug":"Multi-source","permalink":"https://junfish.github.io/tags/Multi-source/"},{"name":"Multi-task","slug":"Multi-task","permalink":"https://junfish.github.io/tags/Multi-task/"},{"name":"ImageNet","slug":"ImageNet","permalink":"https://junfish.github.io/tags/ImageNet/"},{"name":"Preprocess","slug":"Preprocess","permalink":"https://junfish.github.io/tags/Preprocess/"},{"name":"预处理","slug":"预处理","permalink":"https://junfish.github.io/tags/%E9%A2%84%E5%A4%84%E7%90%86/"},{"name":"PTM","slug":"PTM","permalink":"https://junfish.github.io/tags/PTM/"},{"name":"SSL","slug":"SSL","permalink":"https://junfish.github.io/tags/SSL/"},{"name":"benchmark datasets","slug":"benchmark-datasets","permalink":"https://junfish.github.io/tags/benchmark-datasets/"},{"name":"CV","slug":"CV","permalink":"https://junfish.github.io/tags/CV/"},{"name":"plugins","slug":"plugins","permalink":"https://junfish.github.io/tags/plugins/"},{"name":"comment system","slug":"comment-system","permalink":"https://junfish.github.io/tags/comment-system/"},{"name":"LeanCloud","slug":"LeanCloud","permalink":"https://junfish.github.io/tags/LeanCloud/"},{"name":"Valine","slug":"Valine","permalink":"https://junfish.github.io/tags/Valine/"},{"name":"评论系统","slug":"评论系统","permalink":"https://junfish.github.io/tags/%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F/"},{"name":"github","slug":"github","permalink":"https://junfish.github.io/tags/github/"},{"name":"macintosh","slug":"macintosh","permalink":"https://junfish.github.io/tags/macintosh/"}]}